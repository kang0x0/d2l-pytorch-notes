{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "310ac5cd",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 长短期记忆网络（LSTM）\n",
    ":label:`sec_lstm`\n",
    "\n",
    "长期以来，隐变量模型存在着长期信息保存和短期输入缺失的问题。\n",
    "解决这一问题的最早方法之一是长短期存储器（long short-term memory，LSTM）\n",
    " :cite:`Hochreiter.Schmidhuber.1997`。\n",
    "它有许多与门控循环单元（ :numref:`sec_gru`）一样的属性。\n",
    "有趣的是，长短期记忆网络的设计比门控循环单元稍微复杂一些，\n",
    "却比门控循环单元早诞生了近20年。\n",
    "\n",
    "## 门控记忆元\n",
    "\n",
    "可以说，长短期记忆网络的设计灵感来自于计算机的逻辑门。\n",
    "长短期记忆网络引入了*记忆元*（memory cell），或简称为*单元*（cell）。\n",
    "有些文献认为记忆元是隐状态的一种特殊类型，\n",
    "它们与隐状态具有相同的形状，其设计目的是用于记录附加的信息。\n",
    "为了控制记忆元，我们需要许多门。\n",
    "其中一个门用来从单元中输出条目，我们将其称为*输出门*（output gate）。\n",
    "另外一个门用来决定何时将数据读入单元，我们将其称为*输入门*（input gate）。\n",
    "我们还需要一种机制来重置单元的内容，由*遗忘门*（forget gate）来管理，\n",
    "这种设计的动机与门控循环单元相同，\n",
    "能够通过专用机制决定什么时候记忆或忽略隐状态中的输入。\n",
    "让我们看看这在实践中是如何运作的。\n",
    "\n",
    "### 输入门、忘记门和输出门\n",
    "\n",
    "就如在门控循环单元中一样，\n",
    "当前时间步的输入和前一个时间步的隐状态\n",
    "作为数据送入长短期记忆网络的门中，\n",
    "如 :numref:`lstm_0`所示。\n",
    "它们由三个具有sigmoid激活函数的全连接层处理，\n",
    "以计算输入门、遗忘门和输出门的值。\n",
    "因此，这三个门的值都在$(0, 1)$的范围内。\n",
    "\n",
    "![长短期记忆模型中的输入门、遗忘门和输出门](../img/lstm-0.svg)\n",
    ":label:`lstm_0`\n",
    "\n",
    "我们来细化一下长短期记忆网络的数学表达。\n",
    "假设有$h$个隐藏单元，批量大小为$n$，输入数为$d$。\n",
    "因此，输入为$\\mathbf{X}_t \\in \\mathbb{R}^{n \\times d}$，\n",
    "前一时间步的隐状态为$\\mathbf{H}_{t-1} \\in \\mathbb{R}^{n \\times h}$。\n",
    "相应地，时间步$t$的门被定义如下：\n",
    "输入门是$\\mathbf{I}_t \\in \\mathbb{R}^{n \\times h}$，\n",
    "遗忘门是$\\mathbf{F}_t \\in \\mathbb{R}^{n \\times h}$，\n",
    "输出门是$\\mathbf{O}_t \\in \\mathbb{R}^{n \\times h}$。\n",
    "它们的计算方法如下：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{I}_t &= \\sigma(\\mathbf{X}_t \\mathbf{W}_{xi} + \\mathbf{H}_{t-1} \\mathbf{W}_{hi} + \\mathbf{b}_i),\\\\\n",
    "\\mathbf{F}_t &= \\sigma(\\mathbf{X}_t \\mathbf{W}_{xf} + \\mathbf{H}_{t-1} \\mathbf{W}_{hf} + \\mathbf{b}_f),\\\\\n",
    "\\mathbf{O}_t &= \\sigma(\\mathbf{X}_t \\mathbf{W}_{xo} + \\mathbf{H}_{t-1} \\mathbf{W}_{ho} + \\mathbf{b}_o),\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "其中$\\mathbf{W}_{xi}, \\mathbf{W}_{xf}, \\mathbf{W}_{xo} \\in \\mathbb{R}^{d \\times h}$\n",
    "和$\\mathbf{W}_{hi}, \\mathbf{W}_{hf}, \\mathbf{W}_{ho} \\in \\mathbb{R}^{h \\times h}$是权重参数，\n",
    "$\\mathbf{b}_i, \\mathbf{b}_f, \\mathbf{b}_o \\in \\mathbb{R}^{1 \\times h}$是偏置参数。\n",
    "\n",
    "### 候选记忆元\n",
    "\n",
    "由于还没有指定各种门的操作，所以先介绍*候选记忆元*（candidate memory cell）\n",
    "$\\tilde{\\mathbf{C}}_t \\in \\mathbb{R}^{n \\times h}$。\n",
    "它的计算与上面描述的三个门的计算类似，\n",
    "但是使用$\\tanh$函数作为激活函数，函数的值范围为$(-1, 1)$。\n",
    "下面导出在时间步$t$处的方程：\n",
    "\n",
    "$$\\tilde{\\mathbf{C}}_t = \\text{tanh}(\\mathbf{X}_t \\mathbf{W}_{xc} + \\mathbf{H}_{t-1} \\mathbf{W}_{hc} + \\mathbf{b}_c),$$\n",
    "\n",
    "其中$\\mathbf{W}_{xc} \\in \\mathbb{R}^{d \\times h}$和\n",
    "$\\mathbf{W}_{hc} \\in \\mathbb{R}^{h \\times h}$是权重参数，\n",
    "$\\mathbf{b}_c \\in \\mathbb{R}^{1 \\times h}$是偏置参数。\n",
    "\n",
    "候选记忆元的如 :numref:`lstm_1`所示。\n",
    "\n",
    "![长短期记忆模型中的候选记忆元](../img/lstm-1.svg)\n",
    ":label:`lstm_1`\n",
    "\n",
    "### 记忆元\n",
    "\n",
    "在门控循环单元中，有一种机制来控制输入和遗忘（或跳过）。\n",
    "类似地，在长短期记忆网络中，也有两个门用于这样的目的：\n",
    "输入门$\\mathbf{I}_t$控制采用多少来自$\\tilde{\\mathbf{C}}_t$的新数据，\n",
    "而遗忘门$\\mathbf{F}_t$控制保留多少过去的\n",
    "记忆元$\\mathbf{C}_{t-1} \\in \\mathbb{R}^{n \\times h}$的内容。\n",
    "使用按元素乘法，得出：\n",
    "\n",
    "$$\\mathbf{C}_t = \\mathbf{F}_t \\odot \\mathbf{C}_{t-1} + \\mathbf{I}_t \\odot \\tilde{\\mathbf{C}}_t.$$\n",
    "\n",
    "如果遗忘门始终为$1$且输入门始终为$0$，\n",
    "则过去的记忆元$\\mathbf{C}_{t-1}$\n",
    "将随时间被保存并传递到当前时间步。\n",
    "引入这种设计是为了缓解梯度消失问题，\n",
    "并更好地捕获序列中的长距离依赖关系。\n",
    "\n",
    "这样我们就得到了计算记忆元的流程图，如 :numref:`lstm_2`。\n",
    "\n",
    "![在长短期记忆网络模型中计算记忆元](../img/lstm-2.svg)\n",
    "\n",
    ":label:`lstm_2`\n",
    "\n",
    "### 隐状态\n",
    "\n",
    "最后，我们需要定义如何计算隐状态\n",
    "$\\mathbf{H}_t \\in \\mathbb{R}^{n \\times h}$，\n",
    "这就是输出门发挥作用的地方。\n",
    "在长短期记忆网络中，它仅仅是记忆元的$\\tanh$的门控版本。\n",
    "这就确保了$\\mathbf{H}_t$的值始终在区间$(-1, 1)$内：\n",
    "\n",
    "$$\\mathbf{H}_t = \\mathbf{O}_t \\odot \\tanh(\\mathbf{C}_t).$$\n",
    "\n",
    "只要输出门接近$1$，我们就能够有效地将所有记忆信息传递给预测部分，\n",
    "而对于输出门接近$0$，我们只保留记忆元内的所有信息，而不需要更新隐状态。\n",
    "\n",
    " :numref:`lstm_3`提供了数据流的图形化演示。\n",
    "\n",
    "![在长短期记忆模型中计算隐状态](../img/lstm-3.svg)\n",
    ":label:`lstm_3`\n",
    "\n",
    "## 从零开始实现\n",
    "\n",
    "现在，我们从零开始实现长短期记忆网络。\n",
    "与 :numref:`sec_rnn_scratch`中的实验相同，\n",
    "我们首先加载时光机器数据集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b14ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import os\n",
    "import collections\n",
    "import random\n",
    "import torch\n",
    "\n",
    "class Vocab:  #@save\n",
    "    \"\"\"文本词表\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        # 按出现频率排序\n",
    "        counter = count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "        # 未知词元的索引为0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # 未知词元的索引为0\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs\n",
    "    \n",
    "def count_corpus(tokens):  #@save\n",
    "    \"\"\"统计词元的频率\"\"\"\n",
    "    # 这里的tokens是1D列表或2D列表\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # 将词元列表展平成一个列表\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n",
    "\n",
    "def download_time_machine(data_dir='../data', filename='timemachine.txt'):\n",
    "    \"\"\"下载时间机器文本文件\"\"\"\n",
    "    url = 'http://d2l-data.s3-accelerate.amazonaws.com/timemachine.txt'\n",
    "    \n",
    "    # 创建数据目录（如果不存在）\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    # 完整文件路径\n",
    "    file_path = os.path.join(data_dir, filename)\n",
    "    \n",
    "    # 如果文件不存在，则下载\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f'Downloading {filename} from {url}...')\n",
    "        response = requests.get(url)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f'File saved to {file_path}')\n",
    "    else:\n",
    "        print(f'File already exists at {file_path}')\n",
    "    \n",
    "    return file_path\n",
    "\n",
    "def read_time_machine():\n",
    "    \"\"\"将时间机器数据集加载到文本行的列表中\"\"\"\n",
    "    # 下载文件并获取路径\n",
    "    file_path = download_time_machine()\n",
    "    \n",
    "    # 读取文件内容\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # 处理每一行：只保留字母，转为小写，去除首尾空格\n",
    "    processed_lines = [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n",
    "    \n",
    "    return processed_lines\n",
    "\n",
    "def tokenize(lines, token='word'):  #@save\n",
    "    \"\"\"将文本行拆分为单词或字符词元\"\"\"\n",
    "    if token == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token == 'char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print('错误：未知词元类型：' + token)\n",
    "\n",
    "def load_corpus_time_machine(max_tokens=-1):  #@save\n",
    "    \"\"\"返回时光机器数据集的词元索引列表和词表\"\"\"\n",
    "    lines = read_time_machine()\n",
    "    tokens = tokenize(lines, 'char')\n",
    "    vocab = Vocab(tokens)\n",
    "    # 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，\n",
    "    # 所以将所有文本行展平到一个列表中\n",
    "    corpus = [vocab[token] for line in tokens for token in line]\n",
    "    if max_tokens > 0:\n",
    "        corpus = corpus[:max_tokens]\n",
    "    return corpus, vocab\n",
    "\n",
    "def seq_data_iter_random(corpus, batch_size, num_steps):  #@save\n",
    "    \"\"\"使用随机抽样生成一个小批量子序列\"\"\"\n",
    "    # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1\n",
    "    corpus = corpus[random.randint(0, num_steps - 1):]\n",
    "    # 减去1，是因为我们需要考虑标签\n",
    "    num_subseqs = (len(corpus) - 1) // num_steps\n",
    "    # 长度为num_steps的子序列的起始索引\n",
    "    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n",
    "    # 在随机抽样的迭代过程中，\n",
    "    # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻\n",
    "    random.shuffle(initial_indices)\n",
    "\n",
    "    def data(pos):\n",
    "        # 返回从pos位置开始的长度为num_steps的序列\n",
    "        return corpus[pos: pos + num_steps]\n",
    "\n",
    "    num_batches = num_subseqs // batch_size\n",
    "    for i in range(0, batch_size * num_batches, batch_size):\n",
    "        # 在这里，initial_indices包含子序列的随机起始索引\n",
    "        initial_indices_per_batch = initial_indices[i: i + batch_size]\n",
    "        X = [data(j) for j in initial_indices_per_batch]\n",
    "        Y = [data(j + 1) for j in initial_indices_per_batch]\n",
    "        yield torch.tensor(X), torch.tensor(Y)\n",
    "\n",
    "def seq_data_iter_sequential(corpus, batch_size, num_steps):  #@save\n",
    "    \"\"\"使用顺序分区生成一个小批量子序列\"\"\"\n",
    "    # 从随机偏移量开始划分序列\n",
    "    offset = random.randint(0, num_steps)\n",
    "    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n",
    "    Xs = torch.tensor(corpus[offset: offset + num_tokens])\n",
    "    Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n",
    "    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n",
    "    num_batches = Xs.shape[1] // num_steps\n",
    "    for i in range(0, num_steps * num_batches, num_steps):\n",
    "        X = Xs[:, i: i + num_steps]\n",
    "        Y = Ys[:, i: i + num_steps]\n",
    "        yield X, Y\n",
    "\n",
    "class SeqDataLoader:  #@save\n",
    "    \"\"\"加载序列数据的迭代器\"\"\"\n",
    "    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):\n",
    "        if use_random_iter:\n",
    "            self.data_iter_fn = seq_data_iter_random\n",
    "        else:\n",
    "            self.data_iter_fn = seq_data_iter_sequential\n",
    "        self.corpus, self.vocab = load_corpus_time_machine(max_tokens)\n",
    "        self.batch_size, self.num_steps = batch_size, num_steps\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)\n",
    "\n",
    "def load_data_time_machine(batch_size, num_steps,  #@save\n",
    "                           use_random_iter=False, max_tokens=10000):\n",
    "    \"\"\"返回时光机器数据集的迭代器和词表\"\"\"\n",
    "    data_iter = SeqDataLoader(\n",
    "        batch_size, num_steps, use_random_iter, max_tokens)\n",
    "    return data_iter, data_iter.vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96a7231c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:24:18.324326Z",
     "iopub.status.busy": "2023-08-18T07:24:18.323673Z",
     "iopub.status.idle": "2023-08-18T07:24:21.607373Z",
     "shell.execute_reply": "2023-08-18T07:24:21.606483Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists at ../data\\timemachine.txt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# from d2l import torch as d2l\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = load_data_time_machine(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef97237",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "### [**初始化模型参数**]\n",
    "\n",
    "接下来，我们需要定义和初始化模型参数。\n",
    "如前所述，超参数`num_hiddens`定义隐藏单元的数量。\n",
    "我们按照标准差$0.01$的高斯分布初始化权重，并将偏置项设为$0$。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d90745d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:24:21.612618Z",
     "iopub.status.busy": "2023-08-18T07:24:21.611785Z",
     "iopub.status.idle": "2023-08-18T07:24:21.619127Z",
     "shell.execute_reply": "2023-08-18T07:24:21.618267Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def get_lstm_params(vocab_size, num_hiddens, device):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "\n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape, device=device)*0.01\n",
    "\n",
    "    def three():\n",
    "        return (normal((num_inputs, num_hiddens)),\n",
    "                normal((num_hiddens, num_hiddens)),\n",
    "                torch.zeros(num_hiddens, device=device))\n",
    "\n",
    "    W_xi, W_hi, b_i = three()  # 输入门参数\n",
    "    W_xf, W_hf, b_f = three()  # 遗忘门参数\n",
    "    W_xo, W_ho, b_o = three()  # 输出门参数\n",
    "    W_xc, W_hc, b_c = three()  # 候选记忆元参数\n",
    "    # 输出层参数\n",
    "    W_hq = normal((num_hiddens, num_outputs))\n",
    "    b_q = torch.zeros(num_outputs, device=device)\n",
    "    # 附加梯度\n",
    "    params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc,\n",
    "              b_c, W_hq, b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aecd87",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "### 定义模型\n",
    "\n",
    "在[**初始化函数**]中，\n",
    "长短期记忆网络的隐状态需要返回一个*额外*的记忆元，\n",
    "单元的值为0，形状为（批量大小，隐藏单元数）。\n",
    "因此，我们得到以下的状态初始化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beeae3b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:24:21.623788Z",
     "iopub.status.busy": "2023-08-18T07:24:21.623183Z",
     "iopub.status.idle": "2023-08-18T07:24:21.628423Z",
     "shell.execute_reply": "2023-08-18T07:24:21.627603Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def init_lstm_state(batch_size, num_hiddens, device):\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device),\n",
    "            torch.zeros((batch_size, num_hiddens), device=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45563d",
   "metadata": {
    "origin_pos": 15
   },
   "source": [
    "[**实际模型**]的定义与我们前面讨论的一样：\n",
    "提供三个门和一个额外的记忆元。\n",
    "请注意，只有隐状态才会传递到输出层，\n",
    "而记忆元$\\mathbf{C}_t$不直接参与输出计算。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50de4e9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:24:21.632468Z",
     "iopub.status.busy": "2023-08-18T07:24:21.631955Z",
     "iopub.status.idle": "2023-08-18T07:24:21.638292Z",
     "shell.execute_reply": "2023-08-18T07:24:21.637498Z"
    },
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def lstm(inputs, state, params):\n",
    "    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c,\n",
    "     W_hq, b_q] = params\n",
    "    (H, C) = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)\n",
    "        F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)\n",
    "        O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)\n",
    "        C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c)\n",
    "        C = F * C + I * C_tilda\n",
    "        H = O * torch.tanh(C)\n",
    "        Y = (H @ W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs, dim=0), (H, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36361aa",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "### [**训练**]和预测\n",
    "\n",
    "让我们通过实例化 :numref:`sec_rnn_scratch`中\n",
    "引入的`RNNModelScratch`类来训练一个长短期记忆网络，\n",
    "就如我们在 :numref:`sec_gru`中所做的一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23d4e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i=0):  #@save\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd1dea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "class RNNModelScratch: #@save\n",
    "    \"\"\"从零开始实现的循环神经网络模型\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, device,\n",
    "                 get_params, init_state, forward_fn):\n",
    "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
    "        self.params = get_params(vocab_size, num_hiddens, device)\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "\n",
    "    def __call__(self, X, state):\n",
    "        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)\n",
    "        return self.forward_fn(X, state, self.params)\n",
    "\n",
    "    def begin_state(self, batch_size, device):\n",
    "        return self.init_state(batch_size, self.num_hiddens, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "457bf516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "\n",
    "class Timer:  #@save\n",
    "    \"\"\"记录多次运行时间\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"启动计时器\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"停止计时器并将时间记录在列表中\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"返回平均时间\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"返回时间总和\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"返回累计时间\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist()\n",
    "\n",
    "class Accumulator:  #@save\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def grad_clipping(net, theta):  #@save\n",
    "    \"\"\"裁剪梯度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm\n",
    "\n",
    "#@save\n",
    "def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n",
    "    \"\"\"训练网络一个迭代周期（定义见第8章）\"\"\"\n",
    "    state, timer = None, Timer()\n",
    "    metric = Accumulator(2)  # 训练损失之和,词元数量\n",
    "    for X, Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            # 在第一次迭代或使用随机抽样时初始化state\n",
    "            state = net.begin_state(batch_size=X.shape[0], device=device)\n",
    "        else:\n",
    "            if isinstance(net, nn.Module) and not isinstance(state, tuple):\n",
    "                # state对于nn.GRU是个张量\n",
    "                state.detach_()\n",
    "            else:\n",
    "                # state对于nn.LSTM或对于我们从零开始实现的模型是个张量\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "        y = Y.T.reshape(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat, state = net(X, state)\n",
    "        l = loss(y_hat, y.long()).mean()\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            # 因为已经调用了mean函数\n",
    "            updater(batch_size=1)\n",
    "        metric.add(l * y.numel(), y.numel())\n",
    "    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e7c373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ch8(prefix, num_preds, net, vocab, device):  #@save\n",
    "    \"\"\"在prefix后面生成新字符\"\"\"\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
    "    for y in prefix[1:]:  # 预热期\n",
    "        _, state = net(get_input(), state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):  # 预测num_preds步\n",
    "        y, state = net(get_input(), state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])\n",
    "\n",
    "def sgd(params, lr, batch_size):  #@save\n",
    "    \"\"\"小批量随机梯度下降\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()\n",
    "\n",
    "from IPython import display\n",
    "class Animator:  #@save\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        \n",
    "        # 替换 d2l.use_svg_display()\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.rcParams['figure.figsize'] = figsize\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # 替换 d2l.set_axes，使用 lambda 函数直接配置参数\n",
    "        self.config_axes = lambda: self._set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def _set_axes(self, ax, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "        \"\"\"设置坐标轴标签、范围和比例\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        # 设置坐标轴标签\n",
    "        if xlabel:\n",
    "            ax.set_xlabel(xlabel)\n",
    "        if ylabel:\n",
    "            ax.set_ylabel(ylabel)\n",
    "        # 设置坐标轴范围\n",
    "        if xlim:\n",
    "            ax.set_xlim(xlim)\n",
    "        if ylim:\n",
    "            ax.set_ylim(ylim)\n",
    "        # 设置坐标轴比例\n",
    "        if xscale:\n",
    "            ax.set_xscale(xscale)\n",
    "        if yscale:\n",
    "            ax.set_yscale(yscale)\n",
    "        # 设置图例\n",
    "        if legend:\n",
    "            ax.legend(legend)\n",
    "        # 添加网格\n",
    "        ax.grid(True)\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "#@save\n",
    "def train_ch8(net, train_iter, vocab, lr, num_epochs, device,\n",
    "              use_random_iter=False):\n",
    "    \"\"\"训练模型（定义见第8章）\"\"\"\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = Animator(xlabel='epoch', ylabel='perplexity',\n",
    "                            legend=['train'], xlim=[10, num_epochs])\n",
    "    # 初始化\n",
    "    if isinstance(net, nn.Module):\n",
    "        updater = torch.optim.SGD(net.parameters(), lr)\n",
    "    else:\n",
    "        updater = lambda batch_size: sgd(net.params, lr, batch_size)\n",
    "    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)\n",
    "    # 训练和预测\n",
    "    for epoch in range(num_epochs):\n",
    "        ppl, speed = train_epoch_ch8(\n",
    "            net, train_iter, loss, updater, device, use_random_iter)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(predict('time traveller'))\n",
    "            animator.add(epoch + 1, [ppl])\n",
    "    print(f'困惑度 {ppl:.1f}, {speed:.1f} 词元/秒 {str(device)}')\n",
    "    print(predict('time traveller'))\n",
    "    print(predict('traveller'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2025d7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:24:21.642387Z",
     "iopub.status.busy": "2023-08-18T07:24:21.641860Z",
     "iopub.status.idle": "2023-08-18T07:28:54.778673Z",
     "shell.execute_reply": "2023-08-18T07:28:54.777826Z"
    },
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "困惑度 1.1, 15212.2 词元/秒 cpu\n",
      "time traveller for so it will be convenient to speak of himwas e\n",
      "traveller filled and scallorist ght of thatonee har a suall\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_size, num_hiddens, device = len(vocab), 256, try_gpu()\n",
    "num_epochs, lr = 500, 1\n",
    "model = RNNModelScratch(len(vocab), num_hiddens, device, get_lstm_params,\n",
    "                            init_lstm_state, lstm)\n",
    "train_ch8(model, train_iter, vocab, lr, num_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245cff43",
   "metadata": {
    "origin_pos": 24
   },
   "source": [
    "## [**简洁实现**]\n",
    "\n",
    "使用高级API，我们可以直接实例化`LSTM`模型。\n",
    "高级API封装了前文介绍的所有配置细节。\n",
    "这段代码的运行速度要快得多，\n",
    "因为它使用的是编译好的运算符而不是Python来处理之前阐述的许多细节。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8273cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "#@save\n",
    "class RNNModel(nn.Module):\n",
    "    \"\"\"循环神经网络模型\"\"\"\n",
    "    def __init__(self, rnn_layer, vocab_size, **kwargs):\n",
    "        super(RNNModel, self).__init__(**kwargs)\n",
    "        self.rnn = rnn_layer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_hiddens = self.rnn.hidden_size\n",
    "        # 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1\n",
    "        if not self.rnn.bidirectional:\n",
    "            self.num_directions = 1\n",
    "            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)\n",
    "        else:\n",
    "            self.num_directions = 2\n",
    "            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)\n",
    "\n",
    "    def forward(self, inputs, state):\n",
    "        X = F.one_hot(inputs.T.long(), self.vocab_size)\n",
    "        X = X.to(torch.float32)\n",
    "        Y, state = self.rnn(X, state)\n",
    "        # 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数)\n",
    "        # 它的输出形状是(时间步数*批量大小,词表大小)。\n",
    "        output = self.linear(Y.reshape((-1, Y.shape[-1])))\n",
    "        return output, state\n",
    "\n",
    "    def begin_state(self, device, batch_size=1):\n",
    "        if not isinstance(self.rnn, nn.LSTM):\n",
    "            # nn.GRU以张量作为隐状态\n",
    "            return  torch.zeros((self.num_directions * self.rnn.num_layers,\n",
    "                                 batch_size, self.num_hiddens),\n",
    "                                device=device)\n",
    "        else:\n",
    "            # nn.LSTM以元组作为隐状态\n",
    "            return (torch.zeros((\n",
    "                self.num_directions * self.rnn.num_layers,\n",
    "                batch_size, self.num_hiddens), device=device),\n",
    "                    torch.zeros((\n",
    "                        self.num_directions * self.rnn.num_layers,\n",
    "                        batch_size, self.num_hiddens), device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca7c37b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:28:54.782381Z",
     "iopub.status.busy": "2023-08-18T07:28:54.781811Z",
     "iopub.status.idle": "2023-08-18T07:29:19.488133Z",
     "shell.execute_reply": "2023-08-18T07:29:19.487180Z"
    },
    "origin_pos": 26,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "困惑度 1.0, 54901.8 词元/秒 cpu\n",
      "time traveller with a slight accession ofcheerfulness really thi\n",
      "travelleryou can show black is white by argument said filby\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_inputs = vocab_size\n",
    "lstm_layer = nn.LSTM(num_inputs, num_hiddens)\n",
    "model = RNNModel(lstm_layer, len(vocab))\n",
    "model = model.to(device)\n",
    "train_ch8(model, train_iter, vocab, lr, num_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc39a6bb",
   "metadata": {
    "origin_pos": 29
   },
   "source": [
    "长短期记忆网络是典型的具有重要状态控制的隐变量自回归模型。\n",
    "多年来已经提出了其许多变体，例如，多层、残差连接、不同类型的正则化。\n",
    "然而，由于序列的长距离依赖性，训练长短期记忆网络\n",
    "和其他序列模型（例如门控循环单元）的成本是相当高的。\n",
    "在后面的内容中，我们将讲述更高级的替代模型，如Transformer。\n",
    "\n",
    "## 小结\n",
    "\n",
    "* 长短期记忆网络有三种类型的门：输入门、遗忘门和输出门。\n",
    "* 长短期记忆网络的隐藏层输出包括“隐状态”和“记忆元”。只有隐状态会传递到输出层，而记忆元完全属于内部信息。\n",
    "* 长短期记忆网络可以缓解梯度消失和梯度爆炸。\n",
    "\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 调整和分析超参数对运行时间、困惑度和输出顺序的影响。\n",
    "1. 如何更改模型以生成适当的单词，而不是字符序列？\n",
    "1. 在给定隐藏层维度的情况下，比较门控循环单元、长短期记忆网络和常规循环神经网络的计算成本。要特别注意训练和推断成本。\n",
    "1. 既然候选记忆元通过使用$\\tanh$函数来确保值范围在$(-1,1)$之间，那么为什么隐状态需要再次使用$\\tanh$函数来确保输出值范围在$(-1,1)$之间呢？\n",
    "1. 实现一个能够基于时间序列进行预测而不是基于字符序列进行预测的长短期记忆网络模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f6654",
   "metadata": {
    "origin_pos": 31,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/2768)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
