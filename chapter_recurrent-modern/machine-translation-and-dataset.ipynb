{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "077b0f04",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 机器翻译与数据集\n",
    ":label:`sec_machine_translation`\n",
    "\n",
    "语言模型是自然语言处理的关键，\n",
    "而*机器翻译*是语言模型最成功的基准测试。\n",
    "因为机器翻译正是将输入序列转换成输出序列的\n",
    "*序列转换模型*（sequence transduction）的核心问题。\n",
    "序列转换模型在各类现代人工智能应用中发挥着至关重要的作用，\n",
    "因此我们将其做为本章剩余部分和 :numref:`chap_attention`的重点。\n",
    "为此，本节将介绍机器翻译问题及其后文需要使用的数据集。\n",
    "\n",
    "*机器翻译*（machine translation）指的是\n",
    "将序列从一种语言自动翻译成另一种语言。\n",
    "事实上，这个研究领域可以追溯到数字计算机发明后不久的20世纪40年代，\n",
    "特别是在第二次世界大战中使用计算机破解语言编码。\n",
    "几十年来，在使用神经网络进行端到端学习的兴起之前，\n",
    "统计学方法在这一领域一直占据主导地位\n",
    " :cite:`Brown.Cocke.Della-Pietra.ea.1988,Brown.Cocke.Della-Pietra.ea.1990`。\n",
    "因为*统计机器翻译*（statistical machine translation）涉及了\n",
    "翻译模型和语言模型等组成部分的统计分析，\n",
    "因此基于神经网络的方法通常被称为\n",
    "*神经机器翻译*（neural machine translation），\n",
    "用于将两种翻译模型区分开来。\n",
    "\n",
    "本书的关注点是神经网络机器翻译方法，强调的是端到端的学习。\n",
    "与 :numref:`sec_language_model`中的语料库\n",
    "是单一语言的语言模型问题存在不同，\n",
    "机器翻译的数据集是由源语言和目标语言的文本序列对组成的。\n",
    "因此，我们需要一种完全不同的方法来预处理机器翻译数据集，\n",
    "而不是复用语言模型的预处理程序。\n",
    "下面，我们看一下如何将预处理后的数据加载到小批量中用于训练。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38f128f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:28.568184Z",
     "iopub.status.busy": "2023-08-18T07:07:28.567577Z",
     "iopub.status.idle": "2023-08-18T07:07:30.535405Z",
     "shell.execute_reply": "2023-08-18T07:07:30.534582Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "# from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0458ec",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "## [**下载和预处理数据集**]\n",
    "\n",
    "首先，下载一个由[Tatoeba项目的双语句子对](http://www.manythings.org/anki/)\n",
    "组成的“英－法”数据集，数据集中的每一行都是制表符分隔的文本序列对，\n",
    "序列对由英文文本序列和翻译后的法语文本序列组成。\n",
    "请注意，每个文本序列可以是一个句子，\n",
    "也可以是包含多个句子的一个段落。\n",
    "在这个将英语翻译成法语的机器翻译问题中，\n",
    "英语是*源语言*（source language），\n",
    "法语是*目标语言*（target language）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b8bdf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\n",
      "Hi.\tSalut !\n",
      "Run!\tCours !\n",
      "Run!\tCourez !\n",
      "Who?\tQui ?\n",
      "Wow!\tÇa alors !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import requests\n",
    "import zipfile\n",
    "import tarfile\n",
    "import hashlib\n",
    "from io import BytesIO\n",
    "\n",
    "#@save\n",
    "DATA_HUB = {}\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
    "\n",
    "DATA_HUB['fra-eng'] = (DATA_URL + 'fra-eng.zip',\n",
    "                       '94646ad1522d915e7b0f9296181140edcf86a4f5')\n",
    "\n",
    "def download(name, cache_dir=os.path.join('..', 'data')):  #@save\n",
    "    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名\"\"\"\n",
    "    assert name in DATA_HUB, f\"{name} 不存在于 {DATA_HUB}\"\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname  # 命中缓存\n",
    "    print(f'正在从{url}下载{fname}...')\n",
    "    r = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname\n",
    "\n",
    "def download_extract(name, folder=None):  #@save\n",
    "    \"\"\"下载并解压zip/tar文件\"\"\"\n",
    "    fname = download(name)\n",
    "    base_dir = os.path.dirname(fname)\n",
    "    data_dir, ext = os.path.splitext(fname)\n",
    "    if ext == '.zip':\n",
    "        fp = zipfile.ZipFile(fname, 'r')\n",
    "    elif ext in ('.tar', '.gz'):\n",
    "        fp = tarfile.open(fname, 'r')\n",
    "    else:\n",
    "        assert False, '只有zip/tar文件可以被解压缩'\n",
    "    fp.extractall(base_dir)\n",
    "    return os.path.join(base_dir, folder) if folder else data_dir\n",
    "\n",
    "#@save\n",
    "def read_data_nmt():\n",
    "    \"\"\"载入\"英语-法语\"数据集\"\"\"\n",
    "    data_dir = download_extract('fra-eng')\n",
    "    with open(os.path.join(data_dir, 'fra.txt'), 'r',\n",
    "             encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "# 测试代码\n",
    "raw_text = read_data_nmt()\n",
    "print(raw_text[:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3461d76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:30.539676Z",
     "iopub.status.busy": "2023-08-18T07:07:30.539042Z",
     "iopub.status.idle": "2023-08-18T07:07:30.809623Z",
     "shell.execute_reply": "2023-08-18T07:07:30.808727Z"
    },
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\n",
      "Hi.\tSalut !\n",
      "Run!\tCours !\n",
      "Run!\tCourez !\n",
      "Who?\tQui ?\n",
      "Wow!\tÇa alors !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #@save\n",
    "# d2l.DATA_HUB['fra-eng'] = (d2l.DATA_URL + 'fra-eng.zip',\n",
    "#                            '94646ad1522d915e7b0f9296181140edcf86a4f5')\n",
    "\n",
    "# #@save\n",
    "# def read_data_nmt():\n",
    "#     \"\"\"载入“英语－法语”数据集\"\"\"\n",
    "#     data_dir = d2l.download_extract('fra-eng')\n",
    "#     with open(os.path.join(data_dir, 'fra.txt'), 'r',\n",
    "#              encoding='utf-8') as f:\n",
    "#         return f.read()\n",
    "\n",
    "raw_text = read_data_nmt()\n",
    "print(raw_text[:75])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8c081f",
   "metadata": {
    "origin_pos": 7
   },
   "source": [
    "下载数据集后，原始文本数据需要经过[**几个预处理步骤**]。\n",
    "例如，我们用空格代替*不间断空格*（non-breaking space），\n",
    "使用小写字母替换大写字母，并在单词和标点符号之间插入空格。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "114c461d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:30.813835Z",
     "iopub.status.busy": "2023-08-18T07:07:30.813273Z",
     "iopub.status.idle": "2023-08-18T07:07:36.581927Z",
     "shell.execute_reply": "2023-08-18T07:07:36.580959Z"
    },
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go .\tva !\n",
      "hi .\tsalut !\n",
      "run !\tcours !\n",
      "run !\tcourez !\n",
      "who ?\tqui ?\n",
      "wow !\tça alors !\n"
     ]
    }
   ],
   "source": [
    "#@save\n",
    "def preprocess_nmt(text):\n",
    "    \"\"\"预处理“英语－法语”数据集\"\"\"\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(',.!?') and prev_char != ' '\n",
    "\n",
    "    # 使用空格替换不间断空格\n",
    "    # 使用小写字母替换大写字母\n",
    "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
    "    # 在单词和标点符号之间插入空格\n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
    "           for i, char in enumerate(text)]\n",
    "    return ''.join(out)\n",
    "\n",
    "text = preprocess_nmt(raw_text)\n",
    "print(text[:80])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4048187",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "## [**词元化**]\n",
    "\n",
    "与 :numref:`sec_language_model`中的字符级词元化不同，\n",
    "在机器翻译中，我们更喜欢单词级词元化\n",
    "（最先进的模型可能使用更高级的词元化技术）。\n",
    "下面的`tokenize_nmt`函数对前`num_examples`个文本序列对进行词元，\n",
    "其中每个词元要么是一个词，要么是一个标点符号。\n",
    "此函数返回两个词元列表：`source`和`target`：\n",
    "`source[i]`是源语言（这里是英语）第$i$个文本序列的词元列表，\n",
    "`target[i]`是目标语言（这里是法语）第$i$个文本序列的词元列表。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc08d1a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:36.585962Z",
     "iopub.status.busy": "2023-08-18T07:07:36.585396Z",
     "iopub.status.idle": "2023-08-18T07:07:37.431130Z",
     "shell.execute_reply": "2023-08-18T07:07:37.430360Z"
    },
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['go', '.'],\n",
       "  ['hi', '.'],\n",
       "  ['run', '!'],\n",
       "  ['run', '!'],\n",
       "  ['who', '?'],\n",
       "  ['wow', '!']],\n",
       " [['va', '!'],\n",
       "  ['salut', '!'],\n",
       "  ['cours', '!'],\n",
       "  ['courez', '!'],\n",
       "  ['qui', '?'],\n",
       "  ['ça', 'alors', '!']])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@save\n",
    "def tokenize_nmt(text, num_examples=None):\n",
    "    \"\"\"词元化“英语－法语”数据数据集\"\"\"\n",
    "    source, target = [], []\n",
    "    for i, line in enumerate(text.split('\\n')):\n",
    "        if num_examples and i > num_examples:\n",
    "            break\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            source.append(parts[0].split(' '))\n",
    "            target.append(parts[1].split(' '))\n",
    "    return source, target\n",
    "\n",
    "source, target = tokenize_nmt(text)\n",
    "source[:6], target[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ecec6",
   "metadata": {
    "origin_pos": 11
   },
   "source": [
    "让我们[**绘制每个文本序列所包含的词元数量的直方图**]。\n",
    "在这个简单的“英－法”数据集中，大多数文本序列的词元数量少于$20$个。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31b3aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_list_len_pair_hist(legend, xlabel, ylabel, xlist, ylist):\n",
    "    \"\"\"绘制列表长度对的直方图\"\"\"\n",
    "    # 设置图形大小\n",
    "    plt.figure(figsize=(3.5, 2.5))\n",
    "    \n",
    "    # 计算每个列表的长度\n",
    "    x_lengths = [len(l) for l in xlist]\n",
    "    y_lengths = [len(l) for l in ylist]\n",
    "    \n",
    "    # 绘制直方图\n",
    "    _, bins, patches = plt.hist([x_lengths, y_lengths], label=legend)\n",
    "    \n",
    "    # 为第二个数据集（target）的条形添加斜线填充\n",
    "    for patch in patches[1]:\n",
    "        patch.set_hatch('/')\n",
    "    \n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend(legend)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "118a08f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:37.436349Z",
     "iopub.status.busy": "2023-08-18T07:07:37.435794Z",
     "iopub.status.idle": "2023-08-18T07:07:37.726273Z",
     "shell.execute_reply": "2023-08-18T07:07:37.725467Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@save\n",
    "# def show_list_len_pair_hist(legend, xlabel, ylabel, xlist, ylist):\n",
    "#     \"\"\"绘制列表长度对的直方图\"\"\"\n",
    "#     d2l.set_figsize()\n",
    "#     _, _, patches = d2l.plt.hist(\n",
    "#         [[len(l) for l in xlist], [len(l) for l in ylist]])\n",
    "#     d2l.plt.xlabel(xlabel)\n",
    "#     d2l.plt.ylabel(ylabel)\n",
    "#     for patch in patches[1].patches:\n",
    "#         patch.set_hatch('/')\n",
    "#     d2l.plt.legend(legend)\n",
    "\n",
    "\n",
    "show_list_len_pair_hist(['source', 'target'], '# tokens per sequence',\n",
    "                        'count', source, target);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e67b14",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "## [**词表**]\n",
    "\n",
    "由于机器翻译数据集由语言对组成，\n",
    "因此我们可以分别为源语言和目标语言构建两个词表。\n",
    "使用单词级词元化时，词表大小将明显大于使用字符级词元化时的词表大小。\n",
    "为了缓解这一问题，这里我们将出现次数少于2次的低频率词元\n",
    "视为相同的未知（“&lt;unk&gt;”）词元。\n",
    "除此之外，我们还指定了额外的特定词元，\n",
    "例如在小批量时用于将序列填充到相同长度的填充词元（“&lt;pad&gt;”），\n",
    "以及序列的开始词元（“&lt;bos&gt;”）和结束词元（“&lt;eos&gt;”）。\n",
    "这些特殊词元在自然语言处理任务中比较常用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54286649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Vocab:  #@save\n",
    "    \"\"\"文本词表\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        # 按出现频率排序\n",
    "        counter = count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "        # 未知词元的索引为0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # 未知词元的索引为0\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs\n",
    "    \n",
    "def count_corpus(tokens):  #@save\n",
    "    \"\"\"统计词元的频率\"\"\"\n",
    "    # 这里的tokens是1D列表或2D列表\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # 将词元列表展平成一个列表\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1179a522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:37.732422Z",
     "iopub.status.busy": "2023-08-18T07:07:37.731864Z",
     "iopub.status.idle": "2023-08-18T07:07:37.957959Z",
     "shell.execute_reply": "2023-08-18T07:07:37.957157Z"
    },
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10012"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab = Vocab(source, min_freq=2,\n",
    "                      reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "len(src_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c91b5",
   "metadata": {
    "origin_pos": 15
   },
   "source": [
    "## 加载数据集\n",
    ":label:`subsec_mt_data_loading`\n",
    "\n",
    "回想一下，语言模型中的[**序列样本都有一个固定的长度**]，\n",
    "无论这个样本是一个句子的一部分还是跨越了多个句子的一个片断。\n",
    "这个固定长度是由 :numref:`sec_language_model`中的\n",
    "`num_steps`（时间步数或词元数量）参数指定的。\n",
    "在机器翻译中，每个样本都是由源和目标组成的文本序列对，\n",
    "其中的每个文本序列可能具有不同的长度。\n",
    "\n",
    "为了提高计算效率，我们仍然可以通过*截断*（truncation）和\n",
    "*填充*（padding）方式实现一次只处理一个小批量的文本序列。\n",
    "假设同一个小批量中的每个序列都应该具有相同的长度`num_steps`，\n",
    "那么如果文本序列的词元数目少于`num_steps`时，\n",
    "我们将继续在其末尾添加特定的“&lt;pad&gt;”词元，\n",
    "直到其长度达到`num_steps`；\n",
    "反之，我们将截断文本序列时，只取其前`num_steps` 个词元，\n",
    "并且丢弃剩余的词元。这样，每个文本序列将具有相同的长度，\n",
    "以便以相同形状的小批量进行加载。\n",
    "\n",
    "如前所述，下面的`truncate_pad`函数将(**截断或填充文本序列**)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42aa524a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:37.962377Z",
     "iopub.status.busy": "2023-08-18T07:07:37.961250Z",
     "iopub.status.idle": "2023-08-18T07:07:37.968643Z",
     "shell.execute_reply": "2023-08-18T07:07:37.967892Z"
    },
    "origin_pos": 16,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47, 4, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@save\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"截断或填充文本序列\"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]  # 截断\n",
    "    return line + [padding_token] * (num_steps - len(line))  # 填充\n",
    "\n",
    "truncate_pad(src_vocab[source[0]], 10, src_vocab['<pad>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974b660",
   "metadata": {
    "origin_pos": 17
   },
   "source": [
    "现在我们定义一个函数，可以将文本序列\n",
    "[**转换成小批量数据集用于训练**]。\n",
    "我们将特定的“&lt;eos&gt;”词元添加到所有序列的末尾，\n",
    "用于表示序列的结束。\n",
    "当模型通过一个词元接一个词元地生成序列进行预测时，\n",
    "生成的“&lt;eos&gt;”词元说明完成了序列输出工作。\n",
    "此外，我们还记录了每个文本序列的长度，\n",
    "统计长度时排除了填充词元，\n",
    "在稍后将要介绍的一些模型会需要这个长度信息。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db17050b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:37.973483Z",
     "iopub.status.busy": "2023-08-18T07:07:37.972873Z",
     "iopub.status.idle": "2023-08-18T07:07:37.978080Z",
     "shell.execute_reply": "2023-08-18T07:07:37.977330Z"
    },
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "def build_array_nmt(lines, vocab, num_steps):\n",
    "    \"\"\"将机器翻译的文本序列转换成小批量\"\"\"\n",
    "    lines = [vocab[l] for l in lines]\n",
    "    lines = [l + [vocab['<eos>']] for l in lines]\n",
    "    array = torch.tensor([truncate_pad(\n",
    "        l, num_steps, vocab['<pad>']) for l in lines])\n",
    "    valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
    "    return array, valid_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e2af67",
   "metadata": {
    "origin_pos": 19
   },
   "source": [
    "## [**训练模型**]\n",
    "\n",
    "最后，我们定义`load_data_nmt`函数来返回数据迭代器，\n",
    "以及源语言和目标语言的两种词表。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "651b8d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"构造一个PyTorch数据迭代器\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8addcc51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:37.982873Z",
     "iopub.status.busy": "2023-08-18T07:07:37.982349Z",
     "iopub.status.idle": "2023-08-18T07:07:37.988101Z",
     "shell.execute_reply": "2023-08-18T07:07:37.987357Z"
    },
    "origin_pos": 20,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "def load_data_nmt(batch_size, num_steps, num_examples=600):\n",
    "    \"\"\"返回翻译数据集的迭代器和词表\"\"\"\n",
    "    text = preprocess_nmt(read_data_nmt())\n",
    "    source, target = tokenize_nmt(text, num_examples)\n",
    "    src_vocab = Vocab(source, min_freq=2,\n",
    "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    tgt_vocab = Vocab(target, min_freq=2,\n",
    "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
    "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
    "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    data_iter = load_array(data_arrays, batch_size)\n",
    "    return data_iter, src_vocab, tgt_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afba4ea",
   "metadata": {
    "origin_pos": 21
   },
   "source": [
    "下面我们[**读出“英语－法语”数据集中的第一个小批量数据**]。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90df834d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:37.992732Z",
     "iopub.status.busy": "2023-08-18T07:07:37.992204Z",
     "iopub.status.idle": "2023-08-18T07:07:43.780428Z",
     "shell.execute_reply": "2023-08-18T07:07:43.779613Z"
    },
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[ 0, 12,  4,  3,  1,  1,  1,  1],\n",
      "        [ 6, 22,  4,  3,  1,  1,  1,  1]], dtype=torch.int32)\n",
      "X的有效长度: tensor([4, 4])\n",
      "Y: tensor([[ 0,  4,  3,  1,  1,  1,  1,  1],\n",
      "        [21, 25,  4,  3,  1,  1,  1,  1]], dtype=torch.int32)\n",
      "Y的有效长度: tensor([3, 4])\n"
     ]
    }
   ],
   "source": [
    "train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size=2, num_steps=8)\n",
    "for X, X_valid_len, Y, Y_valid_len in train_iter:\n",
    "    print('X:', X.type(torch.int32))\n",
    "    print('X的有效长度:', X_valid_len)\n",
    "    print('Y:', Y.type(torch.int32))\n",
    "    print('Y的有效长度:', Y_valid_len)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df773107",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "## 小结\n",
    "\n",
    "* 机器翻译指的是将文本序列从一种语言自动翻译成另一种语言。\n",
    "* 使用单词级词元化时的词表大小，将明显大于使用字符级词元化时的词表大小。为了缓解这一问题，我们可以将低频词元视为相同的未知词元。\n",
    "* 通过截断和填充文本序列，可以保证所有的文本序列都具有相同的长度，以便以小批量的方式加载。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 在`load_data_nmt`函数中尝试不同的`num_examples`参数值。这对源语言和目标语言的词表大小有何影响？\n",
    "1. 某些语言（例如中文和日语）的文本没有单词边界指示符（例如空格）。对于这种情况，单词级词元化仍然是个好主意吗？为什么？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439397fa",
   "metadata": {
    "origin_pos": 25,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/2776)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
