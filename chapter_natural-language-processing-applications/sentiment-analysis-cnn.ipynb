{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76c80cf7",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 情感分析：使用卷积神经网络\n",
    ":label:`sec_sentiment_cnn`\n",
    "\n",
    "在 :numref:`chap_cnn`中，我们探讨了使用二维卷积神经网络处理二维图像数据的机制，并将其应用于局部特征，如相邻像素。虽然卷积神经网络最初是为计算机视觉设计的，但它也被广泛用于自然语言处理。简单地说，只要将任何文本序列想象成一维图像即可。通过这种方式，一维卷积神经网络可以处理文本中的局部特征，例如$n$元语法。\n",
    "\n",
    "本节将使用*textCNN*模型来演示如何设计一个表示单个文本 :cite:`Kim.2014`的卷积神经网络架构。与 :numref:`fig_nlp-map-sa-rnn`中使用带有GloVe预训练的循环神经网络架构进行情感分析相比， :numref:`fig_nlp-map-sa-cnn`中唯一的区别在于架构的选择。\n",
    "\n",
    "![将GloVe放入卷积神经网络架构进行情感分析](../img/nlp-map-sa-cnn.svg)\n",
    ":label:`fig_nlp-map-sa-cnn`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d655bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import requests\n",
    "import zipfile\n",
    "import tarfile\n",
    "import hashlib\n",
    "from io import BytesIO\n",
    "\n",
    "#@save\n",
    "DATA_HUB = {}\n",
    "DATA_HUB['aclImdb'] = (\n",
    "    'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz',\n",
    "    '01ada507287d82875905620988597833ad4e0903')\n",
    "\n",
    "def download(name, cache_dir=os.path.join('..', 'data')):  #@save\n",
    "    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名\"\"\"\n",
    "    assert name in DATA_HUB, f\"{name} 不存在于 {DATA_HUB}\"\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname  # 命中缓存\n",
    "    print(f'正在从{url}下载{fname}...')\n",
    "    r = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname\n",
    "\n",
    "def download_extract(name, folder=None):  #@save\n",
    "    \"\"\"下载并解压zip/tar文件\"\"\"\n",
    "    fname = download(name)\n",
    "    base_dir = os.path.dirname(fname)\n",
    "    data_dir, ext = os.path.splitext(fname)\n",
    "    if ext == '.zip':\n",
    "        fp = zipfile.ZipFile(fname, 'r')\n",
    "    elif ext in ('.tar', '.gz'):\n",
    "        fp = tarfile.open(fname, 'r')\n",
    "    else:\n",
    "        assert False, '只有zip/tar文件可以被解压缩'\n",
    "    fp.extractall(base_dir)\n",
    "    return os.path.join(base_dir, folder) if folder else data_dir\n",
    "\n",
    "def read_imdb(data_dir, is_train):\n",
    "    \"\"\"读取IMDb评论数据集文本序列和标签\"\"\"\n",
    "    data, labels = [], []\n",
    "    for label in ('pos', 'neg'):\n",
    "        folder_name = os.path.join(data_dir, 'train' if is_train else 'test',\n",
    "                                   label)\n",
    "        for file in os.listdir(folder_name):\n",
    "            with open(os.path.join(folder_name, file), 'rb') as f:\n",
    "                review = f.read().decode('utf-8').replace('\\n', '')\n",
    "                data.append(review)\n",
    "                labels.append(1 if label == 'pos' else 0)\n",
    "    return data, labels\n",
    "\n",
    "def tokenize(lines, token='word'):  #@save\n",
    "    \"\"\"将文本行拆分为单词或字符词元\"\"\"\n",
    "    if token == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token == 'char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print('错误：未知词元类型：' + token)\n",
    "\n",
    "import collections\n",
    "import torch\n",
    "\n",
    "class Vocab:  #@save\n",
    "    \"\"\"文本词表\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        # 按出现频率排序\n",
    "        counter = count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "        # 未知词元的索引为0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # 未知词元的索引为0\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs\n",
    "    \n",
    "def count_corpus(tokens):  #@save\n",
    "    \"\"\"统计词元的频率\"\"\"\n",
    "    # 这里的tokens是1D列表或2D列表\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # 将词元列表展平成一个列表\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n",
    "\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"截断或填充文本序列\"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]  # 截断\n",
    "    return line + [padding_token] * (num_steps - len(line))  # 填充\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"构造一个PyTorch数据迭代器\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "def load_data_imdb(batch_size, num_steps=500):\n",
    "    \"\"\"返回数据迭代器和IMDb评论数据集的词表\"\"\"\n",
    "    data_dir = download_extract('aclImdb', 'aclImdb')\n",
    "    train_data = read_imdb(data_dir, True)\n",
    "    test_data = read_imdb(data_dir, False)\n",
    "    train_tokens = tokenize(train_data[0], token='word')\n",
    "    test_tokens = tokenize(test_data[0], token='word')\n",
    "    vocab = Vocab(train_tokens, min_freq=5)\n",
    "    train_features = torch.tensor([truncate_pad(\n",
    "        vocab[line], num_steps, vocab['<pad>']) for line in train_tokens])\n",
    "    test_features = torch.tensor([truncate_pad(\n",
    "        vocab[line], num_steps, vocab['<pad>']) for line in test_tokens])\n",
    "    train_iter = load_array((train_features, torch.tensor(train_data[1])),\n",
    "                                batch_size)\n",
    "    test_iter = load_array((test_features, torch.tensor(test_data[1])),\n",
    "                               batch_size,\n",
    "                               is_train=False)\n",
    "    return train_iter, test_iter, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5b05735",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:29.533507Z",
     "iopub.status.busy": "2023-08-18T06:56:29.532815Z",
     "iopub.status.idle": "2023-08-18T06:57:08.360556Z",
     "shell.execute_reply": "2023-08-18T06:57:08.359662Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# from d2l import torch as d2l\n",
    "\n",
    "batch_size = 64\n",
    "train_iter, test_iter, vocab = load_data_imdb(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfb806b",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "## 一维卷积\n",
    "\n",
    "在介绍该模型之前，让我们先看看一维卷积是如何工作的。请记住，这只是基于互相关运算的二维卷积的特例。\n",
    "\n",
    "![一维互相关运算。阴影部分是第一个输出元素以及用于输出计算的输入和核张量元素：$0\\times1+1\\times2=2$](../img/conv1d.svg)\n",
    ":label:`fig_conv1d`\n",
    "\n",
    "如 :numref:`fig_conv1d`中所示，在一维情况下，卷积窗口在输入张量上从左向右滑动。在滑动期间，卷积窗口中某个位置包含的输入子张量（例如， :numref:`fig_conv1d`中的$0$和$1$）和核张量（例如， :numref:`fig_conv1d`中的$1$和$2$）按元素相乘。这些乘法的总和在输出张量的相应位置给出单个标量值（例如， :numref:`fig_conv1d`中的$0\\times1+1\\times2=2$）。\n",
    "\n",
    "我们在下面的`corr1d`函数中实现了一维互相关。给定输入张量`X`和核张量`K`，它返回输出张量`Y`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06263d9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:57:08.364760Z",
     "iopub.status.busy": "2023-08-18T06:57:08.364177Z",
     "iopub.status.idle": "2023-08-18T06:57:08.369258Z",
     "shell.execute_reply": "2023-08-18T06:57:08.368473Z"
    },
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def corr1d(X, K):\n",
    "    w = K.shape[0]\n",
    "    Y = torch.zeros((X.shape[0] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        Y[i] = (X[i: i + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c34067",
   "metadata": {
    "origin_pos": 7
   },
   "source": [
    "我们可以从 :numref:`fig_conv1d`构造输入张量`X`和核张量`K`来验证上述一维互相关实现的输出。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f6357d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:57:08.372600Z",
     "iopub.status.busy": "2023-08-18T06:57:08.372159Z",
     "iopub.status.idle": "2023-08-18T06:57:08.399427Z",
     "shell.execute_reply": "2023-08-18T06:57:08.398684Z"
    },
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  5.,  8., 11., 14., 17.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, K = torch.tensor([0, 1, 2, 3, 4, 5, 6]), torch.tensor([1, 2])\n",
    "corr1d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd7511d",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "对于任何具有多个通道的一维输入，卷积核需要具有相同数量的输入通道。然后，对于每个通道，对输入的一维张量和卷积核的一维张量执行互相关运算，将所有通道上的结果相加以产生一维输出张量。 :numref:`fig_conv1d_channel`演示了具有3个输入通道的一维互相关操作。\n",
    "\n",
    "![具有3个输入通道的一维互相关运算。阴影部分是第一个输出元素以及用于输出计算的输入和核张量元素：$2\\times(-1)+3\\times(-3)+1\\times3+2\\times4+0\\times1+1\\times2=2$](../img/conv1d-channel.svg)\n",
    ":label:`fig_conv1d_channel`\n",
    "\n",
    "我们可以实现多个输入通道的一维互相关运算，并在 :numref:`fig_conv1d_channel`中验证结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab10c163",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:57:08.446606Z",
     "iopub.status.busy": "2023-08-18T06:57:08.446039Z",
     "iopub.status.idle": "2023-08-18T06:57:08.454551Z",
     "shell.execute_reply": "2023-08-18T06:57:08.453800Z"
    },
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  8., 14., 20., 26., 32.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corr1d_multi_in(X, K):\n",
    "    # 首先，遍历'X'和'K'的第0维（通道维）。然后，把它们加在一起\n",
    "    return sum(corr1d(x, k) for x, k in zip(X, K))\n",
    "\n",
    "X = torch.tensor([[0, 1, 2, 3, 4, 5, 6],\n",
    "              [1, 2, 3, 4, 5, 6, 7],\n",
    "              [2, 3, 4, 5, 6, 7, 8]])\n",
    "K = torch.tensor([[1, 2], [3, 4], [-1, -3]])\n",
    "corr1d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae59cc7",
   "metadata": {
    "origin_pos": 11
   },
   "source": [
    "注意，多输入通道的一维互相关等同于单输入通道的二维互相关。举例说明， :numref:`fig_conv1d_channel`中的多输入通道一维互相关的等价形式是 :numref:`fig_conv1d_2d`中的单输入通道二维互相关，其中卷积核的高度必须与输入张量的高度相同。\n",
    "\n",
    "![具有单个输入通道的二维互相关操作。阴影部分是第一个输出元素以及用于输出计算的输入和内核张量元素： $2\\times(-1)+3\\times(-3)+1\\times3+2\\times4+0\\times1+1\\times2=2$](../img/conv1d-2d.svg)\n",
    ":label:`fig_conv1d_2d`\n",
    "\n",
    " :numref:`fig_conv1d`和 :numref:`fig_conv1d_channel`中的输出都只有一个通道。与 :numref:`subsec_multi-output-channels`中描述的具有多个输出通道的二维卷积相同，我们也可以为一维卷积指定多个输出通道。\n",
    "\n",
    "## 最大时间汇聚层\n",
    "\n",
    "类似地，我们可以使用汇聚层从序列表示中提取最大值，作为跨时间步的最重要特征。textCNN中使用的*最大时间汇聚层*的工作原理类似于一维全局汇聚 :cite:`Collobert.Weston.Bottou.ea.2011`。对于每个通道在不同时间步存储值的多通道输入，每个通道的输出是该通道的最大值。请注意，最大时间汇聚允许在不同通道上使用不同数量的时间步。\n",
    "\n",
    "## textCNN模型\n",
    "\n",
    "使用一维卷积和最大时间汇聚，textCNN模型将单个预训练的词元表示作为输入，然后获得并转换用于下游应用的序列表示。\n",
    "\n",
    "对于具有由$d$维向量表示的$n$个词元的单个文本序列，输入张量的宽度、高度和通道数分别为$n$、$1$和$d$。textCNN模型将输入转换为输出，如下所示：\n",
    "\n",
    "1. 定义多个一维卷积核，并分别对输入执行卷积运算。具有不同宽度的卷积核可以捕获不同数目的相邻词元之间的局部特征。\n",
    "1. 在所有输出通道上执行最大时间汇聚层，然后将所有标量汇聚输出连结为向量。\n",
    "1. 使用全连接层将连结后的向量转换为输出类别。Dropout可以用来减少过拟合。\n",
    "\n",
    "![textCNN的模型架构](../img/textcnn.svg)\n",
    ":label:`fig_conv1d_textcnn`\n",
    "\n",
    " :numref:`fig_conv1d_textcnn`通过一个具体的例子说明了textCNN的模型架构。输入是具有11个词元的句子，其中每个词元由6维向量表示。因此，我们有一个宽度为11的6通道输入。定义两个宽度为2和4的一维卷积核，分别具有4个和5个输出通道。它们产生4个宽度为$11-2+1=10$的输出通道和5个宽度为$11-4+1=8$的输出通道。尽管这9个通道的宽度不同，但最大时间汇聚层给出了一个连结的9维向量，该向量最终被转换为用于二元情感预测的2维输出向量。\n",
    "\n",
    "### 定义模型\n",
    "\n",
    "我们在下面的类中实现textCNN模型。与 :numref:`sec_sentiment_rnn`的双向循环神经网络模型相比，除了用卷积层代替循环神经网络层外，我们还使用了两个嵌入层：一个是可训练权重，另一个是固定权重。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2e051a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:57:08.458036Z",
     "iopub.status.busy": "2023-08-18T06:57:08.457474Z",
     "iopub.status.idle": "2023-08-18T06:57:08.466575Z",
     "shell.execute_reply": "2023-08-18T06:57:08.465450Z"
    },
    "origin_pos": 13,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, kernel_sizes, num_channels,\n",
    "                 **kwargs):\n",
    "        super(TextCNN, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # 这个嵌入层不需要训练\n",
    "        self.constant_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.decoder = nn.Linear(sum(num_channels), 2)\n",
    "        # 最大时间汇聚层没有参数，因此可以共享此实例\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.relu = nn.ReLU()\n",
    "        # 创建多个一维卷积层\n",
    "        self.convs = nn.ModuleList()\n",
    "        for c, k in zip(num_channels, kernel_sizes):\n",
    "            self.convs.append(nn.Conv1d(2 * embed_size, c, k))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # 沿着向量维度将两个嵌入层连结起来，\n",
    "        # 每个嵌入层的输出形状都是（批量大小，词元数量，词元向量维度）连结起来\n",
    "        embeddings = torch.cat((\n",
    "            self.embedding(inputs), self.constant_embedding(inputs)), dim=2)\n",
    "        # 根据一维卷积层的输入格式，重新排列张量，以便通道作为第2维\n",
    "        embeddings = embeddings.permute(0, 2, 1)\n",
    "        # 每个一维卷积层在最大时间汇聚层合并后，获得的张量形状是（批量大小，通道数，1）\n",
    "        # 删除最后一个维度并沿通道维度连结\n",
    "        encoding = torch.cat([\n",
    "            torch.squeeze(self.relu(self.pool(conv(embeddings))), dim=-1)\n",
    "            for conv in self.convs], dim=1)\n",
    "        outputs = self.decoder(self.dropout(encoding))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdedc58",
   "metadata": {
    "origin_pos": 15
   },
   "source": [
    "让我们创建一个textCNN实例。它有3个卷积层，卷积核宽度分别为3、4和5，均有100个输出通道。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efbe2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_gpus():  #@save\n",
    "    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]\"\"\"\n",
    "    devices = [torch.device(f'cuda:{i}')\n",
    "             for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b263a464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:57:08.470313Z",
     "iopub.status.busy": "2023-08-18T06:57:08.469519Z",
     "iopub.status.idle": "2023-08-18T06:57:08.572337Z",
     "shell.execute_reply": "2023-08-18T06:57:08.571481Z"
    },
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "embed_size, kernel_sizes, nums_channels = 100, [3, 4, 5], [100, 100, 100]\n",
    "devices = try_all_gpus()\n",
    "net = TextCNN(len(vocab), embed_size, kernel_sizes, nums_channels)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) in (nn.Linear, nn.Conv1d):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "net.apply(init_weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8fe95d",
   "metadata": {
    "origin_pos": 19
   },
   "source": [
    "### 加载预训练词向量\n",
    "\n",
    "与 :numref:`sec_sentiment_rnn`相同，我们加载预训练的100维GloVe嵌入作为初始化的词元表示。这些词元表示（嵌入权重）在`embedding`中将被训练，在`constant_embedding`中将被固定。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a62b1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class TokenEmbedding:\n",
    "    \"\"\"GloVe嵌入\"\"\"\n",
    "    def __init__(self, embedding_name):\n",
    "        self.idx_to_token, self.idx_to_vec = self._load_embedding(\n",
    "            embedding_name)\n",
    "        self.unknown_idx = 0\n",
    "        self.token_to_idx = {token: idx for idx, token in\n",
    "                             enumerate(self.idx_to_token)}\n",
    "\n",
    "    def _load_embedding(self, embedding_name):\n",
    "        idx_to_token, idx_to_vec = ['<unk>'], []\n",
    "        data_dir = download_extract(embedding_name)\n",
    "        # GloVe网站：https://nlp.stanford.edu/projects/glove/\n",
    "        # fastText网站：https://fasttext.cc/\n",
    "        with open(os.path.join(data_dir, 'vec.txt'), 'r') as f:\n",
    "            for line in f:\n",
    "                elems = line.rstrip().split(' ')\n",
    "                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
    "                # 跳过标题信息，例如fastText中的首行\n",
    "                if len(elems) > 1:\n",
    "                    idx_to_token.append(token)\n",
    "                    idx_to_vec.append(elems)\n",
    "        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n",
    "        return idx_to_token, torch.tensor(idx_to_vec)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        indices = [self.token_to_idx.get(token, self.unknown_idx)\n",
    "                   for token in tokens]\n",
    "        vecs = self.idx_to_vec[torch.tensor(indices)]\n",
    "        return vecs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3926166b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:57:08.576318Z",
     "iopub.status.busy": "2023-08-18T06:57:08.575732Z",
     "iopub.status.idle": "2023-08-18T06:57:35.120291Z",
     "shell.execute_reply": "2023-08-18T06:57:35.119200Z"
    },
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "DATA_HUB = {}\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
    "\n",
    "#@save\n",
    "DATA_HUB['glove.6b.100d'] = (DATA_URL + 'glove.6B.100d.zip',\n",
    "                                 'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a')\n",
    "\n",
    "glove_embedding = TokenEmbedding('glove.6b.100d')\n",
    "embeds = glove_embedding[vocab.idx_to_token]\n",
    "net.embedding.weight.data.copy_(embeds)\n",
    "net.constant_embedding.weight.data.copy_(embeds)\n",
    "net.constant_embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7069d13",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "### 训练和评估模型\n",
    "\n",
    "现在我们可以训练textCNN模型进行情感分析。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8da53fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_gpus():  #@save\n",
    "    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]\"\"\"\n",
    "    devices = [torch.device(f'cuda:{i}')\n",
    "             for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class Timer:  #@save\n",
    "    \"\"\"记录多次运行时间\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"启动计时器\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"停止计时器并将时间记录在列表中\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"返回平均时间\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"返回时间总和\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"返回累计时间\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist()\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "class Animator:  #@save\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        \n",
    "        # 替换 d2l.use_svg_display()\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.rcParams['figure.figsize'] = figsize\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # 替换 d2l.set_axes，使用 lambda 函数直接配置参数\n",
    "        self.config_axes = lambda: self._set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def _set_axes(self, ax, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "        \"\"\"设置坐标轴标签、范围和比例\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        # 设置坐标轴标签\n",
    "        if xlabel:\n",
    "            ax.set_xlabel(xlabel)\n",
    "        if ylabel:\n",
    "            ax.set_ylabel(ylabel)\n",
    "        # 设置坐标轴范围\n",
    "        if xlim:\n",
    "            ax.set_xlim(xlim)\n",
    "        if ylim:\n",
    "            ax.set_ylim(ylim)\n",
    "        # 设置坐标轴比例\n",
    "        if xscale:\n",
    "            ax.set_xscale(xscale)\n",
    "        if yscale:\n",
    "            ax.set_yscale(yscale)\n",
    "        # 设置图例\n",
    "        if legend:\n",
    "            ax.legend(legend)\n",
    "        # 添加网格\n",
    "        ax.grid(True)\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "class Accumulator:  #@save\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def accuracy(y_hat, y):  #@save\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "def train_batch_ch13(net, X, y, loss, trainer, devices):\n",
    "    \"\"\"用多GPU进行小批量训练\"\"\"\n",
    "    if isinstance(X, list):\n",
    "        # 微调BERT中所需\n",
    "        X = [x.to(devices[0]) for x in X]\n",
    "    else:\n",
    "        X = X.to(devices[0])\n",
    "    y = y.to(devices[0])\n",
    "    net.train()\n",
    "    trainer.zero_grad()\n",
    "    pred = net(X)\n",
    "    l = loss(pred, y)\n",
    "    l.sum().backward()\n",
    "    trainer.step()\n",
    "    train_loss_sum = l.sum()\n",
    "    train_acc_sum = accuracy(pred, y)\n",
    "    return train_loss_sum, train_acc_sum\n",
    "\n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None): #@save\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # 正确预测的数量，总预测的数量\n",
    "    metric = Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # BERT微调所需的（之后将介绍）\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "#@save\n",
    "def train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,\n",
    "               devices=try_all_gpus()):\n",
    "    \"\"\"用多GPU进行模型训练\"\"\"\n",
    "    timer, num_batches = Timer(), len(train_iter)\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1],\n",
    "                            legend=['train loss', 'train acc', 'test acc'])\n",
    "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    for epoch in range(num_epochs):\n",
    "        # 4个维度：储存训练损失，训练准确度，实例数，特点数\n",
    "        metric = Accumulator(4)\n",
    "        for i, (features, labels) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            l, acc = train_batch_ch13(\n",
    "                net, features, labels, loss, trainer, devices)\n",
    "            metric.add(l, acc, labels.shape[0], labels.numel())\n",
    "            timer.stop()\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (metric[0] / metric[2], metric[1] / metric[3],\n",
    "                              None))\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss {metric[0] / metric[2]:.3f}, train acc '\n",
    "          f'{metric[1] / metric[3]:.3f}, test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on '\n",
    "          f'{str(devices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9538271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:57:35.126378Z",
     "iopub.status.busy": "2023-08-18T06:57:35.125783Z",
     "iopub.status.idle": "2023-08-18T06:58:21.371973Z",
     "shell.execute_reply": "2023-08-18T06:58:21.371119Z"
    },
    "origin_pos": 25,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.063, train acc 0.980, test acc 0.876\n",
      "233.3 examples/sec on [device(type='cpu')]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6231a050",
   "metadata": {
    "origin_pos": 27
   },
   "source": [
    "下面，我们使用训练好的模型来预测两个简单句子的情感。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4c1f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i=0):  #@save\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def predict_sentiment(net, vocab, sequence):\n",
    "    \"\"\"预测文本序列的情感\"\"\"\n",
    "    sequence = torch.tensor(vocab[sequence.split()], device=try_gpu())\n",
    "    label = torch.argmax(net(sequence.reshape(1, -1)), dim=1)\n",
    "    return 'positive' if label == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54bb830a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:58:21.375835Z",
     "iopub.status.busy": "2023-08-18T06:58:21.375244Z",
     "iopub.status.idle": "2023-08-18T06:58:21.383027Z",
     "shell.execute_reply": "2023-08-18T06:58:21.382227Z"
    },
    "origin_pos": 28,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "802c833b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:58:21.386663Z",
     "iopub.status.busy": "2023-08-18T06:58:21.386099Z",
     "iopub.status.idle": "2023-08-18T06:58:21.393226Z",
     "shell.execute_reply": "2023-08-18T06:58:21.392391Z"
    },
    "origin_pos": 29,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbca6d3",
   "metadata": {
    "origin_pos": 30
   },
   "source": [
    "## 小结\n",
    "\n",
    "* 一维卷积神经网络可以处理文本中的局部特征，例如$n$元语法。\n",
    "* 多输入通道的一维互相关等价于单输入通道的二维互相关。\n",
    "* 最大时间汇聚层允许在不同通道上使用不同数量的时间步长。\n",
    "* textCNN模型使用一维卷积层和最大时间汇聚层将单个词元表示转换为下游应用输出。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 调整超参数，并比较 :numref:`sec_sentiment_rnn`中用于情感分析的架构和本节中用于情感分析的架构，例如在分类精度和计算效率方面。\n",
    "1. 请试着用 :numref:`sec_sentiment_rnn`练习中介绍的方法进一步提高模型的分类精度。\n",
    "1. 在输入表示中添加位置编码。它是否提高了分类的精度？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c40650d",
   "metadata": {
    "origin_pos": 32,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/5720)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
