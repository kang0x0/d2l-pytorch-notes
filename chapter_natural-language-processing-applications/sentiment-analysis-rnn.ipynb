{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc862d32",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 情感分析：使用循环神经网络\n",
    ":label:`sec_sentiment_rnn`\n",
    "\n",
    "与词相似度和类比任务一样，我们也可以将预先训练的词向量应用于情感分析。由于 :numref:`sec_sentiment`中的IMDb评论数据集不是很大，使用在大规模语料库上预训练的文本表示可以减少模型的过拟合。作为 :numref:`fig_nlp-map-sa-rnn`中所示的具体示例，我们将使用预训练的GloVe模型来表示每个词元，并将这些词元表示送入多层双向循环神经网络以获得文本序列表示，该文本序列表示将被转换为情感分析输出 :cite:`Maas.Daly.Pham.ea.2011`。对于相同的下游应用，我们稍后将考虑不同的架构选择。\n",
    "\n",
    "![将GloVe送入基于循环神经网络的架构，用于情感分析](../img/nlp-map-sa-rnn.svg)\n",
    ":label:`fig_nlp-map-sa-rnn`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4527d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import requests\n",
    "import zipfile\n",
    "import tarfile\n",
    "import hashlib\n",
    "from io import BytesIO\n",
    "\n",
    "#@save\n",
    "DATA_HUB = {}\n",
    "DATA_HUB['aclImdb'] = (\n",
    "    'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz',\n",
    "    '01ada507287d82875905620988597833ad4e0903')\n",
    "\n",
    "def download(name, cache_dir=os.path.join('..', 'data')):  #@save\n",
    "    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名\"\"\"\n",
    "    assert name in DATA_HUB, f\"{name} 不存在于 {DATA_HUB}\"\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname  # 命中缓存\n",
    "    print(f'正在从{url}下载{fname}...')\n",
    "    r = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname\n",
    "\n",
    "def download_extract(name, folder=None):  #@save\n",
    "    \"\"\"下载并解压zip/tar文件\"\"\"\n",
    "    fname = download(name)\n",
    "    base_dir = os.path.dirname(fname)\n",
    "    data_dir, ext = os.path.splitext(fname)\n",
    "    if ext == '.zip':\n",
    "        fp = zipfile.ZipFile(fname, 'r')\n",
    "    elif ext in ('.tar', '.gz'):\n",
    "        fp = tarfile.open(fname, 'r')\n",
    "    else:\n",
    "        assert False, '只有zip/tar文件可以被解压缩'\n",
    "    fp.extractall(base_dir)\n",
    "    return os.path.join(base_dir, folder) if folder else data_dir\n",
    "\n",
    "def read_imdb(data_dir, is_train):\n",
    "    \"\"\"读取IMDb评论数据集文本序列和标签\"\"\"\n",
    "    data, labels = [], []\n",
    "    for label in ('pos', 'neg'):\n",
    "        folder_name = os.path.join(data_dir, 'train' if is_train else 'test',\n",
    "                                   label)\n",
    "        for file in os.listdir(folder_name):\n",
    "            with open(os.path.join(folder_name, file), 'rb') as f:\n",
    "                review = f.read().decode('utf-8').replace('\\n', '')\n",
    "                data.append(review)\n",
    "                labels.append(1 if label == 'pos' else 0)\n",
    "    return data, labels\n",
    "\n",
    "def tokenize(lines, token='word'):  #@save\n",
    "    \"\"\"将文本行拆分为单词或字符词元\"\"\"\n",
    "    if token == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token == 'char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print('错误：未知词元类型：' + token)\n",
    "\n",
    "import collections\n",
    "import torch\n",
    "\n",
    "class Vocab:  #@save\n",
    "    \"\"\"文本词表\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        # 按出现频率排序\n",
    "        counter = count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "        # 未知词元的索引为0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # 未知词元的索引为0\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs\n",
    "    \n",
    "def count_corpus(tokens):  #@save\n",
    "    \"\"\"统计词元的频率\"\"\"\n",
    "    # 这里的tokens是1D列表或2D列表\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # 将词元列表展平成一个列表\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n",
    "\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"截断或填充文本序列\"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]  # 截断\n",
    "    return line + [padding_token] * (num_steps - len(line))  # 填充\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"构造一个PyTorch数据迭代器\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "def load_data_imdb(batch_size, num_steps=500):\n",
    "    \"\"\"返回数据迭代器和IMDb评论数据集的词表\"\"\"\n",
    "    data_dir = download_extract('aclImdb', 'aclImdb')\n",
    "    train_data = read_imdb(data_dir, True)\n",
    "    test_data = read_imdb(data_dir, False)\n",
    "    train_tokens = tokenize(train_data[0], token='word')\n",
    "    test_tokens = tokenize(test_data[0], token='word')\n",
    "    vocab = Vocab(train_tokens, min_freq=5)\n",
    "    train_features = torch.tensor([truncate_pad(\n",
    "        vocab[line], num_steps, vocab['<pad>']) for line in train_tokens])\n",
    "    test_features = torch.tensor([truncate_pad(\n",
    "        vocab[line], num_steps, vocab['<pad>']) for line in test_tokens])\n",
    "    train_iter = load_array((train_features, torch.tensor(train_data[1])),\n",
    "                                batch_size)\n",
    "    test_iter = load_array((test_features, torch.tensor(test_data[1])),\n",
    "                               batch_size,\n",
    "                               is_train=False)\n",
    "    return train_iter, test_iter, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39fc24d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:05.652082Z",
     "iopub.status.busy": "2023-08-18T07:05:05.651505Z",
     "iopub.status.idle": "2023-08-18T07:05:40.292912Z",
     "shell.execute_reply": "2023-08-18T07:05:40.291561Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# from d2l import torch as d2l\n",
    "\n",
    "batch_size = 64\n",
    "train_iter, test_iter, vocab = load_data_imdb(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e77029",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "## 使用循环神经网络表示单个文本\n",
    "\n",
    "在文本分类任务（如情感分析）中，可变长度的文本序列将被转换为固定长度的类别。在下面的`BiRNN`类中，虽然文本序列的每个词元经由嵌入层（`self.embedding`）获得其单独的预训练GloVe表示，但是整个序列由双向循环神经网络（`self.encoder`）编码。更具体地说，双向长短期记忆网络在初始和最终时间步的隐状态（在最后一层）被连结起来作为文本序列的表示。然后，通过一个具有两个输出（“积极”和“消极”）的全连接层（`self.decoder`），将此单一文本表示转换为输出类别。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744f39e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:40.299184Z",
     "iopub.status.busy": "2023-08-18T07:05:40.298245Z",
     "iopub.status.idle": "2023-08-18T07:05:40.309337Z",
     "shell.execute_reply": "2023-08-18T07:05:40.307994Z"
    },
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens,\n",
    "                 num_layers, **kwargs):\n",
    "        super(BiRNN, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # 将bidirectional设置为True以获取双向循环神经网络\n",
    "        self.encoder = nn.LSTM(embed_size, num_hiddens, num_layers=num_layers,\n",
    "                                bidirectional=True)\n",
    "        self.decoder = nn.Linear(4 * num_hiddens, 2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs的形状是（批量大小，时间步数）\n",
    "        # 因为长短期记忆网络要求其输入的第一个维度是时间维，\n",
    "        # 所以在获得词元表示之前，输入会被转置。\n",
    "        # 输出形状为（时间步数，批量大小，词向量维度）\n",
    "        embeddings = self.embedding(inputs.T)\n",
    "        self.encoder.flatten_parameters()\n",
    "        # 返回上一个隐藏层在不同时间步的隐状态，\n",
    "        # outputs的形状是（时间步数，批量大小，2*隐藏单元数）\n",
    "        outputs, _ = self.encoder(embeddings)\n",
    "        # 连结初始和最终时间步的隐状态，作为全连接层的输入，\n",
    "        # 其形状为（批量大小，4*隐藏单元数）\n",
    "        encoding = torch.cat((outputs[0], outputs[-1]), dim=1)\n",
    "        outs = self.decoder(encoding)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98329015",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "让我们构造一个具有两个隐藏层的双向循环神经网络来表示单个文本以进行情感分析。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de17f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_gpus():  #@save\n",
    "    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]\"\"\"\n",
    "    devices = [torch.device(f'cuda:{i}')\n",
    "             for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8b2c0f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:40.314032Z",
     "iopub.status.busy": "2023-08-18T07:05:40.313553Z",
     "iopub.status.idle": "2023-08-18T07:05:40.403532Z",
     "shell.execute_reply": "2023-08-18T07:05:40.402355Z"
    },
    "origin_pos": 9,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, num_layers = 100, 100, 2\n",
    "devices = try_all_gpus()\n",
    "net = BiRNN(len(vocab), embed_size, num_hiddens, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8215de71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:40.408642Z",
     "iopub.status.busy": "2023-08-18T07:05:40.407984Z",
     "iopub.status.idle": "2023-08-18T07:05:40.420400Z",
     "shell.execute_reply": "2023-08-18T07:05:40.419330Z"
    },
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    if type(m) == nn.LSTM:\n",
    "        for param in m._flat_weights_names:\n",
    "            if \"weight\" in param:\n",
    "                nn.init.xavier_uniform_(m._parameters[param])\n",
    "net.apply(init_weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b604a0d",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "## 加载预训练的词向量\n",
    "\n",
    "下面，我们为词表中的单词加载预训练的100维（需要与`embed_size`一致）的GloVe嵌入。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f88cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class TokenEmbedding:\n",
    "    \"\"\"GloVe嵌入\"\"\"\n",
    "    def __init__(self, embedding_name):\n",
    "        self.idx_to_token, self.idx_to_vec = self._load_embedding(\n",
    "            embedding_name)\n",
    "        self.unknown_idx = 0\n",
    "        self.token_to_idx = {token: idx for idx, token in\n",
    "                             enumerate(self.idx_to_token)}\n",
    "\n",
    "    def _load_embedding(self, embedding_name):\n",
    "        idx_to_token, idx_to_vec = ['<unk>'], []\n",
    "        data_dir = download_extract(embedding_name)\n",
    "        # GloVe网站：https://nlp.stanford.edu/projects/glove/\n",
    "        # fastText网站：https://fasttext.cc/\n",
    "        with open(os.path.join(data_dir, 'vec.txt'), 'r') as f:\n",
    "            for line in f:\n",
    "                elems = line.rstrip().split(' ')\n",
    "                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
    "                # 跳过标题信息，例如fastText中的首行\n",
    "                if len(elems) > 1:\n",
    "                    idx_to_token.append(token)\n",
    "                    idx_to_vec.append(elems)\n",
    "        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n",
    "        return idx_to_token, torch.tensor(idx_to_vec)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        indices = [self.token_to_idx.get(token, self.unknown_idx)\n",
    "                   for token in tokens]\n",
    "        vecs = self.idx_to_vec[torch.tensor(indices)]\n",
    "        return vecs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50827d9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:05:40.424891Z",
     "iopub.status.busy": "2023-08-18T07:05:40.424223Z",
     "iopub.status.idle": "2023-08-18T07:06:05.190359Z",
     "shell.execute_reply": "2023-08-18T07:06:05.188903Z"
    },
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从http://d2l-data.s3-accelerate.amazonaws.com/glove.6B.100d.zip下载..\\data\\glove.6B.100d.zip...\n"
     ]
    }
   ],
   "source": [
    "DATA_HUB = {}\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
    "\n",
    "#@save\n",
    "DATA_HUB['glove.6b.100d'] = (DATA_URL + 'glove.6B.100d.zip',\n",
    "                                 'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a')\n",
    "\n",
    "glove_embedding = TokenEmbedding('glove.6b.100d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f48ad7",
   "metadata": {
    "origin_pos": 15
   },
   "source": [
    "打印词表中所有词元向量的形状。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ca5c11f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:05.196382Z",
     "iopub.status.busy": "2023-08-18T07:06:05.195537Z",
     "iopub.status.idle": "2023-08-18T07:06:05.260164Z",
     "shell.execute_reply": "2023-08-18T07:06:05.258848Z"
    },
    "origin_pos": 16,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49346, 100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = glove_embedding[vocab.idx_to_token]\n",
    "embeds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8621b1b",
   "metadata": {
    "origin_pos": 17
   },
   "source": [
    "我们使用这些预训练的词向量来表示评论中的词元，并且在训练期间不要更新这些向量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f86f2b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:05.267876Z",
     "iopub.status.busy": "2023-08-18T07:06:05.266887Z",
     "iopub.status.idle": "2023-08-18T07:06:05.276563Z",
     "shell.execute_reply": "2023-08-18T07:06:05.275272Z"
    },
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "net.embedding.weight.data.copy_(embeds)\n",
    "net.embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9d2712",
   "metadata": {
    "origin_pos": 21
   },
   "source": [
    "## 训练和评估模型\n",
    "\n",
    "现在我们可以训练双向循环神经网络进行情感分析。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22b995b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_gpus():  #@save\n",
    "    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]\"\"\"\n",
    "    devices = [torch.device(f'cuda:{i}')\n",
    "             for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class Timer:  #@save\n",
    "    \"\"\"记录多次运行时间\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"启动计时器\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"停止计时器并将时间记录在列表中\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"返回平均时间\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"返回时间总和\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"返回累计时间\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist()\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "class Animator:  #@save\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        \n",
    "        # 替换 d2l.use_svg_display()\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.rcParams['figure.figsize'] = figsize\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # 替换 d2l.set_axes，使用 lambda 函数直接配置参数\n",
    "        self.config_axes = lambda: self._set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def _set_axes(self, ax, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "        \"\"\"设置坐标轴标签、范围和比例\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        # 设置坐标轴标签\n",
    "        if xlabel:\n",
    "            ax.set_xlabel(xlabel)\n",
    "        if ylabel:\n",
    "            ax.set_ylabel(ylabel)\n",
    "        # 设置坐标轴范围\n",
    "        if xlim:\n",
    "            ax.set_xlim(xlim)\n",
    "        if ylim:\n",
    "            ax.set_ylim(ylim)\n",
    "        # 设置坐标轴比例\n",
    "        if xscale:\n",
    "            ax.set_xscale(xscale)\n",
    "        if yscale:\n",
    "            ax.set_yscale(yscale)\n",
    "        # 设置图例\n",
    "        if legend:\n",
    "            ax.legend(legend)\n",
    "        # 添加网格\n",
    "        ax.grid(True)\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "class Accumulator:  #@save\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def accuracy(y_hat, y):  #@save\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "def train_batch_ch13(net, X, y, loss, trainer, devices):\n",
    "    \"\"\"用多GPU进行小批量训练\"\"\"\n",
    "    if isinstance(X, list):\n",
    "        # 微调BERT中所需\n",
    "        X = [x.to(devices[0]) for x in X]\n",
    "    else:\n",
    "        X = X.to(devices[0])\n",
    "    y = y.to(devices[0])\n",
    "    net.train()\n",
    "    trainer.zero_grad()\n",
    "    pred = net(X)\n",
    "    l = loss(pred, y)\n",
    "    l.sum().backward()\n",
    "    trainer.step()\n",
    "    train_loss_sum = l.sum()\n",
    "    train_acc_sum = accuracy(pred, y)\n",
    "    return train_loss_sum, train_acc_sum\n",
    "\n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None): #@save\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # 正确预测的数量，总预测的数量\n",
    "    metric = Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # BERT微调所需的（之后将介绍）\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "#@save\n",
    "def train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,\n",
    "               devices=try_all_gpus()):\n",
    "    \"\"\"用多GPU进行模型训练\"\"\"\n",
    "    timer, num_batches = Timer(), len(train_iter)\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1],\n",
    "                            legend=['train loss', 'train acc', 'test acc'])\n",
    "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    for epoch in range(num_epochs):\n",
    "        # 4个维度：储存训练损失，训练准确度，实例数，特点数\n",
    "        metric = Accumulator(4)\n",
    "        for i, (features, labels) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            l, acc = train_batch_ch13(\n",
    "                net, features, labels, loss, trainer, devices)\n",
    "            metric.add(l, acc, labels.shape[0], labels.numel())\n",
    "            timer.stop()\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (metric[0] / metric[2], metric[1] / metric[3],\n",
    "                              None))\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss {metric[0] / metric[2]:.3f}, train acc '\n",
    "          f'{metric[1] / metric[3]:.3f}, test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on '\n",
    "          f'{str(devices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e98aa66f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:06:05.282869Z",
     "iopub.status.busy": "2023-08-18T07:06:05.281955Z",
     "iopub.status.idle": "2023-08-18T07:07:16.147782Z",
     "shell.execute_reply": "2023-08-18T07:07:16.146887Z"
    },
    "origin_pos": 23,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m trainer = torch.optim.Adam(net.parameters(), lr=lr)\n\u001b[32m      3\u001b[39m loss = nn.CrossEntropyLoss(reduction=\u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mtrain_ch13\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 177\u001b[39m, in \u001b[36mtrain_ch13\u001b[39m\u001b[34m(net, train_iter, test_iter, loss, trainer, num_epochs, devices)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (features, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_iter):\n\u001b[32m    176\u001b[39m     timer.start()\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     l, acc = \u001b[43mtrain_batch_ch13\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m     metric.add(l, acc, labels.shape[\u001b[32m0\u001b[39m], labels.numel())\n\u001b[32m    180\u001b[39m     timer.stop()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 139\u001b[39m, in \u001b[36mtrain_batch_ch13\u001b[39m\u001b[34m(net, X, y, loss, trainer, devices)\u001b[39m\n\u001b[32m    137\u001b[39m pred = net(X)\n\u001b[32m    138\u001b[39m l = loss(pred, y)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[43ml\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m trainer.step()\n\u001b[32m    141\u001b[39m train_loss_sum = l.sum()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\d2l-zh\\pytorch\\.venv\\Lib\\site-packages\\torch\\_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\d2l-zh\\pytorch\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\d2l-zh\\pytorch\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 5\n",
    "trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,\n",
    "    devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd858123",
   "metadata": {
    "origin_pos": 25
   },
   "source": [
    "我们定义以下函数来使用训练好的模型`net`预测文本序列的情感。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc81f3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i=0):  #@save\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc5f0ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:16.151578Z",
     "iopub.status.busy": "2023-08-18T07:07:16.150980Z",
     "iopub.status.idle": "2023-08-18T07:07:16.156295Z",
     "shell.execute_reply": "2023-08-18T07:07:16.155474Z"
    },
    "origin_pos": 27,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "def predict_sentiment(net, vocab, sequence):\n",
    "    \"\"\"预测文本序列的情感\"\"\"\n",
    "    sequence = torch.tensor(vocab[sequence.split()], device=try_gpu())\n",
    "    label = torch.argmax(net(sequence.reshape(1, -1)), dim=1)\n",
    "    return 'positive' if label == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532d7858",
   "metadata": {
    "origin_pos": 29
   },
   "source": [
    "最后，让我们使用训练好的模型对两个简单的句子进行情感预测。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41cb5e96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:16.160003Z",
     "iopub.status.busy": "2023-08-18T07:07:16.159129Z",
     "iopub.status.idle": "2023-08-18T07:07:16.167838Z",
     "shell.execute_reply": "2023-08-18T07:07:16.166727Z"
    },
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84350bf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:07:16.171422Z",
     "iopub.status.busy": "2023-08-18T07:07:16.170827Z",
     "iopub.status.idle": "2023-08-18T07:07:16.177666Z",
     "shell.execute_reply": "2023-08-18T07:07:16.176801Z"
    },
    "origin_pos": 31,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13f4f0d",
   "metadata": {
    "origin_pos": 32
   },
   "source": [
    "## 小结\n",
    "\n",
    "* 预训练的词向量可以表示文本序列中的各个词元。\n",
    "* 双向循环神经网络可以表示文本序列。例如通过连结初始和最终时间步的隐状态，可以使用全连接的层将该单个文本表示转换为类别。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 增加迭代轮数可以提高训练和测试的准确性吗？调优其他超参数怎么样？\n",
    "1. 使用较大的预训练词向量，例如300维的GloVe嵌入。它是否提高了分类精度？\n",
    "1. 是否可以通过spaCy词元化来提高分类精度？需要安装Spacy（`pip install spacy`）和英语语言包（`python -m spacy download en`）。在代码中，首先导入Spacy（`import spacy`）。然后，加载Spacy英语软件包（`spacy_en = spacy.load('en')`）。最后，定义函数`def tokenizer(text): return [tok.text for tok in spacy_en.tokenizer(text)]`并替换原来的`tokenizer`函数。请注意GloVe和spaCy中短语标记的不同形式。例如，短语标记“new york”在GloVe中的形式是“new-york”，而在spaCy词元化之后的形式是“new york”。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d148e971",
   "metadata": {
    "origin_pos": 34,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/5724)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
