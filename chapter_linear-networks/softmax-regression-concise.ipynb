{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1464cc27",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# softmax回归的简洁实现\n",
    ":label:`sec_softmax_concise`\n",
    "\n",
    "在 :numref:`sec_linear_concise`中，\n",
    "我们发现(**通过深度学习框架的高级API能够使实现**)\n",
    "(~~softmax~~)\n",
    "线性(**回归变得更加容易**)。\n",
    "同样，通过深度学习框架的高级API也能更方便地实现softmax回归模型。\n",
    "本节如在 :numref:`sec_softmax_scratch`中一样，\n",
    "继续使用Fashion-MNIST数据集，并保持批量大小为256。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f81001f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:57:16.212083Z",
     "iopub.status.busy": "2023-08-18T06:57:16.211369Z",
     "iopub.status.idle": "2023-08-18T06:57:18.227520Z",
     "shell.execute_reply": "2023-08-18T06:57:18.226314Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92e395a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:57:18.231806Z",
     "iopub.status.busy": "2023-08-18T06:57:18.230933Z",
     "iopub.status.idle": "2023-08-18T06:57:18.337514Z",
     "shell.execute_reply": "2023-08-18T06:57:18.336238Z"
    },
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "\n",
    "def get_dataloader_workers():  #@save\n",
    "    \"\"\"使用4个进程来读取数据\"\"\"\n",
    "    return 4\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None):  #@save\n",
    "    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=get_dataloader_workers()),\n",
    "            data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=get_dataloader_workers()))\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2b9199",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "## 初始化模型参数\n",
    "\n",
    "如我们在 :numref:`sec_softmax`所述，\n",
    "[**softmax回归的输出层是一个全连接层**]。\n",
    "因此，为了实现我们的模型，\n",
    "我们只需在`Sequential`中添加一个带有10个输出的全连接层。\n",
    "同样，在这里`Sequential`并不是必要的，\n",
    "但它是实现深度模型的基础。\n",
    "我们仍然以均值0和标准差0.01随机初始化权重。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebf37311",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:57:18.342288Z",
     "iopub.status.busy": "2023-08-18T06:57:18.342007Z",
     "iopub.status.idle": "2023-08-18T06:57:18.349431Z",
     "shell.execute_reply": "2023-08-18T06:57:18.348277Z"
    },
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "# PyTorch不会隐式地调整输入的形状。因此，\n",
    "# 我们在线性层前定义了展平层（flatten），来调整网络输入的形状\n",
    "net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "net.apply(init_weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a6c3c5",
   "metadata": {
    "origin_pos": 11
   },
   "source": [
    "## 重新审视Softmax的实现\n",
    ":label:`subsec_softmax-implementation-revisited`\n",
    "\n",
    "在前面 :numref:`sec_softmax_scratch`的例子中，\n",
    "我们计算了模型的输出，然后将此输出送入交叉熵损失。\n",
    "从数学上讲，这是一件完全合理的事情。\n",
    "然而，从计算角度来看，指数可能会造成数值稳定性问题。\n",
    "\n",
    "回想一下，softmax函数$\\hat y_j = \\frac{\\exp(o_j)}{\\sum_k \\exp(o_k)}$，\n",
    "其中$\\hat y_j$是预测的概率分布。\n",
    "$o_j$是未规范化的预测$\\mathbf{o}$的第$j$个元素。\n",
    "如果$o_k$中的一些数值非常大，\n",
    "那么$\\exp(o_k)$可能大于数据类型容许的最大数字，即*上溢*（overflow）。\n",
    "这将使分母或分子变为`inf`（无穷大），\n",
    "最后得到的是0、`inf`或`nan`（不是数字）的$\\hat y_j$。\n",
    "在这些情况下，我们无法得到一个明确定义的交叉熵值。\n",
    "\n",
    "解决这个问题的一个技巧是：\n",
    "在继续softmax计算之前，先从所有$o_k$中减去$\\max(o_k)$。\n",
    "这里可以看到每个$o_k$按常数进行的移动不会改变softmax的返回值：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat y_j & =  \\frac{\\exp(o_j - \\max(o_k))\\exp(\\max(o_k))}{\\sum_k \\exp(o_k - \\max(o_k))\\exp(\\max(o_k))} \\\\\n",
    "& = \\frac{\\exp(o_j - \\max(o_k))}{\\sum_k \\exp(o_k - \\max(o_k))}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "在减法和规范化步骤之后，可能有些$o_j - \\max(o_k)$具有较大的负值。\n",
    "由于精度受限，$\\exp(o_j - \\max(o_k))$将有接近零的值，即*下溢*（underflow）。\n",
    "这些值可能会四舍五入为零，使$\\hat y_j$为零，\n",
    "并且使得$\\log(\\hat y_j)$的值为`-inf`。\n",
    "反向传播几步后，我们可能会发现自己面对一屏幕可怕的`nan`结果。\n",
    "\n",
    "尽管我们要计算指数函数，但我们最终在计算交叉熵损失时会取它们的对数。\n",
    "通过将softmax和交叉熵结合在一起，可以避免反向传播过程中可能会困扰我们的数值稳定性问题。\n",
    "如下面的等式所示，我们避免计算$\\exp(o_j - \\max(o_k))$，\n",
    "而可以直接使用$o_j - \\max(o_k)$，因为$\\log(\\exp(\\cdot))$被抵消了。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\log{(\\hat y_j)} & = \\log\\left( \\frac{\\exp(o_j - \\max(o_k))}{\\sum_k \\exp(o_k - \\max(o_k))}\\right) \\\\\n",
    "& = \\log{(\\exp(o_j - \\max(o_k)))}-\\log{\\left( \\sum_k \\exp(o_k - \\max(o_k)) \\right)} \\\\\n",
    "& = o_j - \\max(o_k) -\\log{\\left( \\sum_k \\exp(o_k - \\max(o_k)) \\right)}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "我们也希望保留传统的softmax函数，以备我们需要评估通过模型输出的概率。\n",
    "但是，我们没有将softmax概率传递到损失函数中，\n",
    "而是[**在交叉熵损失函数中传递未规范化的预测，并同时计算softmax及其对数**]，\n",
    "这是一种类似[\"LogSumExp技巧\"](https://en.wikipedia.org/wiki/LogSumExp)的聪明方式。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91c3ac45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:57:18.353684Z",
     "iopub.status.busy": "2023-08-18T06:57:18.353410Z",
     "iopub.status.idle": "2023-08-18T06:57:18.358187Z",
     "shell.execute_reply": "2023-08-18T06:57:18.357079Z"
    },
    "origin_pos": 13,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c347cec2",
   "metadata": {
    "origin_pos": 15
   },
   "source": [
    "## 优化算法\n",
    "\n",
    "在这里，我们(**使用学习率为0.1的小批量随机梯度下降作为优化算法**)。\n",
    "这与我们在线性回归例子中的相同，这说明了优化器的普适性。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4849ef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:57:18.362274Z",
     "iopub.status.busy": "2023-08-18T06:57:18.361998Z",
     "iopub.status.idle": "2023-08-18T06:57:18.366991Z",
     "shell.execute_reply": "2023-08-18T06:57:18.365798Z"
    },
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cf8941",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "## 训练\n",
    "\n",
    "接下来我们[**调用**] :numref:`sec_softmax_scratch`中(~~之前~~)\n",
    "(**定义的训练函数来训练模型**)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5acea90d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:57:18.371133Z",
     "iopub.status.busy": "2023-08-18T06:57:18.370849Z",
     "iopub.status.idle": "2023-08-18T06:58:00.716532Z",
     "shell.execute_reply": "2023-08-18T06:58:00.715223Z"
    },
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "class Animator:  #@save\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        \n",
    "        # 替换 d2l.use_svg_display()\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.rcParams['figure.figsize'] = figsize\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # 替换 d2l.set_axes，使用 lambda 函数直接配置参数\n",
    "        self.config_axes = lambda: self._set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def _set_axes(self, ax, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "        \"\"\"设置坐标轴标签、范围和比例\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        # 设置坐标轴标签\n",
    "        if xlabel:\n",
    "            ax.set_xlabel(xlabel)\n",
    "        if ylabel:\n",
    "            ax.set_ylabel(ylabel)\n",
    "        # 设置坐标轴范围\n",
    "        if xlim:\n",
    "            ax.set_xlim(xlim)\n",
    "        if ylim:\n",
    "            ax.set_ylim(ylim)\n",
    "        # 设置坐标轴比例\n",
    "        if xscale:\n",
    "            ax.set_xscale(xscale)\n",
    "        if yscale:\n",
    "            ax.set_yscale(yscale)\n",
    "        # 设置图例\n",
    "        if legend:\n",
    "            ax.legend(legend)\n",
    "        # 添加网格\n",
    "        ax.grid(True)\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "class Accumulator:  #@save\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def accuracy(y_hat, y):  #@save\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "def train_epoch_ch3(net, train_iter, loss, updater):  #@save\n",
    "    \"\"\"训练模型一个迭代周期（定义见第3章）\"\"\"\n",
    "    # 将模型设置为训练模式\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    # 训练损失总和、训练准确度总和、样本数\n",
    "    metric = Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        # 计算梯度并更新参数\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            # 使用PyTorch内置的优化器和损失函数\n",
    "            updater.zero_grad()\n",
    "            l.mean().backward()\n",
    "            updater.step()\n",
    "        else:\n",
    "            # 使用定制的优化器和损失函数\n",
    "            l.sum().backward()\n",
    "            updater(X.shape[0])\n",
    "        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
    "    # 返回训练损失和训练精度\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "\n",
    "def evaluate_accuracy(net, data_iter):  #@save\n",
    "    \"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()  # 将模型设置为评估模式\n",
    "    metric = Accumulator(2)  # 正确预测数、预测总数\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  #@save\n",
    "    \"\"\"训练模型（定义见第3章）\"\"\"\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n",
    "                        legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "        animator.add(epoch + 1, train_metrics + (test_acc,))\n",
    "    train_loss, train_acc = train_metrics\n",
    "    assert train_loss < 0.5, train_loss\n",
    "    assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "    assert test_acc <= 1 and test_acc > 0.7, test_acc\n",
    "\n",
    "num_epochs = 10\n",
    "train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d7d1c",
   "metadata": {
    "origin_pos": 22
   },
   "source": [
    "和以前一样，这个算法使结果收敛到一个相当高的精度，而且这次的代码比之前更精简了。\n",
    "\n",
    "## 小结\n",
    "\n",
    "* 使用深度学习框架的高级API，我们可以更简洁地实现softmax回归。\n",
    "* 从计算的角度来看，实现softmax回归比较复杂。在许多情况下，深度学习框架在这些著名的技巧之外采取了额外的预防措施，来确保数值的稳定性。这使我们避免了在实践中从零开始编写模型时可能遇到的陷阱。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 尝试调整超参数，例如批量大小、迭代周期数和学习率，并查看结果。\n",
    "1. 增加迭代周期的数量。为什么测试精度会在一段时间后降低？我们怎么解决这个问题？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81d17a2",
   "metadata": {
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1793)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
