{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6709af5b",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Bahdanau 注意力\n",
    ":label:`sec_seq2seq_attention`\n",
    "\n",
    " :numref:`sec_seq2seq`中探讨了机器翻译问题：\n",
    "通过设计一个基于两个循环神经网络的编码器-解码器架构，\n",
    "用于序列到序列学习。\n",
    "具体来说，循环神经网络编码器将长度可变的序列转换为固定形状的上下文变量，\n",
    "然后循环神经网络解码器根据生成的词元和上下文变量\n",
    "按词元生成输出（目标）序列词元。\n",
    "然而，即使并非所有输入（源）词元都对解码某个词元都有用，\n",
    "在每个解码步骤中仍使用编码*相同*的上下文变量。\n",
    "有什么方法能改变上下文变量呢？\n",
    "\n",
    "我们试着从 :cite:`Graves.2013`中找到灵感：\n",
    "在为给定文本序列生成手写的挑战中，\n",
    "Graves设计了一种可微注意力模型，\n",
    "将文本字符与更长的笔迹对齐，\n",
    "其中对齐方式仅向一个方向移动。\n",
    "受学习对齐想法的启发，Bahdanau等人提出了一个没有严格单向对齐限制的\n",
    "可微注意力模型 :cite:`Bahdanau.Cho.Bengio.2014`。\n",
    "在预测词元时，如果不是所有输入词元都相关，模型将仅对齐（或参与）输入序列中与当前预测相关的部分。这是通过将上下文变量视为注意力集中的输出来实现的。\n",
    "\n",
    "## 模型\n",
    "\n",
    "下面描述的Bahdanau注意力模型\n",
    "将遵循 :numref:`sec_seq2seq`中的相同符号表达。\n",
    "这个新的基于注意力的模型与 :numref:`sec_seq2seq`中的模型相同，\n",
    "只不过 :eqref:`eq_seq2seq_s_t`中的上下文变量$\\mathbf{c}$\n",
    "在任何解码时间步$t'$都会被$\\mathbf{c}_{t'}$替换。\n",
    "假设输入序列中有$T$个词元，\n",
    "解码时间步$t'$的上下文变量是注意力集中的输出：\n",
    "\n",
    "$$\\mathbf{c}_{t'} = \\sum_{t=1}^T \\alpha(\\mathbf{s}_{t' - 1}, \\mathbf{h}_t) \\mathbf{h}_t,$$\n",
    "\n",
    "其中，时间步$t' - 1$时的解码器隐状态$\\mathbf{s}_{t' - 1}$是查询，\n",
    "编码器隐状态$\\mathbf{h}_t$既是键，也是值，\n",
    "注意力权重$\\alpha$是使用 :eqref:`eq_attn-scoring-alpha`\n",
    "所定义的加性注意力打分函数计算的。\n",
    "\n",
    "与 :numref:`fig_seq2seq_details`中的循环神经网络编码器-解码器架构略有不同，\n",
    " :numref:`fig_s2s_attention_details`描述了Bahdanau注意力的架构。\n",
    "\n",
    "![一个带有Bahdanau注意力的循环神经网络编码器-解码器模型](../img/seq2seq-attention-details.svg)\n",
    ":label:`fig_s2s_attention_details`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578eec9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:29.787913Z",
     "iopub.status.busy": "2023-08-18T07:15:29.787398Z",
     "iopub.status.idle": "2023-08-18T07:15:31.837042Z",
     "shell.execute_reply": "2023-08-18T07:15:31.836075Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4707cd",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "## 定义注意力解码器\n",
    "\n",
    "下面看看如何定义Bahdanau注意力，实现循环神经网络编码器-解码器。\n",
    "其实，我们只需重新定义解码器即可。\n",
    "为了更方便地显示学习的注意力权重，\n",
    "以下`AttentionDecoder`类定义了[**带有注意力机制解码器的基本接口**]。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adffb85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本解码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca599f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:31.875080Z",
     "iopub.status.busy": "2023-08-18T07:15:31.874396Z",
     "iopub.status.idle": "2023-08-18T07:15:31.879397Z",
     "shell.execute_reply": "2023-08-18T07:15:31.878617Z"
    },
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "class AttentionDecoder(Decoder):\n",
    "    \"\"\"带有注意力机制解码器的基本接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionDecoder, self).__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f1f6d",
   "metadata": {
    "origin_pos": 7
   },
   "source": [
    "接下来，让我们在接下来的`Seq2SeqAttentionDecoder`类中\n",
    "[**实现带有Bahdanau注意力的循环神经网络解码器**]。\n",
    "首先，初始化解码器的状态，需要下面的输入：\n",
    "\n",
    "1. 编码器在所有时间步的最终层隐状态，将作为注意力的键和值；\n",
    "1. 上一时间步的编码器全层隐状态，将作为初始化解码器的隐状态；\n",
    "1. 编码器有效长度（排除在注意力池中填充词元）。\n",
    "\n",
    "在每个解码时间步骤中，解码器上一个时间步的最终层隐状态将用作查询。\n",
    "因此，注意力输出和输入嵌入都连结为循环神经网络解码器的输入。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1353869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "#@save\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "#@save\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作\"\"\"\n",
    "    # X:3D张量，valid_lens:1D或2D张量\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\n",
    "                              value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
    "\n",
    "#@save\n",
    "class AdditiveAttention(nn.Module):\n",
    "    \"\"\"加性注意力\"\"\"\n",
    "    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\n",
    "        super(AdditiveAttention, self).__init__(**kwargs)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
    "        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        queries, keys = self.W_q(queries), self.W_k(keys)\n",
    "        # 在维度扩展后，\n",
    "        # queries的形状：(batch_size，查询的个数，1，num_hidden)\n",
    "        # key的形状：(batch_size，1，“键－值”对的个数，num_hiddens)\n",
    "        # 使用广播方式进行求和\n",
    "        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
    "        features = torch.tanh(features)\n",
    "        # self.w_v仅有一个输出，因此从形状中移除最后那个维度。\n",
    "        # scores的形状：(batch_size，查询的个数，“键-值”对的个数)\n",
    "        scores = self.w_v(features).squeeze(-1)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d21b004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:31.883127Z",
     "iopub.status.busy": "2023-08-18T07:15:31.882496Z",
     "iopub.status.idle": "2023-08-18T07:15:31.892223Z",
     "shell.execute_reply": "2023-08-18T07:15:31.891475Z"
    },
    "origin_pos": 9,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class Seq2SeqAttentionDecoder(AttentionDecoder):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)\n",
    "        self.attention = AdditiveAttention(\n",
    "            num_hiddens, num_hiddens, num_hiddens, dropout)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(\n",
    "            embed_size + num_hiddens, num_hiddens, num_layers,\n",
    "            dropout=dropout)\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        # outputs的形状为(batch_size，num_steps，num_hiddens).\n",
    "        # hidden_state的形状为(num_layers，batch_size，num_hiddens)\n",
    "        outputs, hidden_state = enc_outputs\n",
    "        return (outputs.permute(1, 0, 2), hidden_state, enc_valid_lens)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # enc_outputs的形状为(batch_size,num_steps,num_hiddens).\n",
    "        # hidden_state的形状为(num_layers,batch_size,\n",
    "        # num_hiddens)\n",
    "        enc_outputs, hidden_state, enc_valid_lens = state\n",
    "        # 输出X的形状为(num_steps,batch_size,embed_size)\n",
    "        X = self.embedding(X).permute(1, 0, 2)\n",
    "        outputs, self._attention_weights = [], []\n",
    "        for x in X:\n",
    "            # query的形状为(batch_size,1,num_hiddens)\n",
    "            query = torch.unsqueeze(hidden_state[-1], dim=1)\n",
    "            # context的形状为(batch_size,1,num_hiddens)\n",
    "            context = self.attention(\n",
    "                query, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "            # 在特征维度上连结\n",
    "            x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1)\n",
    "            # 将x变形为(1,batch_size,embed_size+num_hiddens)\n",
    "            out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)\n",
    "            outputs.append(out)\n",
    "            self._attention_weights.append(self.attention.attention_weights)\n",
    "        # 全连接层变换后，outputs的形状为\n",
    "        # (num_steps,batch_size,vocab_size)\n",
    "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
    "        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state,\n",
    "                                          enc_valid_lens]\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d2dbea",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "接下来，使用包含7个时间步的4个序列输入的小批量[**测试Bahdanau注意力解码器**]。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "280a8fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "#@save\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本编码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "#@save\n",
    "class Seq2SeqEncoder(Encoder):\n",
    "    \"\"\"用于序列到序列学习的循环神经网络编码器\"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,\n",
    "                          dropout=dropout)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        # 输出'X'的形状：(batch_size,num_steps,embed_size)\n",
    "        X = self.embedding(X)\n",
    "        # 在循环神经网络模型中，第一个轴对应于时间步\n",
    "        X = X.permute(1, 0, 2)\n",
    "        # 如果未提及状态，则默认为0\n",
    "        output, state = self.rnn(X)\n",
    "        # output的形状:(num_steps,batch_size,num_hiddens)\n",
    "        # state的形状:(num_layers,batch_size,num_hiddens)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cd7ffa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:31.895756Z",
     "iopub.status.busy": "2023-08-18T07:15:31.895141Z",
     "iopub.status.idle": "2023-08-18T07:15:31.935399Z",
     "shell.execute_reply": "2023-08-18T07:15:31.934579Z"
    },
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 10]), 3, torch.Size([4, 7, 16]), 2, torch.Size([4, 16]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                             num_layers=2)\n",
    "encoder.eval()\n",
    "decoder = Seq2SeqAttentionDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                                  num_layers=2)\n",
    "decoder.eval()\n",
    "X = torch.zeros((4, 7), dtype=torch.long)  # (batch_size,num_steps)\n",
    "state = decoder.init_state(encoder(X), None)\n",
    "output, state = decoder(X, state)\n",
    "output.shape, len(state), state[0].shape, len(state[1]), state[1][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9a6381",
   "metadata": {
    "origin_pos": 17
   },
   "source": [
    "## [**训练**]\n",
    "\n",
    "与 :numref:`sec_seq2seq_training`类似，\n",
    "我们在这里指定超参数，实例化一个带有Bahdanau注意力的编码器和解码器，\n",
    "并对这个模型进行机器翻译训练。\n",
    "由于新增的注意力机制，训练要比没有注意力机制的\n",
    " :numref:`sec_seq2seq_training`慢得多。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dacb0baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i=0):  #@save\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d10fc9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import os\n",
    "import collections\n",
    "import random\n",
    "import torch\n",
    "\n",
    "class Vocab:  #@save\n",
    "    \"\"\"文本词表\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        # 按出现频率排序\n",
    "        counter = count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "        # 未知词元的索引为0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # 未知词元的索引为0\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs\n",
    "    \n",
    "def count_corpus(tokens):  #@save\n",
    "    \"\"\"统计词元的频率\"\"\"\n",
    "    # 这里的tokens是1D列表或2D列表\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # 将词元列表展平成一个列表\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4ec903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import requests\n",
    "import zipfile\n",
    "import tarfile\n",
    "import hashlib\n",
    "from torch.utils import data\n",
    "\n",
    "#@save\n",
    "DATA_HUB = {}\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
    "\n",
    "DATA_HUB['fra-eng'] = (DATA_URL + 'fra-eng.zip',\n",
    "                       '94646ad1522d915e7b0f9296181140edcf86a4f5')\n",
    "\n",
    "def download(name, cache_dir=os.path.join('..', 'data')):  #@save\n",
    "    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名\"\"\"\n",
    "    assert name in DATA_HUB, f\"{name} 不存在于 {DATA_HUB}\"\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname  # 命中缓存\n",
    "    print(f'正在从{url}下载{fname}...')\n",
    "    r = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname\n",
    "\n",
    "def download_extract(name, folder=None):  #@save\n",
    "    \"\"\"下载并解压zip/tar文件\"\"\"\n",
    "    fname = download(name)\n",
    "    base_dir = os.path.dirname(fname)\n",
    "    data_dir, ext = os.path.splitext(fname)\n",
    "    if ext == '.zip':\n",
    "        fp = zipfile.ZipFile(fname, 'r')\n",
    "    elif ext in ('.tar', '.gz'):\n",
    "        fp = tarfile.open(fname, 'r')\n",
    "    else:\n",
    "        assert False, '只有zip/tar文件可以被解压缩'\n",
    "    fp.extractall(base_dir)\n",
    "    return os.path.join(base_dir, folder) if folder else data_dir\n",
    "\n",
    "#@save\n",
    "def read_data_nmt():\n",
    "    \"\"\"载入\"英语-法语\"数据集\"\"\"\n",
    "    data_dir = download_extract('fra-eng')\n",
    "    with open(os.path.join(data_dir, 'fra.txt'), 'r',\n",
    "             encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "#@save\n",
    "def preprocess_nmt(text):\n",
    "    \"\"\"预处理“英语－法语”数据集\"\"\"\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(',.!?') and prev_char != ' '\n",
    "\n",
    "    # 使用空格替换不间断空格\n",
    "    # 使用小写字母替换大写字母\n",
    "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
    "    # 在单词和标点符号之间插入空格\n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
    "           for i, char in enumerate(text)]\n",
    "    return ''.join(out)\n",
    "\n",
    "def tokenize_nmt(text, num_examples=None):\n",
    "    \"\"\"词元化“英语－法语”数据数据集\"\"\"\n",
    "    source, target = [], []\n",
    "    for i, line in enumerate(text.split('\\n')):\n",
    "        if num_examples and i > num_examples:\n",
    "            break\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            source.append(parts[0].split(' '))\n",
    "            target.append(parts[1].split(' '))\n",
    "    return source, target\n",
    "\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"截断或填充文本序列\"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]  # 截断\n",
    "    return line + [padding_token] * (num_steps - len(line))  # 填充\n",
    "\n",
    "def build_array_nmt(lines, vocab, num_steps):\n",
    "    \"\"\"将机器翻译的文本序列转换成小批量\"\"\"\n",
    "    lines = [vocab[l] for l in lines]\n",
    "    lines = [l + [vocab['<eos>']] for l in lines]\n",
    "    array = torch.tensor([truncate_pad(\n",
    "        l, num_steps, vocab['<pad>']) for l in lines])\n",
    "    valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
    "    return array, valid_len\n",
    "\n",
    "def load_data_nmt(batch_size, num_steps, num_examples=600):\n",
    "    \"\"\"返回翻译数据集的迭代器和词表\"\"\"\n",
    "    text = preprocess_nmt(read_data_nmt())\n",
    "    source, target = tokenize_nmt(text, num_examples)\n",
    "    src_vocab = Vocab(source, min_freq=2,\n",
    "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    tgt_vocab = Vocab(target, min_freq=2,\n",
    "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
    "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
    "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    data_iter = load_array(data_arrays, batch_size)\n",
    "    return data_iter, src_vocab, tgt_vocab\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"构造一个PyTorch数据迭代器\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acc7f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基类\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dde6f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"带遮蔽的softmax交叉熵损失函数\"\"\"\n",
    "    # pred的形状：(batch_size,num_steps,vocab_size)\n",
    "    # label的形状：(batch_size,num_steps)\n",
    "    # valid_len的形状：(batch_size,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction='none'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "class Animator:  #@save\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        \n",
    "        # 替换 d2l.use_svg_display()\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.rcParams['figure.figsize'] = figsize\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # 替换 d2l.set_axes，使用 lambda 函数直接配置参数\n",
    "        self.config_axes = lambda: self._set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def _set_axes(self, ax, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "        \"\"\"设置坐标轴标签、范围和比例\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        # 设置坐标轴标签\n",
    "        if xlabel:\n",
    "            ax.set_xlabel(xlabel)\n",
    "        if ylabel:\n",
    "            ax.set_ylabel(ylabel)\n",
    "        # 设置坐标轴范围\n",
    "        if xlim:\n",
    "            ax.set_xlim(xlim)\n",
    "        if ylim:\n",
    "            ax.set_ylim(ylim)\n",
    "        # 设置坐标轴比例\n",
    "        if xscale:\n",
    "            ax.set_xscale(xscale)\n",
    "        if yscale:\n",
    "            ax.set_yscale(yscale)\n",
    "        # 设置图例\n",
    "        if legend:\n",
    "            ax.legend(legend)\n",
    "        # 添加网格\n",
    "        ax.grid(True)\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "class Accumulator:  #@save\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def accuracy(y_hat, y):  #@save\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "def train_epoch_ch3(net, train_iter, loss, updater):  #@save\n",
    "    \"\"\"训练模型一个迭代周期（定义见第3章）\"\"\"\n",
    "    # 将模型设置为训练模式\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    # 训练损失总和、训练准确度总和、样本数\n",
    "    metric = Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        # 计算梯度并更新参数\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            # 使用PyTorch内置的优化器和损失函数\n",
    "            updater.zero_grad()\n",
    "            l.mean().backward()\n",
    "            updater.step()\n",
    "        else:\n",
    "            # 使用定制的优化器和损失函数\n",
    "            l.sum().backward()\n",
    "            updater(X.shape[0])\n",
    "        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
    "    # 返回训练损失和训练精度\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "\n",
    "def evaluate_accuracy(net, data_iter):  #@save\n",
    "    \"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()  # 将模型设置为评估模式\n",
    "    metric = Accumulator(2)  # 正确预测数、预测总数\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  #@save\n",
    "    \"\"\"训练模型（定义见第3章）\"\"\"\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n",
    "                        legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "        animator.add(epoch + 1, train_metrics + (test_acc,))\n",
    "    train_loss, train_acc = train_metrics\n",
    "    assert train_loss < 0.5, train_loss\n",
    "    assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "    assert test_acc <= 1 and test_acc > 0.7, test_acc\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class Timer:  #@save\n",
    "    \"\"\"记录多次运行时间\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"启动计时器\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"停止计时器并将时间记录在列表中\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"返回平均时间\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"返回时间总和\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"返回累计时间\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist()\n",
    "\n",
    "def grad_clipping(net, theta):  #@save\n",
    "    \"\"\"裁剪梯度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm\n",
    "\n",
    "#@save\n",
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    \"\"\"训练序列到序列模型\"\"\"\n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    animator = Animator(xlabel='epoch', ylabel='loss',\n",
    "                     xlim=[10, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = Timer()\n",
    "        metric = Accumulator(2)  # 训练损失总和，词元数量\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                          device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # 强制教学\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()\t# 损失函数的标量进行“反向传播”\n",
    "            grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            animator.add(epoch + 1, (metric[0] / metric[1],))\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n",
    "        f'tokens/sec on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44dd619c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:15:31.939197Z",
     "iopub.status.busy": "2023-08-18T07:15:31.938585Z",
     "iopub.status.idle": "2023-08-18T07:17:05.733764Z",
     "shell.execute_reply": "2023-08-18T07:17:05.732879Z"
    },
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.019, 7268.9 tokens/sec on cpu\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAD/CAYAAADVGuzgAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAKlJJREFUeJzt3Ql0FFXaN/An3el09j0kgYSEsIWAhB2DICo7LqCMAs4ckGFgADkqKHpwRhbhDIwgg3wivIOi+H0KCCq+CiJrkCWAsohAAgQIgewJ2ddOur7z3E63aUggCZ1UV+X/O+eeqq6uVO5Nd56+fesuDpIkSQQAAHZPI3cGAACgfhCwAQAUAgEbAEAhELABABQCARsAQCEQsAEAFAIBGwBAIRzlzoA9MhqNlJqaSh4eHuTg4CB3dgBAISRJosLCQmrdujVpNLavDyNg14KDdWhoqNzZAACFunnzJoWEhNj8ugjYteCatfmP7unpSUpgMBhoz549NHz4cNLpdKRGai+j2svXEsp4+/ZtateunSWG2BoCdi3MzSAcrJUUsF1dXUV+1fiP0BLKqPbytYQyGgwGsW2qplTcdAQAUAgEbAAAhUDABgBQCARsAACFQMAGAFAIBOx7qKg0yp0FAAALBOx7uJZVJHcWAADsK2CvXbuWwsPDydnZmfr3708nT56s89wNGzbQoEGDyMfHR6ShQ4fedT4PD12wYAEFBweTi4uLOOfKlSsNztel9MJGlQcAQJUBe+vWrTR37lxauHAhnT59mqKjo2nEiBGUmZlZ6/mxsbE0ceJEOnjwIMXFxYkh5DxqKiUlxXLOe++9R2vWrKH169fTiRMnyM3NTVyzrKysQXm7nImADQD2Q/aAvWrVKpo2bRpNmTKFoqKiRJDlkVAbN26s9fwvvviCZs2aRT169KDIyEj6+OOPxWRN+/fvt9SuV69eTf/85z9pzJgx1L17d/r888/F/CA7duxoUN4up6NJBADsh6xD0ysqKujUqVM0f/58yzGe4YqbMLj2XB8lJSViOKivr694fP36dUpPTxfXMPPy8hJNLXzNCRMm3HWN8vJykcwKCgrENiE9X+RRCTP2mYfEmrdqpPYyqr18LaGMhiYul6wBOzs7m6qqqigwMNDqOD9OSEio1zXeeustMZWhOUBzsDZf485rmp+707Jly2jx4sV3Hc8tqaSt3/1Ink6kGHv37iW1U3sZ1V4+NZexpKSkSa+v6Mmfli9fTlu2bBHt2nzDsrG4hs/t6DVr2ObpVdt07UeDOvqTEj7Z+Z9g2LBhqpxUpyWUUe3lawllzMnJUW/A9vf3J61WSxkZGVbH+XFQUNA9f3blypUiYO/bt0+0U5uZf46vwb1Eal6T271ro9frRarN5awSeiJKOW8s/idQ4z9CSyqj2sun5jLqmrhMst50dHJyot69e1tuGDLzDcSYmJg6f457gSxZsoR2795Nffr0sXqO56LloF3zmlxj5t4i97pmXeLTTO3ZAAByk71JhJsiJk+eLAJvv379RA+P4uJi0WuETZo0idq0aSPamdm///1v0cf6yy+/FH23ze3S7u7uIvENwtdee42WLl1KHTt2FAH8nXfeEe3cY8eObXD+EtLQtQ8A7IPsAXv8+PGUlZUlgjAHX2624Jqz+aZhcnKy1dpo69atEz03/vSnP1ldh/txL1q0SOy/+eabIuhPnz6d8vLyaODAgeKajWnnvppVROWVVaR31D5wWQEAFB2w2ezZs0WqDd9QrCkpKem+1+Na9rvvvivSg/Bw1lKxUaIrGUXUrY3XA10LAEDxA2fsWedA0/JgCRiiDgB2AAH7HjoHmRbSxI1HALAHCNj30DkQARsA7AcC9j10CnK3BGyeowQAQE4I2PfQoZUHaRx4iLqBMgv/mGsEAEAOCNj34KzTUkSAqZZ9Ec0iACAzBOz7iKy+8YgBNAAgNwTs++gSbOrahxuPACA3BOz7iELABgA7gYB9H5HBpiaRa9nFVGaokjs7ANCCIWDfR5CnM3m76qjKKFFiJpYMAwD5IGDXY16SLkGmZhH0FAEAOSFg1wNuPAKAPUDAbkA7Nrr2AYCcELAb0lMkHUPUAUA+CNj10KGVO2k1DpRXYqD0gjK5swMALRQCdn2HqPu7iX00iwCAXBCwG3jjET1FAEAuCNj1hJ4iACA3BOyG9hTBcmEAIBME7Ab2FLmWVYQh6gAgCwTsemrloSdfNycySkSXM1DLBoDmh4DdkCHqGEADADJCwG6ASMwpAgAyQsBuAPQUAQA5IWA3gLlJBKuoA4AcELAbOETdUeNABWWVlJaPIeoA0LwQsBtA76il9tWrqKNZBACaGwL2AzSLAAA0JwTsBoq0TLWKrn0A0LwQsBsIPUUAQC4I2I1sEknKLqbSCgxRB4Dmg4DdQAHuevLDEHUAkAECdqOGqKNZBACaHwJ2I6CnCADIAQG7ESw1bPQUAYCWFLDXrl1L4eHh5OzsTP3796eTJ0/Wee6FCxdo3Lhx4nxumli9evVd5yxatEg8VzNFRkY2ySRQGKIOAC0mYG/dupXmzp1LCxcupNOnT1N0dDSNGDGCMjMzaz2/pKSEIiIiaPny5RQUFFTndbt27UppaWmWdOTIEZsPUddpHaiwrJJS8kptem0AALsM2KtWraJp06bRlClTKCoqitavX0+urq60cePGWs/v27cvrVixgiZMmEB6vb7O6zo6OoqAbk7+/v42zbeTo6bGEHU0iwBA83AkmVRUVNCpU6do/vz5lmMajYaGDh1KcXFxD3TtK1euUOvWrUUzS0xMDC1btozatm1b5/nl5eUimRUUmG4mGgwGkWrTOdBdrO94ISWPHuvoS3Iz57Ou/KqB2suo9vK1hDIamrhcsgXs7OxsqqqqosDAQKvj/DghIaHR1+V28M8++4w6d+4smkMWL15MgwYNovPnz5OHh6l3x504oPN5d9qzZ4+o8dcqz4GItBR75jK1K2l8fm1t7969pHZqL6Pay6fmMpaUlKgzYDeVUaNGWfa7d+8uAnhYWBh99dVXNHXq1Fp/hmv53JZes4YdGhpKw4cPJ09P0w3GO3km5tB3m05RnoM7jR49kOzhk53/CYYNG0Y6nY7USO1lVHv5WkIZc3Jy1BmwuV1Zq9VSRkaG1XF+fK8big3l7e1NnTp1osTExDrP4fbw2trE+Q1V15uqW4iP2N64XUIGyYFcnezjs+9eeVYLtZdR7eVTcxl1TVwm2W46Ojk5Ue/evWn//v2WY0ajUTzmdmdbKSoqoqtXr1JwcDDZUoCHnvzd9cS9+i6hPzYAqL2XCDdDbNiwgTZt2kTx8fE0c+ZMKi4uFr1G2KRJk6xuSvKNyrNnz4rE+ykpKWK/Zu35jTfeoEOHDlFSUhIdO3aMnn32WVGTnzhxYhOOeETABoCmJ+v3+PHjx1NWVhYtWLCA0tPTqUePHrR7927Ljcjk5GTRc8QsNTWVevbsaXm8cuVKkQYPHkyxsbHi2K1bt0Rw5rakgIAAGjhwIB0/flzs21pUsCcdvpJNCekYog4ATU/2htfZs2eLVBtzEDbjEY73G1m4ZcsWai6RmFMEAFrS0HQ1zCmSkFaIIeoA0OQQsB8Aj3YUQ9TLK+lWLoaoA0DTQsB+ADqthjq0MjWLXEhFswgANC0E7AfUO8xbbI8kZsmdFQBQOQTsBzQk0tSj5UB8JtqxAaBJIWA/oJj2fuSi01JqfhldRG8RAGhCCNgPyFmnpYEdTdO37o+vfR5vAABbQMC2gSGRrcR2f7z1vCgAALaEgG0DT1QH7N9u5VNmQZnc2QEAlULAtoFWns4UHeIl9g8koFkEAJoGAraNDOli6i2yD+3YANBEELBtZEiXVpb+2GWGKrmzAwAqhIBtw5n7Wns5U5nBSMeuZsudHQBQIQRsG3FwcKAnqmvZaBYBgKaAgN0E7dgY9QgATQEB24ZiIvzI1UlL6QVlmAwKAGwOAdvWox47YNQjADQNBGwbG1rdLLI/AaMeAcC2ELBt7LFI09qR527lUwZGPQKADSFg21grD2eKDjXNkY1RjwAge8DetGkT7dy50/L4zTffJG9vbxowYADduHGDWrqhmAwKAOwlYP/rX/8iFxcXsR8XF0dr166l9957j/z9/WnOnDnU0pm79x1JzMaoRwCwGcfG/NDNmzepQ4cOYn/Hjh00btw4mj59Oj3yyCP02GOPUUvXJdhDjHrkRQ2OJmZbAjgAQLPXsN3d3SknJ0fs79mzh4YNGyb2nZ2dqbQUq4fzqEdMBgUAdhGwOUD/7W9/E+ny5cs0evRocfzChQsUHh5u6zwqejKoAwkZGPUIAPIFbG6zjomJoaysLPr666/Jz89PHD916hRNnDjRNjlTuIerRz1mFJTT+RSMegQAmdqwuUfIhx9+eNfxxYsX2yBL6hn1OKijP/10IYP2xWfQQ9ULHAAANGsNe/fu3XTkyBGrGnePHj3oxRdfpNzc3EZnRm3M7dgY9QgAsgXsefPmUUGB6Wv+77//Tq+//rpox75+/TrNnTvXJhlTy1qPDg4kmkTS8zHqEQBkCNgcmKOiosQ+t2E/9dRTom8217R//PHHB8ySevi766kHRj0CgJwB28nJiUpKSsT+vn37aPjw4WLf19fXUvMGkyEY9QgAcgbsgQMHiqaPJUuW0MmTJ+nJJ58Ux7mLX0hIiK3yprpRj6UVGPUIAM0csLmHiKOjI23fvp3WrVtHbdq0Ece5OWTkyJEPkB31iQzyoDbeLlReaRSjHgEAmrVbX9u2bemHH3646/h//vOfRmdE3aMeW9HncTdEb5GhURimDgDNGLBZVVWVmEckPj5ePO7atSs988wzpNVqG3tJVTeLiIAdn0lGo0QajYPcWQKAlhKwExMTRTe+lJQU6ty5szi2bNkyCg0NFdOutm/f3tb5VLSHI3zJzUlLmYXldD41n7qHmHqOAAA0eRv2K6+8IoIyz9p3+vRpkZKTk6ldu3biuYbgroA8/whPHNW/f39xE7MuPFcJzwzI53NTw+rVqx/4ms1B78ijHk0r0WAyKABo1oB96NAhMf81d+Mz4/lEli9fLp6rr61bt4reJgsXLhRBPzo6mkaMGEGZmbUHNe5KGBERIX5PUFCQTa7Z3JNBoXsfADRrwNbr9VRYWHjX8aKiItFHu75WrVpF06ZNoylTpoiBOOvXrydXV1fauHFjref37duXVqxYQRMmTBB5sMU1m8vj1aMeL6QWUFo+pqAFgGZqw+aRjbxgwSeffEL9+vUTx06cOEEzZswQNx7ro6KiQszuN3/+fMsxjUZDQ4cOFavYNEZjr1leXi6SmXnwj8FgEMkWvPQa6hHiRWdu5tOe82n0Yr9QsiVzPm2VX3uk9jKqvXwtoYyGJi5XowL2mjVraPLkyWKKVZ1OZ8nomDFj6mxXvlN2drboaRIYaN3NjR8nJCQ0JluNvibfMK1tpkFenIFr57bSxsGBzpCWPou9SN7Zv1NT2Lt3L6md2suo9vKpuYwl1SPA7W561e+++070FjF36+vSpYtl2TCl4Rp5zUmruIbNPV54yL2np6fNfk/vgjL6adVhul5IFBAVQ33DfWx2bf7A5H8CXlzC/CGqNmovo9rL1xLKmFO9EpfsAft+s/AdPHjQqh35fnjBXu6znZFhfROOH9d1Q7Gprsnt4bW1ifMbypZvqhA/HT3fJ5S+PJFM/z2SRAM6mm5E2pKt82yP1F5GtZdPzWXUNXGZ6h2wz5w5U6/zuLtdffDNyd69e9P+/ftp7Nix4pjRaBSPZ8+eXd9sNfk1be3vj0bQlpPJFHspi86n5FO3NljYAABsHLBr1qBthWvt3Bbep08fcfOS27+Li4tFDw82adIkMU8JtzGbbypevHjRss8Dd86ePSsWBTY3x9zvmnIL83Ojp6Nb03dnU2ld7FVa++decmcJANQ+NN0Wxo8fL9aFXLBgAaWnp4tVa3g1G/NNQx6Mw708zFJTU6lnz56WxytXrhRp8ODBFBsbW69r2oOZj7UXAXvX+TS6llVEEQHucmcJABRA1oDNuKmiruYKcxA249GL9VmB/F7XtAeRQZ40tEsrMepx/aGr9N6fouXOEgCodeAMPLhZj5uacL45nUKpeRhIAwD3h4Atk15tfSgmwo8qjRJtOHxN7uwAgAIgYMto1uOmWQ03n0ymnKI/RloCANQGAVtGAzv4U/cQLyozGOnTo0lyZwcA7BwCtoy4z/qsx0xt2ZvikqiwTJ3zKwCAbSBgy2x4VCB1aOVOhWWV9P+OJ8udHQCwYwjYMuPlwmYONrVlf3LkGpUZsLI6ANQOAdsOPNOjtVhZPbuogrb9elPu7ACAnULAtgM6rYb+PjhC7K8/dI0MVUa5swQAdggB20680CeU/N2dKCWvlP73bKrc2QEAO4SAbSecdVqaOtBUy1536CoZjfcfgg8ALQsCth35y8NtycPZkRIzi2jPRSzWCwDWELDtiIezjibHhIv9j2IT6zXRFQC0HAjYdmbKI+HkrNPQuVv5dDSxaZcbAgBlQcC2M37ueprQt63YX3swUe7sAIAdQcC2Q9MfjSBHjQPFXcuh08m5cmcHAOwEArYdau3tQs/2bCP2PzyAWjYAmCBg26kZj7UnjQPRgYRM+gqjHwEAAdt+tQ9wp7nDOon9d3acpwup+XJnCQBkhoBtx3jq1cc7B1B5pZFmfXGaCjD9KkCLhoBt5zP5/Wd8DzEx1I2cEnrjq9/QNxugBUPAtnPerk607i+9yEmrEaMfPz58Xe4sAYBMELAVoHuIN73zdJTYX747gU5evy13lgBABgjYCvGX/m1pbI/WVGWUaPaXpymrEIv2ArQ0CNgKWv/xX889RB1buVNmYTm9svkMVWLebIAWBQFbQVydHGndX3qTm5NWjIJctfey3FkCgGaEgK0wvGDv8nHdxf5HsVdpfzymYQVoKRCwFejp6Nb00gDTNKxztp6lm7dL5M4SADQDBGyFent0F+oR6k0FZZU084tTVI7V1gFUDwFboZwcNbT2z73Ix1VH51MKaOmPl+TOEgA0MQRsBeMRkKsn9CQHB6Itv9yiX7Ic5M4SADQhBGyFG9wpgF55oqPY33pNQ4evZMudJQBoIgjYKvDKkI40uJM/GYwO9Lf/e5o+PnwNc44AqBACtgpoNQ60dmIP6h9gJKNEtHRnPL25/RyVV+JGJICaIGCrhN5RQxPbG+kfozuLhQ+2nbpFL244gSHsACqCgK0ifPPxpZgw+mxKP/J0dqRTN3JpzIdH6HwKFj8AUAO7CNhr166l8PBwcnZ2pv79+9PJkyfvef62bdsoMjJSnP/QQw/Rrl27rJ5/6aWXxNwbNdPIkSOppXi0UwDtePkRivB3o9T8Mnp+fRzt+j1N7mwBgNID9tatW2nu3Lm0cOFCOn36NEVHR9OIESMoMzOz1vOPHTtGEydOpKlTp9KZM2do7NixIp0/f97qPA7QaWlplrR582ZqSSIC3Onblx8RwbvUUCVWrOG5R4zcyA0AiiR7wF61ahVNmzaNpkyZQlFRUbR+/XpydXWljRs31nr+Bx98IILxvHnzqEuXLrRkyRLq1asXffjhh1bn6fV6CgoKsiQfHx9qabxcdLRxch/628B24vGa/VdE4C4ur5Q7awDQCI4ko4qKCjp16hTNnz/fckyj0dDQoUMpLi6u1p/h41wjr4lr5Dt27LA6FhsbS61atRKB+oknnqClS5eSn59frdcsLy8XyaygoEBsDQaDSEpgzmdt+X1rREdqH+BKC/73Iu2+kE5JHxXR+r/0FANvlOReZVQDtZevJZTR0MTlkjVgZ2dnU1VVFQUGBlod58cJCQm1/kx6enqt5/NxM66BP/fcc9SuXTu6evUqvf322zRq1CgR7LVa7V3XXLZsGS1evPiu43v27BG1fSXZu3dvrce5FC93Ifr4kpYSMoroqQ9+ppc6Gamjl/KaSOoqo1qovXxqLmNJSYl6A3ZTmTBhgmWfb0p2796d2rdvL2rdQ4YMuet8ruHXrLVzDTs0NJSGDx9Onp6epJRPdv4nGDZsGOl0ujrPezavlGZ8cZbi0wtpbbyW/j6oHb3yRHvSaWVvHbNZGZVK7eVrCWXMyclRb8D29/cXNd6MDOs5nfkxtzvXho835HwWEREhfldiYmKtAZvbuzndid9QSntT3S/PYQE6+nrWAHr3+4u05ZebtP7n6xR37TatmdiTwvzcSAmU+Lo0hNrLp+Yy6pq4TLJWq5ycnKh37960f/9+yzGj0Sgex8TE1PozfLzm+Yw/ses6n926dUt88gUHB9sw98peuYYXQfjoz71Ef+3fbuXT6A8O0zenb2FIO4Adk/17MDdFbNiwgTZt2kTx8fE0c+ZMKi4uFr1G2KRJk6xuSr766qu0e/duev/990U796JFi+jXX3+l2bNni+eLiopED5Ljx49TUlKSCO5jxoyhDh06iJuT8IfRDwXTj689Sv3Cfam4oormfvUbvbb1LBWUqfOGEIDSyR6wx48fTytXrqQFCxZQjx496OzZsyIgm28sJicni37UZgMGDKAvv/yS/vvf/4o+29u3bxc9RLp16yae5yaWc+fO0TPPPEOdOnUS/bW5Fn/48OFamz1aOu4psnn6wzR3WCcxJ8l3Z1PpyTWHxShJALAvdnHTkWvH5hrynfhG4Z2ef/55kWrj4uJCP/30k83zqGYcqHnGv0c6+NGrW3jJsVJ64X/i6LUhHWnW4x3E8wAgP9lr2GA/eof50q5XB9Ez0a2pyijR+3sv08QNxyk1r1TurAEAAjbcydNZRx9M6EHvPx9Nbk5aOnn9No1c/TN9ceIGFWGEJICsELDhLjxZ1rjeIbTzlUEUHeIlFvr9x7fnqe/SfTR361k6lpiNOUkAWmobNtincH832j5zAH169DptOXmTrmUX0zdnUkTim5XP9WpD43qFiPMAoOkhYMM98QjI6Y+2p2mDIujMzTzafuoWff9bKqXkldL/OZAoUp8wH/pT7xB6snsweTirbzAEgL1AwIZ6N5P0ausj0oKnomjvxQwRvA9fyaJfb+SKtOj7CzSia5CodQ9o70eOChjuDqAkCNjQYM46LT0d3VqkjIIy+vZMigjeiZlFoh83Jz83JxrZLYie6t6a+rXzRddAABtAwIYHEujpTDMGt6e/PxpB527li8C98/c0yimuoC9OJIsU4KGn0Ry8o1tT77Y+pEHwBmgUBGywWZNJdKi3SAufjqJjV3No57k0Mf82LwS8Ke6GSMFezmJI/FPdg6lHqLf4OQCoHwRssDluu+alyTgtGduNjiZm0/fnUmnPhQxKyy+jT45cFynEx4WefCiYHungT73CfMhdj7cjwL3gPwSalJOjhh6PbCVSmaGKfr6cRT+cS6N98Rl0K7eU/ufnayJxK0lUa0/qG+5rSdyUAgB/QMCGZr1ZObxrkEilFVV08FIm7buYQb/cuC3mLzmfUiDSp0eTxPnt/N1El8G+7XzFjIKtPdFlEFo2BGyQhYuTVrRlc2Jp+aX0S1Iu/Zp0WwyHv5RRSNezi0XaduqWOCfA3Yk8HbT0U+Fv1MrTRdTAA9z1pm118nVzUsTqOQCNgYANdiHYy4WeiebUWjzOLzXQ6Ru5dDLptgjiv93Mp6yiCsoiB7p63nrFoZr4HqaPq5MI5G18XKhzkAdFBnlQl2BPUWNHMAclQ8AGu+TlorO0fTNu//4t+Tbtio2jkI5RlFtSKXqfZBWVm7aF5aIrIc8yeLu4QiSupR9IyLRc00mrofat3EUAFynYU2xbeejRWwUUAQEbFNP+3autN6X7SzQ6JqzWtfN4QqrckgoRxDMLyulGTjElpBeKdCm9UMw2GJ9WIFJNPq466hToQREBbmJdy3A/V7EN83MVy6kB2Au8G0E1eECOn7tepEixJnOA5Tleq5J7pYgAnlZACRmmLbeR55YY6MT12yLdiWvf4dXBmye54m2Yr5toL+dvAc46DWrn0GwQsKFF4KAa6usq0rAo0/Jz5qYWHlJ/OaOQknJKRK3cvM0rMVBmYblI3JZeV7dFbxcdebvqyNvFiTwt+6YtB3U3vaM4j5tkxNZRQ3pHLemr983HNWSkkkoSzTkO2ioyGokqjUbRzGNOlTX2jZIkbt66OTmK3+Gm52tqm++PCs0OARuopTe1dGvjJdKd8koq6EZOCSXlFFttOXHTCwfNikqjJajbhiPRL3cvi1dfOq2DKXiLIK4V++7Vjz1dHMUNWS9XndiaPlScyMfN9GHDHzD89wD7hYANUAcOZpx4uP2duImFV5rnoM41ce7VYtmWVlB+iekx75dUVInAXl5pFNuKKtO2vNJ03HzMUGW9KISjxkFMmmVONR87ajSWbwjcNs/XZnwN8XtLGrfyvYtOa/qGUB3QOZh7VQdzyzeJGsGeH/MqRdwqxDV+Sare8t/ISMR7vNYF/714azAYKLecxIee5KAR+TZUl72iet/89+F9HjXrW/2h4uemF9sH+RbB+SgzGMXfTK/TiA8yJU1MhoAN0MgmFq65cgrxsc01y8sr6IddP9JTo0eRXu/UoJ+trDKKD5Di8kpTqt7nwFRSwdsqKig1UG5xBeWJD5cK0XZv/sDhY/yNodRQRaX5VWIKgabjSHT6SKN/2l3vKAK3r5uefF2rt246ctfrRFkLudxlprIXlhmosHpfpLJK0axUEy+Fx/O4uzubXk+P6q1Izo7koXckFydHctFpxDcQU9KQXqcVH3Dmx86OWiotasq/GwI2gF3dNHXUmLYNxTVRLxdOjRsNyj1siioqKa/YIJp7OPG3BU65xTW+NVQHe9PWtN+Q1eK4Jq4lifROjpa2e+4bX3Ofm3XM+1zT5rzcrs5XFeezOvjy6FhbEB9uFVVE1p2HGsVYXkJNCQEbAMSHBDdtcGrr59qgQM+1cnMw1lT3mOGt+TEf4X3+VsJNIrt27aLRo0fU2jXzfr+rsKySbosAXi6CeM0tf4tw12tFTdtcMxa1Zauas05sXZ20ounlj5q4KZk+DAziuLmmzse5WaussorKzFuDUTRHmdIf+yWGpm1eQcAGgAcK9Hxjs7l+lxf3vHHViVGrD0r01HHXim6gtpKdnU0Bq6jJYJwuAICNNHWffARsAACFQMAGAFAIBGwAAIVAwAYAUAgEbAAAhUC3vjqGr7KCAhv0pG8m3L+1pKRE5Lmh/VuVQu1lVHv5WkIZCwsLrWKIrSFg3+OPHhoaKndWAECBcnJyyMvr7gnFHpSD1FQfBQpmNBopNTWVPDw8FDPXMddY+APm5s2b5OnpSWqk9jKqvXwtoYz5+fnUtm1bys3NJW/vuycNe1CoYddCo9FQSEgIKRH/E6jxH6EllVHt5WsJZdRUz6Zo8+s2yVUBAMDmELABABQCAVsl9Ho9LVy4UGzVSu1lVHv5WkIZ9U1cPtx0BABQCNSwAQAUAgEbAEAhELABABQCARsAQCEQsBVm0aJFYvRlzRQZGWl5vqysjF5++WXy8/Mjd3d3GjduHGVkZJC9+vnnn+npp5+m1q1bi7Ls2LHD6nm+J75gwQIKDg4mFxcXGjp0KF25csXqnNu3b9Of//xnMRCDR5dNnTqVioqKSCllfOmll+56TUeOHKmYMi5btoz69u0rRga3atWKxo4dS5cuXbI6pz7vy+TkZHryySfJ1dVVXGfevHlUWVlJSijfY489dtdrOGPGDJuXDwFbgbp27UppaWmWdOTIEctzc+bMoe+//562bdtGhw4dEkPsn3vuObJXxcXFFB0dTWvXrq31+ffee4/WrFlD69evpxMnTpCbmxuNGDFCBAAzDmQXLlygvXv30g8//CAC5PTp00kpZWQcoGu+pps3b7Z63p7LyO8zDsbHjx8X+eMJnoYPHy7KXd/3ZVVVlQhmFRUVdOzYMdq0aRN99tln4sNaCeVj06ZNs3oN+b1r8/Jxtz5QjoULF0rR0dG1PpeXlyfpdDpp27ZtlmPx8fHcbVOKi4uT7B3n89tvv7U8NhqNUlBQkLRixQqrMur1emnz5s3i8cWLF8XP/fLLL5ZzfvzxR8nBwUFKSUmR7L2MbPLkydKYMWPq/BmllTEzM1Pk99ChQ/V+X+7atUvSaDRSenq65Zx169ZJnp6eUnl5uWTP5WODBw+WXn31VakutiofatgKxE0C/PU6IiJC1Lz4qxY7deqU+PTnZgMzbi7hyWji4uJIaa5fv07p6elW5eEZ0Pr3728pD2+5iaBPnz6Wc/h8nsuBa+RKERsbK74md+7cmWbOnClmezNTWhl5AiTm6+tb7/clbx966CEKDAy0nMPfpHiyKP5mYc/lM/viiy/I39+funXrRvPnzxfTyJrZqnyY/ElhOFjxVyn+x+avXYsXL6ZBgwbR+fPnRXBzcnK6a5YwfpPwc0pjznPNN7n5sfk53nKgq8nR0VH8MymlzNwcws0D7dq1o6tXr9Lbb79No0aNEv/kWq1WUWXkmS5fe+01euSRR0TgYvV5X/K2ttfZ/Jw9l4+9+OKLFBYWJipS586do7feeku0c3/zzTc2LR8CtsLwP7JZ9+7dRQDnN8pXX30lbsqB8kyYMMGyz7Uwfl3bt28vat1DhgwhJeG2Xq481LyvoiYv11G+mvcT+DXkm+T82vEHML+WtoImEYXjWkunTp0oMTGRgoKCxE2NvLw8q3P4bjw/pzTmPN/Zm6BmeXibmZlp9TzfeedeFUosM+OmLv5qza+pkso4e/ZscUP04MGDVtMT1+d9ydvaXmfzc/ZcvtpwRYrVfA1tUT4EbIXjrl38Kc6f6L179xbLLu3fv9/yPH8t4zbumJgYUhpuIuA3c83ycJsft9uay8NbDgTcTmp24MAB8dXV/E+jNLdu3RJt2PyaKqGMfC+Vg9m3334r8sWvW031eV/y9vfff7f6YOIeGdyNMSoqiuy5fLU5e/as2NZ8DW1SvnrfngS78Prrr0uxsbHS9evXpaNHj0pDhw6V/P39xZ1rNmPGDKlt27bSgQMHpF9//VWKiYkRyV4VFhZKZ86cEYnfjqtWrRL7N27cEM8vX75c8vb2lr777jvp3LlzojdFu3btpNLSUss1Ro4cKfXs2VM6ceKEdOTIEaljx47SxIkTJSWUkZ974403RG8Jfk337dsn9erVS5ShrKxMEWWcOXOm5OXlJd6XaWlpllRSUmI5537vy8rKSqlbt27S8OHDpbNnz0q7d++WAgICpPnz50v2Xr7ExETp3XffFeXi15DfqxEREdKjjz5q8/IhYCvM+PHjpeDgYMnJyUlq06aNeMxvGDMOZLNmzZJ8fHwkV1dX6dlnnxVvLnt18OBBEcTuTNzVzdy175133pECAwNFd74hQ4ZIly5dsrpGTk6OCF7u7u6im9SUKVNEIFRCGfmfnv+J+Z+Xu76FhYVJ06ZNs+r+Ze9lrK1snD799NMGvS+TkpKkUaNGSS4uLqISwpUTg8Eg2Xv5kpOTRXD29fUV79EOHTpI8+bNk/Lz821ePkyvCgCgEGjDBgBQCARsAACFQMAGAFAIBGwAAIVAwAYAUAgEbAAAhUDABgBQCARsAACFQMAGaAY88x4vG3XnBEgADYGADQCgEAjYAAAKgYANLQJPRcqrX/PUmLzQAy+Ku337dqvmip07d4rFA5ydnenhhx8WE9XX9PXXX4sFkPV6PYWHh9P7779v9Xx5eblYaSQ0NFSc06FDB/rkk0+szuEpUnmpL145e8CAAXetvg1wT7ac1QrAXi1dulSKjIwU01pevXpVzLTGM6vxlJnm2fS6dOki7dmzR0zj+tRTT0nh4eFSRUWF+HmeOpMXUeVpNHm2QP55nnWt5ox0L7zwghQaGip988034nfwVKlbtmwRz5l/R//+/cXvvHDhgjRo0CBpwIABsv1NQHkQsEH1eF5pntLz2LFjVsenTp0qpiw1B1NzcDVPZ8oBeevWreLxiy++KA0bNszq53kKzaioKLHPQZyvsXfv3lrzYP4dHMTNdu7cKY7VnNsb4F7QJAKqx8s08QrWw4YNI3d3d0v6/PPPxWo9ZjVX5eEFbnmh4/j4ePGYt7zwak38mFewr6qqEiuM8IK5gwcPvmdeuMnFzLwayZ3LfwHUBYvwQotYRo1xG3WbNm2snuO25ppBu7HquwAyL5Vlxu3m5vZ1gPpADRtUj9fM48DMawjyjcCaiW8Qmh0/ftyyn5ubS5cvX6YuXbqIx7w9evSo1XX5MS+AzDVrXimbA++hQ4easWTQ0qCGDarn4eFBb7zxBs2ZM0cE1YEDB1J+fr4IuLwIalhYmDjv3XffJT8/PwoMDKR//OMfYuXysWPHiudef/116tu3Ly1ZsoTGjx9PcXFx9OGHH9JHH30knudeI5MnT6a//vWvtGbNGtEL5caNG6K544UXXpC1/KAi92zhBlAJXhty9erVUufOncXaibyG4ogRI6RDhw5Zbgh+//33UteuXcV6mf369ZN+++03q2ts375d3GTkn+cFZVesWGH1PN88nDNnjmXNTV7bb+PGjeI58+/Izc21nG9elJcXbgWoD6zpCC0e98N+/PHHRTOIt7e33NkBqBPasAEAFAIBGwBAIdAkAgCgEKhhAwAoBAI2AIBCIGADACgEAjYAgEIgYAMAKAQCNgCAQiBgAwAoBAI2AAApw/8HTZM0mDMzpksAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs, device = 0.005, 250, try_gpu()\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size, num_steps)\n",
    "encoder = Seq2SeqEncoder(\n",
    "    len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "decoder = Seq2SeqAttentionDecoder(\n",
    "    len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "net = EncoderDecoder(encoder, decoder)\n",
    "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b038fc0",
   "metadata": {
    "origin_pos": 19
   },
   "source": [
    "模型训练后，我们用它[**将几个英语句子翻译成法语**]并计算它们的BLEU分数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6e2ca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"截断或填充文本序列\"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]  # 截断\n",
    "    return line + [padding_token] * (num_steps - len(line))  # 填充\n",
    "\n",
    "#@save\n",
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    \"\"\"序列到序列模型的预测\"\"\"\n",
    "    # 在预测时将net设置为评估模式\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
    "        src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    # 添加批量轴\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    # 添加批量轴\n",
    "    dec_X = torch.unsqueeze(torch.tensor(\n",
    "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        # 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        # 保存注意力权重（稍后讨论）\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        # 一旦序列结束词元被预测，输出序列的生成就完成了\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5483aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import collections\n",
    "\n",
    "def bleu(pred_seq, label_seq, k):  #@save\n",
    "    \"\"\"计算BLEU\"\"\"\n",
    "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
    "    for n in range(1, k + 1):\n",
    "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
    "        for i in range(len_label - n + 1):\n",
    "            label_subs[' '.join(label_tokens[i: i + n])] += 1\n",
    "        for i in range(len_pred - n + 1):\n",
    "            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n",
    "                num_matches += 1\n",
    "                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n",
    "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b449b8a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:17:05.738743Z",
     "iopub.status.busy": "2023-08-18T07:17:05.738202Z",
     "iopub.status.idle": "2023-08-18T07:17:05.773736Z",
     "shell.execute_reply": "2023-08-18T07:17:05.772225Z"
    },
    "origin_pos": 20,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => va !,  bleu 1.000\n",
      "i lost . => j'ai perdu .,  bleu 1.000\n",
      "he's calm . => sois un homme !,  bleu 0.000\n",
      "i'm home . => je suis chez moi .,  bleu 1.000\n"
     ]
    }
   ],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, dec_attention_weight_seq = predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "    print(f'{eng} => {translation}, ',\n",
    "          f'bleu {bleu(translation, fra, k=2):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "703a029f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:17:05.780446Z",
     "iopub.status.busy": "2023-08-18T07:17:05.779931Z",
     "iopub.status.idle": "2023-08-18T07:17:05.800143Z",
     "shell.execute_reply": "2023-08-18T07:17:05.798893Z"
    },
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "attention_weights = torch.cat([step[0][0][0] for step in dec_attention_weight_seq], 0).reshape((\n",
    "    1, 1, -1, num_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb0b7ce",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "训练结束后，下面通过[**可视化注意力权重**]\n",
    "会发现，每个查询都会在键值对上分配不同的权重，这说明\n",
    "在每个解码步中，输入序列的不同部分被选择性地聚集在注意力池中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa27cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5),\n",
    "                  cmap='Reds'):\n",
    "    \"\"\"显示矩阵热图\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    # 设置高分辨率显示\n",
    "    import matplotlib\n",
    "    matplotlib.rcParams['figure.dpi'] = 100\n",
    "    matplotlib.rcParams['savefig.dpi'] = 100\n",
    "    \n",
    "    num_rows, num_cols = matrices.shape[0], matrices.shape[1]\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize,\n",
    "                             sharex=True, sharey=True, squeeze=False)\n",
    "    \n",
    "    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\n",
    "        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\n",
    "            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)\n",
    "            if i == num_rows - 1:\n",
    "                ax.set_xlabel(xlabel)\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(ylabel)\n",
    "            if titles:\n",
    "                ax.set_title(titles[j])\n",
    "    \n",
    "    fig.colorbar(pcm, ax=axes, shrink=0.6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8074a1a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:17:05.806859Z",
     "iopub.status.busy": "2023-08-18T07:17:05.805665Z",
     "iopub.status.idle": "2023-08-18T07:17:06.012470Z",
     "shell.execute_reply": "2023-08-18T07:17:06.011495Z"
    },
    "origin_pos": 25,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 加上一个包含序列结束词元\n",
    "show_heatmaps(\n",
    "    attention_weights[:, :, :, :len(engs[-1].split()) + 1].cpu(),\n",
    "    xlabel='Key positions', ylabel='Query positions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eb6f85",
   "metadata": {
    "origin_pos": 27
   },
   "source": [
    "## 小结\n",
    "\n",
    "* 在预测词元时，如果不是所有输入词元都是相关的，那么具有Bahdanau注意力的循环神经网络编码器-解码器会有选择地统计输入序列的不同部分。这是通过将上下文变量视为加性注意力池化的输出来实现的。\n",
    "* 在循环神经网络编码器-解码器中，Bahdanau注意力将上一时间步的解码器隐状态视为查询，在所有时间步的编码器隐状态同时视为键和值。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 在实验中用LSTM替换GRU。\n",
    "1. 修改实验以将加性注意力打分函数替换为缩放点积注意力，它如何影响训练效率？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7906bc",
   "metadata": {
    "origin_pos": 29,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/5754)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
