{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52df7352",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 循环神经网络的从零开始实现\n",
    ":label:`sec_rnn_scratch`\n",
    "\n",
    "本节将根据 :numref:`sec_rnn`中的描述，\n",
    "从头开始基于循环神经网络实现字符级语言模型。\n",
    "这样的模型将在H.G.Wells的时光机器数据集上训练。\n",
    "和前面 :numref:`sec_language_model`中介绍过的一样，\n",
    "我们先读取数据集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafdcbcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:18:01.555032Z",
     "iopub.status.busy": "2023-08-18T07:18:01.554199Z",
     "iopub.status.idle": "2023-08-18T07:18:04.803287Z",
     "shell.execute_reply": "2023-08-18T07:18:04.802073Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "# from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be4f5d93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:18:04.809116Z",
     "iopub.status.busy": "2023-08-18T07:18:04.808214Z",
     "iopub.status.idle": "2023-08-18T07:18:05.026750Z",
     "shell.execute_reply": "2023-08-18T07:18:05.025592Z"
    },
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists at ../data\\timemachine.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import os\n",
    "import collections\n",
    "import random\n",
    "import torch\n",
    "\n",
    "class Vocab:  #@save\n",
    "    \"\"\"文本词表\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        # 按出现频率排序\n",
    "        counter = count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "        # 未知词元的索引为0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # 未知词元的索引为0\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs\n",
    "    \n",
    "def count_corpus(tokens):  #@save\n",
    "    \"\"\"统计词元的频率\"\"\"\n",
    "    # 这里的tokens是1D列表或2D列表\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # 将词元列表展平成一个列表\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n",
    "\n",
    "def download_time_machine(data_dir='../data', filename='timemachine.txt'):\n",
    "    \"\"\"下载时间机器文本文件\"\"\"\n",
    "    url = 'http://d2l-data.s3-accelerate.amazonaws.com/timemachine.txt'\n",
    "    \n",
    "    # 创建数据目录（如果不存在）\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    # 完整文件路径\n",
    "    file_path = os.path.join(data_dir, filename)\n",
    "    \n",
    "    # 如果文件不存在，则下载\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f'Downloading {filename} from {url}...')\n",
    "        response = requests.get(url)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f'File saved to {file_path}')\n",
    "    else:\n",
    "        print(f'File already exists at {file_path}')\n",
    "    \n",
    "    return file_path\n",
    "\n",
    "def read_time_machine():\n",
    "    \"\"\"将时间机器数据集加载到文本行的列表中\"\"\"\n",
    "    # 下载文件并获取路径\n",
    "    file_path = download_time_machine()\n",
    "    \n",
    "    # 读取文件内容\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # 处理每一行：只保留字母，转为小写，去除首尾空格\n",
    "    processed_lines = [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n",
    "    \n",
    "    return processed_lines\n",
    "\n",
    "def tokenize(lines, token='word'):  #@save\n",
    "    \"\"\"将文本行拆分为单词或字符词元\"\"\"\n",
    "    if token == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token == 'char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print('错误：未知词元类型：' + token)\n",
    "\n",
    "def load_corpus_time_machine(max_tokens=-1):  #@save\n",
    "    \"\"\"返回时光机器数据集的词元索引列表和词表\"\"\"\n",
    "    lines = read_time_machine()\n",
    "    tokens = tokenize(lines, 'char')\n",
    "    vocab = Vocab(tokens)\n",
    "    # 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，\n",
    "    # 所以将所有文本行展平到一个列表中\n",
    "    corpus = [vocab[token] for line in tokens for token in line]\n",
    "    if max_tokens > 0:\n",
    "        corpus = corpus[:max_tokens]\n",
    "    return corpus, vocab\n",
    "\n",
    "def seq_data_iter_random(corpus, batch_size, num_steps):  #@save\n",
    "    \"\"\"使用随机抽样生成一个小批量子序列\"\"\"\n",
    "    # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1\n",
    "    corpus = corpus[random.randint(0, num_steps - 1):]\n",
    "    # 减去1，是因为我们需要考虑标签\n",
    "    num_subseqs = (len(corpus) - 1) // num_steps\n",
    "    # 长度为num_steps的子序列的起始索引\n",
    "    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n",
    "    # 在随机抽样的迭代过程中，\n",
    "    # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻\n",
    "    random.shuffle(initial_indices)\n",
    "\n",
    "    def data(pos):\n",
    "        # 返回从pos位置开始的长度为num_steps的序列\n",
    "        return corpus[pos: pos + num_steps]\n",
    "\n",
    "    num_batches = num_subseqs // batch_size\n",
    "    for i in range(0, batch_size * num_batches, batch_size):\n",
    "        # 在这里，initial_indices包含子序列的随机起始索引\n",
    "        initial_indices_per_batch = initial_indices[i: i + batch_size]\n",
    "        X = [data(j) for j in initial_indices_per_batch]\n",
    "        Y = [data(j + 1) for j in initial_indices_per_batch]\n",
    "        yield torch.tensor(X), torch.tensor(Y)\n",
    "\n",
    "def seq_data_iter_sequential(corpus, batch_size, num_steps):  #@save\n",
    "    \"\"\"使用顺序分区生成一个小批量子序列\"\"\"\n",
    "    # 从随机偏移量开始划分序列\n",
    "    offset = random.randint(0, num_steps)\n",
    "    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n",
    "    Xs = torch.tensor(corpus[offset: offset + num_tokens])\n",
    "    Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n",
    "    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n",
    "    num_batches = Xs.shape[1] // num_steps\n",
    "    for i in range(0, num_steps * num_batches, num_steps):\n",
    "        X = Xs[:, i: i + num_steps]\n",
    "        Y = Ys[:, i: i + num_steps]\n",
    "        yield X, Y\n",
    "\n",
    "class SeqDataLoader:  #@save\n",
    "    \"\"\"加载序列数据的迭代器\"\"\"\n",
    "    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):\n",
    "        if use_random_iter:\n",
    "            self.data_iter_fn = seq_data_iter_random\n",
    "        else:\n",
    "            self.data_iter_fn = seq_data_iter_sequential\n",
    "        self.corpus, self.vocab = load_corpus_time_machine(max_tokens)\n",
    "        self.batch_size, self.num_steps = batch_size, num_steps\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)\n",
    "\n",
    "def load_data_time_machine(batch_size, num_steps,  #@save\n",
    "                           use_random_iter=False, max_tokens=10000):\n",
    "    \"\"\"返回时光机器数据集的迭代器和词表\"\"\"\n",
    "    data_iter = SeqDataLoader(\n",
    "        batch_size, num_steps, use_random_iter, max_tokens)\n",
    "    return data_iter, data_iter.vocab\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = load_data_time_machine(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80db8a1f",
   "metadata": {
    "origin_pos": 7
   },
   "source": [
    "## [**独热编码**]\n",
    "\n",
    "回想一下，在`train_iter`中，每个词元都表示为一个数字索引，\n",
    "将这些索引直接输入神经网络可能会使学习变得困难。\n",
    "我们通常将每个词元表示为更具表现力的特征向量。\n",
    "最简单的表示称为*独热编码*（one-hot encoding），\n",
    "它在 :numref:`subsec_classification-problem`中介绍过。\n",
    "\n",
    "简言之，将每个索引映射为相互不同的单位向量：\n",
    "假设词表中不同词元的数目为$N$（即`len(vocab)`），\n",
    "词元索引的范围为$0$到$N-1$。\n",
    "如果词元的索引是整数$i$，\n",
    "那么我们将创建一个长度为$N$的全$0$向量，\n",
    "并将第$i$处的元素设置为$1$。\n",
    "此向量是原始词元的一个独热向量。\n",
    "索引为$0$和$2$的独热向量如下所示：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5725a77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:18:05.032457Z",
     "iopub.status.busy": "2023-08-18T07:18:05.031682Z",
     "iopub.status.idle": "2023-08-18T07:18:05.042971Z",
     "shell.execute_reply": "2023-08-18T07:18:05.041878Z"
    },
    "origin_pos": 9,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor([0, 2]), len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d08204",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "我们每次采样的(**小批量数据形状是二维张量：\n",
    "（批量大小，时间步数）。**)\n",
    "`one_hot`函数将这样一个小批量数据转换成三维张量，\n",
    "张量的最后一个维度等于词表大小（`len(vocab)`）。\n",
    "我们经常转换输入的维度，以便获得形状为\n",
    "（时间步数，批量大小，词表大小）的输出。\n",
    "这将使我们能够更方便地通过最外层的维度，\n",
    "一步一步地更新小批量数据的隐状态。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a49de8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:18:05.047886Z",
     "iopub.status.busy": "2023-08-18T07:18:05.047143Z",
     "iopub.status.idle": "2023-08-18T07:18:05.054936Z",
     "shell.execute_reply": "2023-08-18T07:18:05.053897Z"
    },
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(10).reshape((2, 5))\n",
    "F.one_hot(X.T, 28).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32469879",
   "metadata": {
    "origin_pos": 17
   },
   "source": [
    "## 初始化模型参数\n",
    "\n",
    "接下来，我们[**初始化循环神经网络模型的模型参数**]。\n",
    "隐藏单元数`num_hiddens`是一个可调的超参数。\n",
    "当训练语言模型时，输入和输出来自相同的词表。\n",
    "因此，它们具有相同的维度，即词表的大小。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8ad7abe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:18:05.059740Z",
     "iopub.status.busy": "2023-08-18T07:18:05.059023Z",
     "iopub.status.idle": "2023-08-18T07:18:05.067363Z",
     "shell.execute_reply": "2023-08-18T07:18:05.066318Z"
    },
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def get_params(vocab_size, num_hiddens, device):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "\n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape, device=device) * 0.01\n",
    "\n",
    "    # 隐藏层参数\n",
    "    W_xh = normal((num_inputs, num_hiddens))\n",
    "    W_hh = normal((num_hiddens, num_hiddens))\n",
    "    b_h = torch.zeros(num_hiddens, device=device)\n",
    "    # 输出层参数\n",
    "    W_hq = normal((num_hiddens, num_outputs))\n",
    "    b_q = torch.zeros(num_outputs, device=device)\n",
    "    # 附加梯度\n",
    "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037e51a5",
   "metadata": {
    "origin_pos": 22
   },
   "source": [
    "## 循环神经网络模型\n",
    "\n",
    "为了定义循环神经网络模型，\n",
    "我们首先需要[**一个`init_rnn_state`函数在初始化时返回隐状态**]。\n",
    "这个函数的返回是一个张量，张量全用0填充，\n",
    "形状为（批量大小，隐藏单元数）。\n",
    "在后面的章节中我们将会遇到隐状态包含多个变量的情况，\n",
    "而使用元组可以更容易地处理些。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e310bbed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:18:05.072206Z",
     "iopub.status.busy": "2023-08-18T07:18:05.071312Z",
     "iopub.status.idle": "2023-08-18T07:18:05.076740Z",
     "shell.execute_reply": "2023-08-18T07:18:05.075653Z"
    },
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size, num_hiddens, device):\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device), )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c7e392",
   "metadata": {
    "origin_pos": 27
   },
   "source": [
    "[**下面的`rnn`函数定义了如何在一个时间步内计算隐状态和输出。**]\n",
    "循环神经网络模型通过`inputs`最外层的维度实现循环，\n",
    "以便逐时间步更新小批量数据的隐状态`H`。\n",
    "此外，这里使用$\\tanh$函数作为激活函数。\n",
    "如 :numref:`sec_mlp`所述，\n",
    "当元素在实数上满足均匀分布时，$\\tanh$函数的平均值为0。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a46eb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:18:05.081883Z",
     "iopub.status.busy": "2023-08-18T07:18:05.080930Z",
     "iopub.status.idle": "2023-08-18T07:18:05.088343Z",
     "shell.execute_reply": "2023-08-18T07:18:05.087321Z"
    },
    "origin_pos": 29,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def rnn(inputs, state, params):\n",
    "    # inputs的形状：(时间步数量，批量大小，词表大小)\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    # X的形状：(批量大小，词表大小)\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)\n",
    "        Y = torch.mm(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs, dim=0), (H,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d272d",
   "metadata": {
    "origin_pos": 32
   },
   "source": [
    "定义了所有需要的函数之后，接下来我们[**创建一个类来包装这些函数**]，\n",
    "并存储从零开始实现的循环神经网络模型的参数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a45ae30c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:18:05.093357Z",
     "iopub.status.busy": "2023-08-18T07:18:05.092334Z",
     "iopub.status.idle": "2023-08-18T07:18:05.101515Z",
     "shell.execute_reply": "2023-08-18T07:18:05.100380Z"
    },
    "origin_pos": 34,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class RNNModelScratch: #@save\n",
    "    \"\"\"从零开始实现的循环神经网络模型\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, device,\n",
    "                 get_params, init_state, forward_fn):\n",
    "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
    "        self.params = get_params(vocab_size, num_hiddens, device)\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "\n",
    "    def __call__(self, X, state):\n",
    "        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)\n",
    "        return self.forward_fn(X, state, self.params)\n",
    "\n",
    "    def begin_state(self, batch_size, device):\n",
    "        return self.init_state(batch_size, self.num_hiddens, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b19f1b",
   "metadata": {
    "origin_pos": 37
   },
   "source": [
    "让我们[**检查输出是否具有正确的形状**]。\n",
    "例如，隐状态的维数是否保持不变。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83809e58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:18:05.106127Z",
     "iopub.status.busy": "2023-08-18T07:18:05.105766Z",
     "iopub.status.idle": "2023-08-18T07:18:07.615027Z",
     "shell.execute_reply": "2023-08-18T07:18:07.613950Z"
    },
    "origin_pos": 39,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 28]), 1, torch.Size([2, 512]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_gpu(i=0):  #@save\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "num_hiddens = 512\n",
    "net = RNNModelScratch(len(vocab), num_hiddens, try_gpu(), get_params,\n",
    "                      init_rnn_state, rnn)\n",
    "state = net.begin_state(X.shape[0], try_gpu())\n",
    "Y, new_state = net(X.to(try_gpu()), state)\n",
    "Y.shape, len(new_state), new_state[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baefc97",
   "metadata": {
    "origin_pos": 42
   },
   "source": [
    "我们可以看到输出形状是（时间步数$\\times$批量大小，词表大小），\n",
    "而隐状态形状保持不变，即（批量大小，隐藏单元数）。\n",
    "\n",
    "## 预测\n",
    "\n",
    "让我们[**首先定义预测函数来生成`prefix`之后的新字符**]，\n",
    "其中的`prefix`是一个用户提供的包含多个字符的字符串。\n",
    "在循环遍历`prefix`中的开始字符时，\n",
    "我们不断地将隐状态传递到下一个时间步，但是不生成任何输出。\n",
    "这被称为*预热*（warm-up）期，\n",
    "因为在此期间模型会自我更新（例如，更新隐状态），\n",
    "但不会进行预测。\n",
    "预热期结束后，隐状态的值通常比刚开始的初始值更适合预测，\n",
    "从而预测字符并输出它们。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a98020e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:18:07.619431Z",
     "iopub.status.busy": "2023-08-18T07:18:07.619151Z",
     "iopub.status.idle": "2023-08-18T07:18:07.626388Z",
     "shell.execute_reply": "2023-08-18T07:18:07.625321Z"
    },
    "origin_pos": 44,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def predict_ch8(prefix, num_preds, net, vocab, device):  #@save\n",
    "    \"\"\"在prefix后面生成新字符\"\"\"\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
    "    for y in prefix[1:]:  # 预热期\n",
    "        _, state = net(get_input(), state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):  # 预测num_preds步\n",
    "        y, state = net(get_input(), state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375db47c",
   "metadata": {
    "origin_pos": 47
   },
   "source": [
    "现在我们可以测试`predict_ch8`函数。\n",
    "我们将前缀指定为`time traveller `，\n",
    "并基于这个前缀生成10个后续字符。\n",
    "鉴于我们还没有训练网络，它会生成荒谬的预测结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ea33551",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:18:07.630956Z",
     "iopub.status.busy": "2023-08-18T07:18:07.630335Z",
     "iopub.status.idle": "2023-08-18T07:18:07.646754Z",
     "shell.execute_reply": "2023-08-18T07:18:07.645688Z"
    },
    "origin_pos": 48,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time traveller dactrlactr'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ch8('time traveller ', 10, net, vocab, try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596cfaf3",
   "metadata": {
    "origin_pos": 50
   },
   "source": [
    "## [**梯度裁剪**]\n",
    "\n",
    "对于长度为$T$的序列，我们在迭代中计算这$T$个时间步上的梯度，\n",
    "将会在反向传播过程中产生长度为$\\mathcal{O}(T)$的矩阵乘法链。\n",
    "如 :numref:`sec_numerical_stability`所述，\n",
    "当$T$较大时，它可能导致数值不稳定，\n",
    "例如可能导致梯度爆炸或梯度消失。\n",
    "因此，循环神经网络模型往往需要额外的方式来支持稳定训练。\n",
    "\n",
    "一般来说，当解决优化问题时，我们对模型参数采用更新步骤。\n",
    "假定在向量形式的$\\mathbf{x}$中，\n",
    "或者在小批量数据的负梯度$\\mathbf{g}$方向上。\n",
    "例如，使用$\\eta > 0$作为学习率时，在一次迭代中，\n",
    "我们将$\\mathbf{x}$更新为$\\mathbf{x} - \\eta \\mathbf{g}$。\n",
    "如果我们进一步假设目标函数$f$表现良好，\n",
    "即函数$f$在常数$L$下是*利普希茨连续的*（Lipschitz continuous）。\n",
    "也就是说，对于任意$\\mathbf{x}$和$\\mathbf{y}$我们有：\n",
    "\n",
    "$$|f(\\mathbf{x}) - f(\\mathbf{y})| \\leq L \\|\\mathbf{x} - \\mathbf{y}\\|.$$\n",
    "\n",
    "在这种情况下，我们可以安全地假设：\n",
    "如果我们通过$\\eta \\mathbf{g}$更新参数向量，则\n",
    "\n",
    "$$|f(\\mathbf{x}) - f(\\mathbf{x} - \\eta\\mathbf{g})| \\leq L \\eta\\|\\mathbf{g}\\|,$$\n",
    "\n",
    "这意味着我们不会观察到超过$L \\eta \\|\\mathbf{g}\\|$的变化。\n",
    "这既是坏事也是好事。\n",
    "坏的方面，它限制了取得进展的速度；\n",
    "好的方面，它限制了事情变糟的程度，尤其当我们朝着错误的方向前进时。\n",
    "\n",
    "有时梯度可能很大，从而优化算法可能无法收敛。\n",
    "我们可以通过降低$\\eta$的学习率来解决这个问题。\n",
    "但是如果我们很少得到大的梯度呢？\n",
    "在这种情况下，这种做法似乎毫无道理。\n",
    "一个流行的替代方案是通过将梯度$\\mathbf{g}$投影回给定半径\n",
    "（例如$\\theta$）的球来裁剪梯度$\\mathbf{g}$。\n",
    "如下式：\n",
    "\n",
    "(**$$\\mathbf{g} \\leftarrow \\min\\left(1, \\frac{\\theta}{\\|\\mathbf{g}\\|}\\right) \\mathbf{g}.$$**)\n",
    "\n",
    "通过这样做，我们知道梯度范数永远不会超过$\\theta$，\n",
    "并且更新后的梯度完全与$\\mathbf{g}$的原始方向对齐。\n",
    "它还有一个值得拥有的副作用，\n",
    "即限制任何给定的小批量数据（以及其中任何给定的样本）对参数向量的影响，\n",
    "这赋予了模型一定程度的稳定性。\n",
    "梯度裁剪提供了一个快速修复梯度爆炸的方法，\n",
    "虽然它并不能完全解决问题，但它是众多有效的技术之一。\n",
    "\n",
    "下面我们定义一个函数来裁剪模型的梯度，\n",
    "模型是从零开始实现的模型或由高级API构建的模型。\n",
    "我们在此计算了所有模型参数的梯度的范数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "997a02ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:18:07.651414Z",
     "iopub.status.busy": "2023-08-18T07:18:07.650745Z",
     "iopub.status.idle": "2023-08-18T07:18:07.657007Z",
     "shell.execute_reply": "2023-08-18T07:18:07.655964Z"
    },
    "origin_pos": 52,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def grad_clipping(net, theta):  #@save\n",
    "    \"\"\"裁剪梯度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726d638a",
   "metadata": {
    "origin_pos": 55
   },
   "source": [
    "## 训练\n",
    "\n",
    "在训练模型之前，让我们[**定义一个函数在一个迭代周期内训练模型**]。\n",
    "它与我们训练 :numref:`sec_softmax_scratch`模型的方式有三个不同之处。\n",
    "\n",
    "1. 序列数据的不同采样方法（随机采样和顺序分区）将导致隐状态初始化的差异。\n",
    "1. 我们在更新模型参数之前裁剪梯度。\n",
    "   这样的操作的目的是，即使训练过程中某个点上发生了梯度爆炸，也能保证模型不会发散。\n",
    "1. 我们用困惑度来评价模型。如 :numref:`subsec_perplexity`所述，\n",
    "   这样的度量确保了不同长度的序列具有可比性。\n",
    "\n",
    "具体来说，当使用顺序分区时，\n",
    "我们只在每个迭代周期的开始位置初始化隐状态。\n",
    "由于下一个小批量数据中的第$i$个子序列样本\n",
    "与当前第$i$个子序列样本相邻，\n",
    "因此当前小批量数据最后一个样本的隐状态，\n",
    "将用于初始化下一个小批量数据第一个样本的隐状态。\n",
    "这样，存储在隐状态中的序列的历史信息\n",
    "可以在一个迭代周期内流经相邻的子序列。\n",
    "然而，在任何一点隐状态的计算，\n",
    "都依赖于同一迭代周期中前面所有的小批量数据，\n",
    "这使得梯度计算变得复杂。\n",
    "为了降低计算量，在处理任何一个小批量数据之前，\n",
    "我们先分离梯度，使得隐状态的梯度计算总是限制在一个小批量数据的时间步内。\n",
    "\n",
    "当使用随机抽样时，因为每个样本都是在一个随机位置抽样的，\n",
    "因此需要为每个迭代周期重新初始化隐状态。\n",
    "与 :numref:`sec_softmax_scratch`中的\n",
    "`train_epoch_ch3`函数相同，\n",
    "`updater`是更新模型参数的常用函数。\n",
    "它既可以是从头开始实现的`d2l.sgd`函数，\n",
    "也可以是深度学习框架中内置的优化函数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b5e10db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:18:07.661288Z",
     "iopub.status.busy": "2023-08-18T07:18:07.660940Z",
     "iopub.status.idle": "2023-08-18T07:18:07.671838Z",
     "shell.execute_reply": "2023-08-18T07:18:07.670625Z"
    },
    "origin_pos": 57,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "class Timer:  #@save\n",
    "    \"\"\"记录多次运行时间\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"启动计时器\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"停止计时器并将时间记录在列表中\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"返回平均时间\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"返回时间总和\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"返回累计时间\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist()\n",
    "\n",
    "class Accumulator:  #@save\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "#@save\n",
    "def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n",
    "    \"\"\"训练网络一个迭代周期（定义见第8章）\"\"\"\n",
    "    state, timer = None, Timer()\n",
    "    metric = Accumulator(2)  # 训练损失之和,词元数量\n",
    "    for X, Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            # 在第一次迭代或使用随机抽样时初始化state\n",
    "            state = net.begin_state(batch_size=X.shape[0], device=device)\n",
    "        else:\n",
    "            if isinstance(net, nn.Module) and not isinstance(state, tuple):\n",
    "                # state对于nn.GRU是个张量\n",
    "                state.detach_()\n",
    "            else:\n",
    "                # state对于nn.LSTM或对于我们从零开始实现的模型是个张量\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "        y = Y.T.reshape(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat, state = net(X, state)\n",
    "        l = loss(y_hat, y.long()).mean()\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            # 因为已经调用了mean函数\n",
    "            updater(batch_size=1)\n",
    "        metric.add(l * y.numel(), y.numel())\n",
    "    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb7b57",
   "metadata": {
    "origin_pos": 60
   },
   "source": [
    "[**循环神经网络模型的训练函数既支持从零开始实现，\n",
    "也可以使用高级API来实现。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fe4738f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:18:07.676190Z",
     "iopub.status.busy": "2023-08-18T07:18:07.675912Z",
     "iopub.status.idle": "2023-08-18T07:18:07.684203Z",
     "shell.execute_reply": "2023-08-18T07:18:07.683026Z"
    },
    "origin_pos": 62,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):  #@save\n",
    "    \"\"\"小批量随机梯度下降\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()\n",
    "\n",
    "from IPython import display\n",
    "class Animator:  #@save\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        \n",
    "        # 替换 d2l.use_svg_display()\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.rcParams['figure.figsize'] = figsize\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # 替换 d2l.set_axes，使用 lambda 函数直接配置参数\n",
    "        self.config_axes = lambda: self._set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def _set_axes(self, ax, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "        \"\"\"设置坐标轴标签、范围和比例\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        # 设置坐标轴标签\n",
    "        if xlabel:\n",
    "            ax.set_xlabel(xlabel)\n",
    "        if ylabel:\n",
    "            ax.set_ylabel(ylabel)\n",
    "        # 设置坐标轴范围\n",
    "        if xlim:\n",
    "            ax.set_xlim(xlim)\n",
    "        if ylim:\n",
    "            ax.set_ylim(ylim)\n",
    "        # 设置坐标轴比例\n",
    "        if xscale:\n",
    "            ax.set_xscale(xscale)\n",
    "        if yscale:\n",
    "            ax.set_yscale(yscale)\n",
    "        # 设置图例\n",
    "        if legend:\n",
    "            ax.legend(legend)\n",
    "        # 添加网格\n",
    "        ax.grid(True)\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "#@save\n",
    "def train_ch8(net, train_iter, vocab, lr, num_epochs, device,\n",
    "              use_random_iter=False):\n",
    "    \"\"\"训练模型（定义见第8章）\"\"\"\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = Animator(xlabel='epoch', ylabel='perplexity',\n",
    "                            legend=['train'], xlim=[10, num_epochs])\n",
    "    # 初始化\n",
    "    if isinstance(net, nn.Module):\n",
    "        updater = torch.optim.SGD(net.parameters(), lr)\n",
    "    else:\n",
    "        updater = lambda batch_size: sgd(net.params, lr, batch_size)\n",
    "    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)\n",
    "    # 训练和预测\n",
    "    for epoch in range(num_epochs):\n",
    "        ppl, speed = train_epoch_ch8(\n",
    "            net, train_iter, loss, updater, device, use_random_iter)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(predict('time traveller'))\n",
    "            animator.add(epoch + 1, [ppl])\n",
    "    print(f'困惑度 {ppl:.1f}, {speed:.1f} 词元/秒 {str(device)}')\n",
    "    print(predict('time traveller'))\n",
    "    print(predict('traveller'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a744039a",
   "metadata": {
    "origin_pos": 65
   },
   "source": [
    "[**现在，我们训练循环神经网络模型。**]\n",
    "因为我们在数据集中只使用了10000个词元，\n",
    "所以模型需要更多的迭代周期来更好地收敛。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60e0712a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:18:07.688319Z",
     "iopub.status.busy": "2023-08-18T07:18:07.688050Z",
     "iopub.status.idle": "2023-08-18T07:19:36.858051Z",
     "shell.execute_reply": "2023-08-18T07:19:36.857197Z"
    },
    "origin_pos": 66,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "困惑度 1.0, 34789.1 词元/秒 cpu\n",
      "time traveller with a slight accession ofcheerfulness really thi\n",
      "traveller with a slight accession ofcheerfulness really thi\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs, lr = 500, 1\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs, try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f058da1",
   "metadata": {
    "origin_pos": 68
   },
   "source": [
    "[**最后，让我们检查一下使用随机抽样方法的结果。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e672f727",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:19:36.861442Z",
     "iopub.status.busy": "2023-08-18T07:19:36.861161Z",
     "iopub.status.idle": "2023-08-18T07:20:58.207471Z",
     "shell.execute_reply": "2023-08-18T07:20:58.206663Z"
    },
    "origin_pos": 69,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "困惑度 1.6, 36499.7 词元/秒 cpu\n",
      "time traveller held in his hand was a glitteringmetallic framewo\n",
      "travellerit s against rearen the atren alithend the time tr\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAD/CAYAAADVGuzgAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAANJpJREFUeJztnQd0VNXWx//pvfeQQqiBkFAChF6EUAVBBMFCERsKIogPeD5BiuAHioggFhTERxGQJu1RpBN6DVJCKCkkBEJ6L/db+8SJSUhCEpPcuXf2b62zZu7cO3fOnvK/Z/bZZ289SZIkMAzDMFqPvtwdYBiGYSoGCzbDMIxCYMFmGIZRCCzYDMMwCoEFm2EYRiGwYDMMwygEFmyGYRiFYCh3B7SR/Px83L9/H1ZWVtDT05O7OwzDKARJkpCSkgJ3d3fo61f/eJgFuxRIrD09PeXuBsMwCiUyMhIeHh7Vfl4W7FKgkbXmTbe2toZSycnJwd69e9GrVy8YGRlBTajZNrXbp2bbHj9+DB8fn0INqW5YsEtB4wYhsVa6YJubmwsb1PbDULNtardP7bYRNeVK5UlHhmEYhcCCzTAMoxBYsBmGYRQC+7AZRgfJy8sr9LfWNvS6hoaGyMzMFP1QGsbGxjUSslcRWLAZRsfihGNjY5GYmChrH1xdXUUUlhLXOejr64tIEBLu2oYFuxyycpV39WeY8tCItbOzs4jUkEMwaWFaamoqLC0tZRup/tNFdTExMfDy8qr1948FuxxikjLhZC93LximeiD3g0asHRwcZBW97OxsmJqaKk6wCScnJyHaubm5tR6WqLx3qxaJSsiQuwsMU21ofNY0smaqjsYVIof/nQW7HKIT0uXuAsNUO0r0G2sTejK+fyzY5RCVyCNshmG0Bxbscoh+zCNshmG0BxbscohKyJS7CwzDVDN169bF4sWLoUQ4SqQcohN5hM0w2kC3bt3QokWLahHaM2fOwMLCAkqER9jlkJSRi+RMeVaDMQxTucU4ubm5FQ7LU2qkDAv2U4hkPzajYpFLz86VpdFrV5TRo0fj8OHD+Oqrr0SEBrVVq1aJ2927dyMwMBAmJiY4duwYwsPD8dxzz8HFxUUszGnTpg32799frkuEzrNixQoMHjxYCHnDhg2xfft2aCPsEnkKkY8z4OduI3c3GKbaycjJQ9MZ/5PltUMmt0NFf1Uk1Ddv3kSzZs0we/Zs8djVq1fF7bRp0/D555+jXr16sLOzE8vd+/Xrh08//VSI+OrVqzFgwADcuHFDrEwsi1mzZmHBggVYuHAhvv76a7z88su4d+8e7O21a+Ucj7CfAo+wGUZebGxsxGIVc3NzkYOEmoGBgdhHAh4cHIz69esLcW3evDneeustIe40Up4zZ47Y97QRM43iR4wYgQYNGmDevHli6fzp06ehbfAI+ylE8uIZRqWYGRngz9m9ZVmanpORVi3nat26dbFtEtpPPvkEO3fuFPk+yK+dkZGBiIiIcs8TEBBQeJ8mJKkaTlxcHLQNWUfYR44cEX9XqMIw+ZG2bt1abBnt1KlT4e/vL95AOmbkyJFiDX950Iel8XNpmq+vb5X7yCNsRq3Qb8Pc2FCWVl2rBS1KRHtMmTIFW7ZsEaPko0eP4uLFi0JDKHdJeZTMCUL9owuLtiGrYKelpYm/MMuWLXtiX3p6Os6fP4+PP/5Y3G7evFn4oQYOHPjU8/r5+Ymrq6bRZERViWDBZhjZIZdIXgVydxw/fly4N2gCkYSa3Cd3796FWpDVJdK3b1/RyvJb7du3r9hjS5cuRdu2bcXfm/ImECg5On1QFSUrK0s0DcnJycUSQNHVWYn5FzTJfuRKVF+TqNm2mrKPzkXRGTRylHP0qIkQ0fSlInh7e+PUqVO4ffu2iP7QhPCVtIV80DS469+/v/jNzpgxQ+wv+Volt0t7T8p6nzTno/dT40vXUNPfR0X5sJOSksSHYGtrW+5xYWFhwoVC6Rvbt2+P+fPnlyvwtJ9miUuiBwlZuflYv203bGo/V3m1UfLCpybUbFt126cZyJCf92kugtogJSWlwsfSROI777wjJhPJJ635V07nKJqilX7H48ePR6dOncQk5MSJE5GQkCDs1QzESHCp2k3RgRmds+g2CXLJYzTQueh4cumWjP0mz0BNoidVJiCyBiEhJt/ToEGDSt1Pb17Hjh2FP3rNmjVlnofiMukL2bhxY+EOoQ8wOjoaoaGhsLKyqvAI29PTE21nbsODTAOsf70NAr3toDToak8/eJpFr+28vTWNmm2rKfvoN0RhbxSHTIMZuSDJIaGl36MS/7lmZmYKNwtpRMn3MT4+Hm5ubmJwSROXOjnCpi/vsGHDxAe9fPnyco8t6mKhmd+goCDxd2rDhg0YO3Zsqc+heE1qJfG0s8CDmEzEpGQrWhSo70ruv67aVt32kQ+YBJJGpHIWDtC4GTR9URr6+vqi76V9NjX9XdRXilhTEDuNOCp71SL3SaNGjXDr1q1Kv3YdO9PCxTMMwzByo68EsSafNC0vrUpZI3KP0HJV+ptSWerYFuQb4EgRhmGg64JNYkpxktSIO3fuiPsUBUJi/cILL+Ds2bPCZ01/56iAKLWiEyY9evQQ0SNF4zAp7wD5mE6cOCHCe2gml1YxVRZPezNxy7HYDMNoA7L6sEmMu3fvXrg9efJkcTtq1CixAEaznJTSKhbl4MGDIt0iQaPnR48eFe6LiooS4kzOf8rKRbPFJ0+eFPcri7stCzajPrRxQYiSkGSM05BVsEl0yzO+Im9MyaD49evXo7rwsCsQ7JjkTGTn5sPYUKs9SAzz1MUnNGFGq4VpAEPbckRpaKqmU7SF0iYdJUnCw4cPCycdaxtFRInIhaOlCUyN9JGZk4/7iRmo66jMpOcMQ5A4+vj4iHDXp6V4qGnRozhmMzMzRYb16enpwcPD44lFM7UBC/ZTPhhPO3OExaWKiUcWbEbp0KiaFpHRgo+KLPWuCWh+ihaddOnSRZEhmUZGRrKINcGC/RQ87QsEm7P2MWqhrBji2oLEji4YtOhEiYItJ8pyIMmAl31BaB/HYjMMIzcs2BWceORIEYZh5IYFuwIuEYJdIgzDyA0LdoVdIizYDMPICwt2BUfYCek5SMlUZ+5lhmGUAQv2U7A0MYSdecFMNk88MgwjJyzYlXGLsB+bYRgZYcGuAB7sx2YYRgtgwa4AtNqRYMFmGEZOWLAr5RJhHzbDMPLBgl2JvNhcyIBhGDlhwa6ESyQqIV3WXLgMw+g2LNgVLGSgrweRZvVh6t/V1RmGYWoTFuwKQIUL3Gw4pwjDMPLCgl3pJFA88cgwjDywYFcQzinCMIzcsGBXEE21mUtRSXJ3hWEYHYUFu4IEN3URt4duxOFhCk88MgxT+7BgV5BGLlZo6WWL3HwJm89Hyd0dhmF0EBbsSvBia09x++uZSI7HZhim1mHBrgTPNneHubEBbj9Kw9l7CXJ3h2EYHYMFu5K5sfv7uxWOshmGYXRGsI8cOYIBAwbA3d0denp62Lp1a7H95HaYMWMG3NzcYGZmhp49eyIsLOyp5122bBnq1q0LU1NTBAUF4fTp09XW5xfbFLhFdl6O4Qo0DMPojmCnpaWhefPmQmBLY8GCBViyZAm+/fZbnDp1ChYWFujduzcyMzPLPOevv/6KyZMnY+bMmTh//rw4Pz0nLi6uWvoc6G2Hek4WyMjJw47LMdVyToZhmIpgCBnp27evaKVBo+vFixfjP//5D5577jnx2OrVq+Hi4iJG4sOHDy/1eYsWLcIbb7yBMWPGiG0S+507d+Knn37CtGnTSn1OVlaWaBqSk5PFbU5OjmgleaGVOxb8LwzrT0fghZYFLhJtRNP30mxQOmq2Te326YJtqhTs8rhz5w5iY2OFG0SDjY2NcHGEhISUKtjZ2dk4d+4cpk+fXviYvr6+OAc9pyzmz5+PWbNmPfH43r17YW5esMKxKFbZgL6egVhE8+OmXXB78hCtYt++fVArarZN7fap0bb09HTdFGwSa4JG1EWhbc2+kjx69Ah5eXmlPuf69etlvhYJPLlRio6wPT090atXL1hbW5f6nCPpF7HvWhweWNTH2L6Noa1Xe/pRBAcHw8iooJCwWlCzbWq3T822xcfH66Zg1yYmJiailYS+TGV9oUYEeQnB3nYpBtP7NRUZ/bSV8uxQOmq2Te32qdE2oxq2R2tVxtXVVdw+ePCg2OO0rdlXEkdHRxgYGFTqOVWlS0MnuFib4HFaNvZfK/56DMMwOiXYPj4+QmQPHDhQzFVB0SLt27cv9TnGxsYIDAws9pz8/HyxXdZzqoqhgT5eCPQQ9zkmm2EYrRXslStXVotzPTU1FRcvXhRNM9FI9yMiIkRc9vvvv4+5c+di+/btuHLlCkaOHClitgcNGlR4jh49emDp0qWF2+SL/uGHH/Dzzz/j2rVrGDdunAgf1ESNVCfD/lqqfiTsIf68XxBZwjAMo1WCTeFxNPodO3YsTpw4UeUXP3v2LFq2bCmaRmzpPi2WIf71r39hwoQJePPNN9GmTRsh8Hv27BELYjSEh4eLyUYNL774Ij7//HNxjhYtWogLAD2n5ERkdeDtYIF+/q6gtCIfbLyE7Nz8an8NhmGYfzTpGB0djd9//x2rVq1Ct27dUK9ePTGCHTVqVKV8xfTc8pIo0Sh79uzZopXF3bt3n3hs/PjxotUGswY2Q0h4PK7FJGPpwVuYHNyoVl6XYRjdo0ojbENDQwwePBjbtm1DZGSkWKiyZs0aeHl5YeDAgeJx8h3rAk5WJpgzqJm4v+zgLYRGc4EDhmG0dNKRXA2dOnUSk3q0SIV8zTTSrl+/Pg4dOgRd4NkAd5EUKi9fwuQNF5GVmyd3lxiGUSFVFmwKlSNfsZ+fn3BtUATHjh07xMQhuUyGDRsmhFtXoFG2o6Uxbj5IxVf7n56gimEYplYEmzLs0UpA8mGTO4QEet26dYXLyClJ0wcffCDcJbqCvYUx5g7yF/e/PRyOi5GJcneJYRiVUSXBdnZ2xuHDhxEaGipC7+zt7Z84xsnJSYy2dYk+zVzxXAt35FPUyIaLyMxh1wjDMDILdteuXdGqVatSky9RRj1NhIe3tzd0jVkD/cREZPjDNHy0JVT4tRmGYWQTbArhS0p6MhoiJSWlRhaoKAlbc2MsGBIAfT3gt/NReG/dBY7PZhhGPsGm2GkaQZckKipKpEDVdbr7OmPpS61gZKCHnVdiMPbnM0jPzpW7WwzD6NLCGVqFSEJNjZaEUzy2BkprSj7rPn361EQ/FUc/fzdRA/KtX87haNgjvLLiFFaObgsbc3VlJ2MYRksFW5PDg5Z7U9ktS0vLYomXqI7ikCFDqr+XCqVLIyf89/UgjFl5GucjEvHi9yFYPbYtnK3+XlrPMAxTI4JNdRIJEmbK2VE0pwdTdg3IDW+3x6s/nsb12BS8sDwEP4xsjcauVnJ3jWEYXfBh04IYFuuK4+tqjd/e7gAve3NEPE7HoGXHsfVCtNzdYhhGrYJNsdaarHh2dnZiu6zGPImXgzm2vtsRnRs6iorr7/96ER9vDeVl7AzDVL9L5Msvv4SVlVXh/dKiRJinr4ZcNaYtvjoQhiUHwvDLyXu4HJ2Eb15uhTq2ZnJ3j2EYtQh20bwgo0ePrqn+qB4DfT2RgrWlp60YZV+KTMSzS46KZe2UW5svhAzDVKsPm3KIlEZubq6oQM5ULFZ7x4RO8K9jg4T0HLy79jwGLD2Ggzfiys0RzjCM7lIlwX7vvfcwdOhQJCQkFD5248YNBAUFiSRQTMXwtDfHxrfb470eDWFhbIDQ6GSMWXkGw74Lwcnb8XJ3j2EYNQj2hQsXxKpGf39/7Nu3D8uWLRO5RXx9fXHp0qXq76WKMTUyEC6SI//qjjc6+8DEUB9n7iZg+Pcn8eqPp3ArLkXuLjIMo2TBpuIEx48fx/PPPy9WNk6aNAkrVqwQVWd4aXrVcLA0wUf9mwrhfqWdl1jWTisk+351FAv2XEdGNkeTMIyuU+UCBjt37sT69etFpRlbW1v8+OOPuH//fvX2TgdxsTYVE5AHJndDzybOyMmT8M2hcAR/eRgHrj2Qu3sMwyhNsN966y3hw546dSqOHj2Ky5cvi6Xp5CLZsGFD9fdSR+O2V4xqg+9fDRQhf1EJGRj781m8ufosIh+ny909hmGUItjkDjl16pSoKkNhaFQpfdeuXaK6+WuvvVb9vdRhevm5Yt/kLniraz0Y6uth758P0P3zQ5i66TLuPkqTu3sMw2i7YJ87dw7Nmzd/4vF3331X7GOqF3NjQ0zv2wQ73+uMTg0ckZsv4dezkXjmi0OY9OtF3IpLlbuLDMNoq2CbmJggPDwc//nPfzBixAjExcWJx3fv3i1isZmagRJGUfa/38Z1QLfGTqIU2ZYL0cK//fYv5wpWTkYl8nJ3hlEplcrWp4HqOfbt2xcdO3bEkSNH8Omnn4o6jxTSR5OPmzZtqv6eMsUyANISdxLnr/+4hX1/PsCeq7GiEcYG+vB1s0Izdyu4srubYXR7hD1t2jTMnTtXxGDTZKOGZ555BidPnqzO/olUrpqiCUUbuV/KWoVZ8li1ZhYM8LAVqVp3T+yMCc80EPm3bc2NkJ2Xj8tRSVh7OgpfXzXAhQiu4M4wOjvCvnLlCtauXfvE4zTK1mT0qy7OnDkjqtlooErtwcHBIkqlLKytrcXKSw1qz8/RxM1aNIKWtVNEyaWoRKw5eQ8htx/jrTUXsOWdjqjraCF3VxmGqW3BprjrmJgY+Pj4PLECsk6dOqhOnJycim1/9tlnYuEOVW4vC03kSkXJysoSTUNycrK4zcnJEU1puFoZwbWJE9p5WWHw14cRmZaD0StPY8ObbWFn/vc/IiWj+VyU+Pnoun26YJtWCfbw4cNFDPbGjRuFOObn54tQvylTpmDkyJGoKbKzs/Hf//4XkydPLnfUnJqaCm9vb9EvWjI/b948+Pn5lXn8/PnzMWvWrCce37t3L8zNzaFk3vAFvrxigLvx6Ri+9CDeaZoHoyovl9I+yC2nZtRsnxptS0+v2UkjPakKqeFIOMmHTP5icldQMV66femll8RjBgYGNdJZWpRDrxEREQF3d/dSjwkJCUFYWBgCAgKQlJSEzz//XEyMXr16FR4eHhUeYXt6egr3DrlXlHy1px9F3eYd8Mqq80jJzEX/Zq5YNNQf+vrKdhNpbCP3mJGR+gobq9k+NdsWHx8PNzc3oT01oR1VGmHTROMPP/yAjz/+WPiUaURLFdUbNmyImoQiUCg6pSyxJmipPDUNHTp0QJMmTfDdd99hzpw5ZYYpUisJfZnU8IVqWscW370SiJE/ncbO0Fh4OVpgah9fqAG1fEa6aJ8abTOqYXuqJNgavLy8RKsN7t27h/3792Pz5s2VfgPpYnLr1i3oMh0aOOKzIQGYsvESlh8Kh7WpEcZ1qy93txiGqQnBJr9xRVm0aBGqm5UrV4oolP79+1fqeeSqoaiWfv36Qdd5IdADMYkZ+GLfTfzfnutIzMjGtD6+qo+iYRidE2yKAKkINfHjp8lDEmwqU0b+8qLQJCdFptDEIUH5TNq1a4cGDRogMTERCxcuFKPz119/vdr7pUQm9GgIY0N9zN99Hd8dvo3kjFzMHdRMlC5jGEYlgn3w4EHIBblCaKKxtMRS9Li+/t9hD1QF54033kBsbKyo7h4YGIgTJ06gadOmtdxr7eWtrvVhY2aEf2+5gnWnI5CcmYMvh7UQQs4wjPbyj3zYRGRkpLilqIqaolevXmXWOTx06FCxbaroTo0pn+FtvWBtZoSJ6y9g5+UYpGbm4ttXAmFmXDMRPgzD/HOqNKSiBE8UIULVZWjpODW6T8mg1BgMr1b6+bvhx1FtYGZkgMM3H2L4DycRlcDJRxhGVYI9YcIEfP/991iwYIHwbVOj+xR2RwV6GeVA+UcoAyC5SC5FJqL/kmPY+1cSKYZhVOASoTwiVB6MYqI10EIVcotQutXly5dXZx+ZWsj+t2NCJ4xfd0GI9pu/nMOYjnUxra8vTAzZRcIwis+HTW6QklBukaLZ+xjl4Glvjo1vtcebXeqJ7ZXH72LI8hNc1YZhlC7Y48ePF6sGiy7npvuUF5v2McqEokT+3a8JfhrdGnbmRgiNTsazXx/D9M2XhZskLYuLUzCM4lwi5LM+cOCAyM2hKRVGxQsox0iPHj3w/PPPFx5b2ZWJjPw84+uCXRM7Y+K6izh99zHWnY4UjQojBNWzR/fGzujTzBXutmZyd5VhdIoqp1cdMmRIscdqMqyPqX3cbMyw7s12OBr2EAevx+GPG3GIfJyBo2GPRFv4vxtYODQAzwaUndeFYRiZBZvioSkVKeWpNjPjEZaaodWP3Ro7i/aJJCH8YRoO3YjD9kv3RUWb8WsvCLfJh70b80pJhtFGHzYJNi37joqKqpkeMVoJpRxo4GyJ1zvXw+ZxHfDWX5OT3x4Ox5hVZ5CUzvH3DKN1gk3LwCmNKuV9ZXQTQwN9TO/XBEtGtISpkT6O3HyIgcuO4UZsitxdYxhVU6UoESrT9eGHH4pc2IzuMrC5O34b1wEedma4F5+Owd8cx57QGLm7xTCqpUqCTRnyTp8+LSJEyI9tb29frDG6g5+7DbaP74SODRyQnp2Ht/97HksOhJWZ+4VhmFqOElm8ePE/eElGbdhbGOPnMW3x6a5rYsHNon03cfNBCha+0JyTSTGM3IJNeakZpqRfe+YAPzRyscLHW0Ox43KMcJN8PzJQhAgyDPPPqXIC5PDwcJGdj3KHxMXFicd2794tit0yusuItl5Y83qQGHVfiU7CwKXHcT4iQe5uMYzuCvbhw4fh7++PU6dOiZWMVIRXs9px5syZ1d1HRmEE1XPAtnc7orGLFR6mZGHYtyGYt+saUnlpO8PUvmBPmzYNc+fOFaXqiyZ7euaZZ3Dy5Ml/1iNGNcmkfnunA/r7uyE3X8L3R26j5xeHsePyfZ6QZJjaFGwqajt48OAnHqciuY8ePapqXxiVYWliiGUvtxLJpLzszRGbnClWR77642mEPyz4V8YwTA0LNuUSiYmJKTUpFBXEZZiSyaT2TuqC93sWFAA+dusR+iw+gl/PRMjdNYZRv2APHz4cU6dOFYVuackyVTU/fvw4pkyZImK0GaYkpkYGeL9nI+yb1AXdGzshJ0/Cv7eEitJkDMPUoGDPmzcPvr6+IkMfTThSRfLOnTujQ4cOInKEYcrC28ECP41ugyGtPJCXL2H8mvO8pJ1halKwaaLxhx9+wO3bt7Fjxw6sWbMGN2/exC+//AIDA14owZQP/Sub/7w/2vrYIyUrF6+tOiOiSRiGqaE4bCq4SzUdafLxlVdewaBBg7BixYqqno7RMciX/d0rgajrYI7oxAy8+ctZZObkyd0thlGfYM+YMQMTJ07EgAEDsHHjRtHo/qRJk8Q+hqkIdhbGwj1CFdsvRCRiysZLyM/nkD+Gqdal6VQVnVwitMpRw8CBA0Xl9AkTJmD27NlVOS2jg9RzssTyV1ph5I+nxXL2eo4WmNyrsdzdYhj1jLBzcnLQunXrJx4PDAxEbm71rWb75JNPhL+zaKPJzvKg0T4dY2pqKlZj7tq1q9r6w9QMHeo7Yt7z/uL+kj9u4fdL9+XuEsOoR7BfffVVMcouyffff4+XX34Z1Ymfn5+I+da0Y8eOlXnsiRMnxKh/7NixIiac/OrUOG+39jOstWdhFZsPN13C1ftJcneJYdThEtFMOu7duxft2rUT25RXJCIiQsRhT548ufC4RYsW/bMOGhrC1dW1Qsd+9dVX6NOnjyiuQMyZM0csn1+6dCm+/fbbf9QPpub5Vx9fXItNERVs3lx9DtvHd4SDpYnc3WIYZQs2jVhbtWpVmLWPcHR0FK3oaJZcGP+UsLAwuLu7CxdH+/btMX/+fHh5eZV6bEhISLGLBdG7d29s3bq13NfIysoSTUNycnKh64eaUtH0XUk2LHqhGYZ8ewr3HqfjnTXnsHJUIIwM9FVhW2VQs326YFtNoSdpcSYeStdKC3MaN24s3CFUrT06OlpcFKysrEqND//555+LTYZ+88034nkPHjwo11dOx5Rk7dq1MDc3r0aLmIoQkw58ecUAWfl66OKajyE++XJ3iWEqRHp6Ol566SUkJSXB2toaWuMSqQ0ozlsDRaAEBQXB29sbGzZsEH7q6mL69OnFRuY0wqZVnL169aqRN702r/bkEgoODoaRkRGUhLdfHMatvYgjsfro294fL7SqoxrbKoKa7VOzbfE1XJxcqwW7tKRTjRo1wq1bt0rdT77ukiNp2n6aD9zExES0ktCXSQ1fKCXa0TegDt6PS8Pi/WGYuf0afN1s0NLLThW2VQY126dG24xq2J4qr3SUA3KPkM/czc2t1P3k4z5w4ECxx+hKTo8zyuO9ZxqiV1MXZOfl41+bLiM3j10jjG6j1YJN2f+ous3du3dFyB4tg6dcJRofNUWkkDtDA62+3LNnD7744gtcv35d+KbPnj2L8ePHy2gFU1X09fWwcGhz2JobISwuFb+dj5K7SwwjK1ot2FFRUUKcadJx2LBhcHBwEBVtnJycxH4KIyyal5uyBdJEIcWDN2/eHJs2bRIRIs2aNZPRCuafQMvWx3dvIO5/uS8MGdmcb4TRXbTah71+/fpy9x86dOiJx4YOHSoaox5ebe+NlcfviiRRK0/cwTvdCgScYXQNrR5hMwxhYmiAD3o1EveXHwpHQlq23F1iGFlgwWYUwaAWddDEzRopmblYdrD0KCGGUTss2IxiJiCn9S1I/LU65B6iEjLk7hLD1Dos2Ixi6NLQER3qO4gwv8UHeJTN6B4s2IxioNw00/s2Efe3X45BVJrcPWKY2oUFm1EU/h42GNDcHZQBZ9s9feEa4So1jK6g1WF9DFMaU3o1wp7QGNxM0kf3RUdhYqgPH0cL0eo5WWBooCfqOlrI3U2GqXZ4hM0oDm8HC8wf5AcXMwlGBnrIys3H9dgU7A6NxbKD4Riy/ASiEtLl7ibDVDs8wmYUyXMt3GF0/yJ69Q7Gg9Rc3HmUhvCHqdh4Ngo3HqTg9Z/P4rdxHWBhwl9xRj3wCJtRNIYG+sL90d3XGa93roeVY9rA0dJEjLgn/XqR/duMqmDBZlSFu60Zvh8ZCGNDfez98wG+2HdD7i4xTLXBgs2ojlZedvjsryrs5NPedjFa7i4xTLXAgs2okudbeeDtrvXF/Q83XcbFyES5u8Qw/xgWbEa1fNi7MXo2cUZ2bj7eWH0WMUm8nJ1RNizYjGox0NfD4uEt0djFCg9TskTkSHp2rtzdYpgqw4LNqBpLE0OsGNUaDhbGuHo/Ge+v58gRRrmwYDOqx9PevCByxKAgcmThXo4cYZQJCzajEwR622PBCwGFRRA2neP6kIzyYMFmdIZBLesU1oecvvkyTt95LHeXGKZSsGAzOsXk4Ebo5++KnDwJb/1yFhHxnHOEUQ4s2IzOVa75YmgL+NexQUJ6Dkb8cBLXYpLl7hbDVAgWbEbnMDM2EJEj3g7mohI7Zff739VYubvFME+FBZvRSVysTbH1nY6i5Fh6dh7e+uUcvj4QBokqIzCMlsKCzegsdhbG+Pm1thjdoa7Y/mLfTYxfdwEZ2Xlyd41hSoUFm9FpjAz08clAP8x/3l8UQ9h5OQYvfHsCsUmZcneNYZQl2PPnz0ebNm1gZWUFZ2dnDBo0CDdulL/oYdWqVaJYa9Fmampaa31mlMmItl5Y83q7whWRg785juuxPBnJaBdaLdiHDx/Gu+++i5MnT2Lfvn3IyclBr169kJZWfrlsa2trxMTEFLZ79+7VWp8Z5dLWxx5b3+2IBs6WiEnKxNDlITh+65Hc3WKYQrS6ftKePXueGD3TSPvcuXPo0qVLmc+jUbWrq2st9JBR4zL2397ugDd+OSsW1oxeeRr/NyRApGtlGLnRasEuSVJSkri1t7cv97jU1FR4e3sjPz8frVq1wrx58+Dn51fm8VlZWaJpSE4u+CtMI3pqSkXTdyXbIIdt5kbATyNbYermUOy8EovJGy4hMj4N47r6iMFAbcCfnTLJqWGb9CSFxDGR+A4cOBCJiYk4duxYmceFhIQgLCwMAQEBQuA///xzHDlyBFevXoWHR+mjpE8++QSzZs164vG1a9fC3Ny8Wu1glAMl9dsRoY8D9ws8h01s89HSQUITWwnWxnL3jtFG0tPT8dJLLwntIdeszgr2uHHjsHv3biHWZQlvWVe8Jk2aYMSIEZgzZ06FR9ienp549OhRjbzptQXZTr7/4OBgGBkZQU3Upm3/PRWBOTuvCwHX0MzdGl0bOaJbI0exapJyb1cn/Nkpk/j4eLi5udWYYCvCJTJ+/Hjs2LFDjJQrI9YEfSFatmyJW7dulXmMiYmJaKU9Vw1fKLXYIZdtYzrVR7v6Tth9JQYHbzzElegkhN5PFm3ZodsisoSqtlN1m04NnUQO7uqCPztlYVTD9mi1YNPgf8KECdiyZQsOHToEHx+fSp8jLy8PV65cQb9+/Wqkj4xu0MTNWrTJvRojLiUTh288xKEbD3Hk5kPEp2WLdK3UKOd2UD17BDd1QW8/V7GikmF0QrAppI/8yNu2bROx2LGxBfkebGxsYGZmJu6PHDkSderUETHbxOzZs9GuXTs0aNBA+LsXLlwowvpef/11WW1h1IOzlSmGtvYUjepFnr37GAeux+HAtQe4G5+Oo2GPRJux7SpaedmibzM39GnmKiJQGEa1gr18+XJx261bt2KPr1y5EqNHjxb3IyIioK//dzh5QkIC3njjDSHudnZ2CAwMxIkTJ9C0adNa7j2jCxgb6qNDA0fR/tO/CW4/ShPC/b+rD3DuXgLORySK9umua/Bzt0ZLL9vC0bqvqxXMjbX6J8hoGVr9banIfCi5Sory5ZdfisYwtQ2F/NV3shTtzS718SA5U2QB3H0lFqfuxIsVlNT+Ph6o62CBTg0cRZ5uym3CMIoVbIZRMuS/Htm+rmiP07JxNOwh/oxJxrWYFJGDmyq533mUJtquKzEip8mzAW61FuvNKA8WbIapBewtjPFcizqiaXiUmoWLEYlY8L/ruPkgFRPWXcC2i9GYM6gZHM3//mlSzm5ys+y/Foek9Gz41bFBADUPWzR0sRQJrBjdgAWbYWTC0dIEPZu6oEsjJ3xz6BaWHbwlRPnU7SOY8Ex9nI/Ux3ffhODPmJRiz7sUlYS1f903MdRHU3dr4VpxszGFm60Z3G1M4WpjCi97c1iZVj3MLD07V9yyn1174E+CYbRg4vL9nlRr0g1Tf7uMCxGJmLebslLSyDkFtCYn0NtOhAq625qJOPArUQUtJStXHE+tJORZ8XW1Rpu6dmhT114kt6pImCFFvmguIFT70sXaBN4OFvBxsIC3o7m4pYgXDzsz2JgZsQunFmHBZhgtoZGLFTa93QE/n7iLX89EwCQnGS919UewnxscLP9e2PVsgLu4zc+XcDc+TSzgiU7IQExSBu4nZopbyjZIfnPylVNbHVKQsdLT3kyEGb4c5CVEuCSh0UmYsvESrsf+Pap/kJwlWmlV5q1MDOFhbw5POzM4W5vA1swYtuZGQshtzY3hYGmMxi5WsKjkYqKcvHwR577lQpTITU7PtzQxLLy1NjNCD19nBHjYaNUFIyEtu0bPz4LNMFoELXF/rZMPXg3ywK5du9CvVZ0yV89RQeF6TpailUZccibO3ksQQnvm7mMh3JGPM/D9kdv44ehtdG3khFfbeaNbY2fk5udjyYEwfHv4NvLyJeFznzXQD50bOorY8rt/TY7ei08T21EJ6XiUmi1G+JqLQlmQntZztBBL+JvVsUETVwskZReM5EuadiM2BRvPRmLrxWhx/vJYciAMTd2sMSLIC8+1cIf1U9w/yZk5CI1KEi6lK9GJSEjLERcZV2tTOFubin8S9A+kkbMVbCgDWAXJ/evisvFcJPZfuouahAWbYVQKiRC5WagRKZk5OBEej7WnInD4ZsFKTWrk2iBfePjDgjzz/QPcMHugX+GovoW5MVp42j5xfiqlRsIdSe1xhljxSZOiiRk5SEzPEbexSRlidE7nprb14v2/nm2IGef2ixE6hTNSy8rJKzayd7Q0xuCWddDKy07U3UzLzkVqVi7SsnJxLz4de/98IKJuPt4aink7r2FAczd0bOCItKw8YWtKZq64pX7Rcbf/sq8i1HUwh7+HLZp7FEzu1nOyEP9ocvIlIdD0D4DOvzs0FpvP08WlIBdRfl7NpmZiwWYYHYEmIGm5PDUaMa85dQ8bzkYhKiGjcBJ07iA/9GlWIPAVqT7f0MVKtPKg8MXQ+0lidCv879FJQsgl6IkROrWIx+niWCrT1sPXBUNbe4jJ2PIiYBLTs4VYrjsdgbC4VGELtfKgi1PAXyJMI2rqW4HLJxNxyVkiIoea+FcRn47fL2kuMOVD+WTo4tKznjnaL0aNwYLNMDpIXUcLfNS/KSYHN8bvl+8j6nE6xnT0qZHFO05WJuje2Fk0Tba+HTt3oWP3nkjNlpCQno3HaTnIzMkTI2Ryx1QEW3Nj4T4a07EuzkckYP3pSDHapwuTlamhcJFobin8kVwyRecCyrsQXP7r4nIpMlHcj03OFJO/hgb6MNLXg5GhvriY0D+PoYEeIvkXbVO2vpqEBZthdBgaJQ9r7Vnrr0viZ2duDGebf57dTk9PD4He9qJVB3QhoNE9NQ3kDqE5A7nhiHuGYZinoA1iTbBgMwzDKAQWbIZhGIXAgs0wDKMQWLAZhmEUAgs2wzCMQuCwvnIKJ1D1dCVD8a7p6enCDrUVO1WzbWq3T822paSkVLj4SlVgwS7nTff0rP34VIZhlE98fLyoPVvd6Ek1dSlQMPn5+bh//74o/KtNmcAqC41g6KITGRkJa2trqAk126Z2+9RsW1JSEry8vERtWVvbJ/Ov/FN4hF0KVNTXw8MDaoF+FGr7YeiCbWq3T8226RcpDF6t562RszIMwzDVDgs2wzCMQmDBVjEmJiaYOXOmuFUbarZN7faxbVWHJx0ZhmEUAo+wGYZhFAILNsMwjEJgwWYYhlEILNgMwzAKgQVbYRw5cgQDBgyAu7u7WIW5devWYvtpDnnGjBlwc3ODmZkZevbsibCwsGLHPH78GC+//LJYtECrscaOHYvU1FTIzfz589GmTRuxwtTZ2RmDBg3CjRs3ih2TmZmJd999Fw4ODrC0tMSQIUPw4MGDYsdERESgf//+MDc3F+f58MMPkZubC7lZvnw5AgICCheMtG/fHrt371aFbUX57LPPxHfz/fffV4Vtn3zyibCnaPP19ZXHNooSYZTDrl27pI8++kjavHkzRfdIW7ZsKbb/s88+k2xsbKStW7dKly5dkgYOHCj5+PhIGRkZhcf06dNHat68uXTy5Enp6NGjUoMGDaQRI0ZIctO7d29p5cqVUmhoqHTx4kWpX79+kpeXl5Samlp4zNtvvy15enpKBw4ckM6ePSu1a9dO6tChQ+H+3NxcqVmzZlLPnj2lCxcuiPfL0dFRmj59uiQ327dvl3bu3CndvHlTunHjhvTvf/9bMjIyEvYq3TYNp0+flurWrSsFBARIEydOLHxcybbNnDlT8vPzk2JiYgrbw4cPZbGNBVvBlBTs/Px8ydXVVVq4cGHhY4mJiZKJiYm0bt06sf3nn3+K5505c6bwmN27d0t6enpSdHS0pE3ExcWJvh4+fLjQFhK4jRs3Fh5z7do1cUxISIjYph+Dvr6+FBsbW3jM8uXLJWtraykrK0vSNuzs7KQVK1aowraUlBSpYcOG0r59+6SuXbsWCrbSbZs5c6YY4JRGbdvGLhEVcefOHcTGxgo3iAbKGBYUFISQkBCxTbfkBmndunXhMXQ85T44deoUtC2RDmFvX1AN+9y5cyI1Z1H76K8pJdspap+/vz9cXFwKj+ndu7dIOHT16lVoC3l5eVi/fj3S0tKEa0QNtpFbgP72F7WBUINtYWFhwg1Zr1494U4kF4cctnHyJxVBYk0U/WJotjX76JZ8aEUxNDQUoqg5RlsyJpIPtGPHjmjWrJl4jPpnbGz8RBa0kvaVZr9mn9xcuXJFCDT5PcnfuWXLFjRt2hQXL15UtG108Tl//jzOnDnzxD6lf25BQUFYtWoVGjdujJiYGMyaNQudO3dGaGhordvGgs1oJTRaox/EsWPHoCboR0/iTP8eNm3ahFGjRuHw4cNQMpQmdeLEidi3bx9MTU2hNvr27Vt4nyaNScC9vb2xYcMGMbFfm7BLREW4urqK25Iz1LSt2Ue3cXFxxfbTbDVFjmiOkZvx48djx44dOHjwYLE0t9S/7OxsJCYmlmtfafZr9skNjcYaNGiAwMBAERXTvHlzfPXVV4q2jdwC9J1q1aqV+LdGjS5CS5YsEfdpNKlU20qDRtONGjXCrVu3av1zY8FWET4+PuILcODAgcLHyE9Gvmn6G07QLX256Eem4Y8//hAuCBo5yAnNo5JYk5uA+kT2FIVEjkpKFbWPwv7In1jUPnI7FL0o0ciPwujI9aBt0PuelZWlaNt69Ogh+kX/HDSN5kjI16u5r1TbSoNCYMPDw0XobK1/blWeOmVkm4mn0CBq9PEtWrRI3L93715hWJ+tra20bds26fLly9Jzzz1Xalhfy5YtpVOnTknHjh0TM/vaENY3btw4EZJ46NChYiFU6enpxUKoKNTvjz/+ECFU7du3F61kCFWvXr1EaOCePXskJycnrQgPmzZtmoh4uXPnjvhsaJuic/bu3at420pSNEpE6bZ98MEH4jtJn9vx48dFeB6F5VEUU23bxoKtMA4ePCiEumQbNWpUYWjfxx9/LLm4uIhwvh49eoiY36LEx8cLgba0tBShRWPGjBEXArkpzS5qFJutgS4877zzjgiHMzc3lwYPHixEvSh3796V+vbtK5mZmYkfFv3gcnJyJLl57bXXJG9vb8nY2Fj8YOmz0Yi10m17mmAr2bYXX3xRcnNzE59bnTp1xPatW7dksY3TqzIMwygE9mEzDMMoBBZshmEYhcCCzTAMoxBYsBmGYRQCCzbDMIxCYMFmGIZRCCzYDMMwCoEFm2EYRiGwYDNMLXDo0CFRWqpkkiCGqQws2AzDMAqBBZthGEYhsGAzOgGlMaX805SylZLOUx5qKiBQ1F2xc+dOkaCekvC3a9dOFFAoym+//QY/Pz+YmJigbt26+OKLL4rtpzSpU6dOhaenpziG8l7/+OOPxY6htLaUbpSqZ3fo0OGJqvAMUy7Vkc2KYbSduXPnSr6+viK1ZXh4uMgASNkMKW2mJgNikyZNRPY8Sn367LPPiurf2dnZ4vmUNpMKqc6ePVtkP6TnU+a1opkEhw0bJqpnU0V7eo39+/dL69evF/s0rxEUFCRe8+rVq1Lnzp2LVddmmKfBgs2onszMTJH28sSJE8UeHzt2rEgzqxFTjbhqUtCSIP/6669i+6WXXpKCg4OLPf/DDz+UmjZtKu6TiNM5qGJ4aWheg0Rcw86dO8VjRXOVM0x5sEuEUT1Uyik9PR3BwcGi8K2mrV69WlQO0aCpEEJQUWKqv3jt2jWxTbdUELgotE3VtKkCOlVWMTAwQNeuXcvtC7lcNFDFEqJkyTaGKQsuwsuoHirpRJCPuk6dOsX2ka+5qGhXlYoWY6VyUhrIb67xrzNMReARNqN6qG4eCTPV2aOJwKKNJgg1nDx5svB+QkICbt68iSZNmohtuj1+/Hix89I2FWOlkbW/v78QXqVXQGe0Gx5hM6rHysoKU6ZMwaRJk4SodurUCUlJSUJwqRCqt7e3OG727NlwcHAQVb4/+ugjODo6YtCgQWLfBx98gDZt2mDOnDl48cUXERISgqVLl+Kbb74R+ylqZNSoUXjttddEtXCKQrl3755wdwwbNkxW+xkVUa6Hm2FUAtW6XLx4sdS4cWPJyMhI1FTs3bu3KIqrmRD8/fffJT8/P1G7r23bttKlS5eKnWPTpk1ikpGeT0VXFy5cWGw/TR5OmjSpsP5fgwYNpJ9++kns07xGQkJC4fGaQspU3JVhKgLXdGR0HorD7t69u3CD2Nrayt0dhikT9mEzDMMoBBZshmEYhcAuEYZhGIXAI2yGYRiFwILNMAyjEFiwGYZhFAILNsMwjEJgwWYYhlEILNgMwzAKgQWbYRhGIbBgMwzDQBn8P0dUr/QZPrb/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = RNNModelScratch(len(vocab), num_hiddens, try_gpu(), get_params,\n",
    "                      init_rnn_state, rnn)\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs, try_gpu(),\n",
    "          use_random_iter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11df14f3",
   "metadata": {
    "origin_pos": 72
   },
   "source": [
    "从零开始实现上述循环神经网络模型，\n",
    "虽然有指导意义，但是并不方便。\n",
    "在下一节中，我们将学习如何改进循环神经网络模型。\n",
    "例如，如何使其实现地更容易，且运行速度更快。\n",
    "\n",
    "## 小结\n",
    "\n",
    "* 我们可以训练一个基于循环神经网络的字符级语言模型，根据用户提供的文本的前缀生成后续文本。\n",
    "* 一个简单的循环神经网络语言模型包括输入编码、循环神经网络模型和输出生成。\n",
    "* 循环神经网络模型在训练以前需要初始化状态，不过随机抽样和顺序划分使用初始化方法不同。\n",
    "* 当使用顺序划分时，我们需要分离梯度以减少计算量。\n",
    "* 在进行任何预测之前，模型通过预热期进行自我更新（例如，获得比初始值更好的隐状态）。\n",
    "* 梯度裁剪可以防止梯度爆炸，但不能应对梯度消失。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 尝试说明独热编码等价于为每个对象选择不同的嵌入表示。\n",
    "1. 通过调整超参数（如迭代周期数、隐藏单元数、小批量数据的时间步数、学习率等）来改善困惑度。\n",
    "    * 困惑度可以降到多少？\n",
    "    * 用可学习的嵌入表示替换独热编码，是否会带来更好的表现？\n",
    "    * 如果用H.G.Wells的其他书作为数据集时效果如何，\n",
    "      例如[*世界大战*](http://www.gutenberg.org/ebooks/36)？\n",
    "1. 修改预测函数，例如使用采样，而不是选择最有可能的下一个字符。\n",
    "    * 会发生什么？\n",
    "    * 调整模型使之偏向更可能的输出，例如，当$\\alpha > 1$，从$q(x_t \\mid x_{t-1}, \\ldots, x_1) \\propto P(x_t \\mid x_{t-1}, \\ldots, x_1)^\\alpha$中采样。\n",
    "1. 在不裁剪梯度的情况下运行本节中的代码会发生什么？\n",
    "1. 更改顺序划分，使其不会从计算图中分离隐状态。运行时间会有变化吗？困惑度呢？\n",
    "1. 用ReLU替换本节中使用的激活函数，并重复本节中的实验。我们还需要梯度裁剪吗？为什么？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c810dbc6",
   "metadata": {
    "origin_pos": 74,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/2103)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
